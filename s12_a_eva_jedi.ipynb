{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\EVA\\JEDi\n"
     ]
    }
   ],
   "source": [
    "cd D:/ML/EVA/JEDi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''D:/ML/EVA/JEDi/data/tiny-imagenet-200/''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_dictionary():\n",
    "    id_dict = {}\n",
    "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
    "        id_dict[line.replace('\\n', '')] = i\n",
    "    return id_dict\n",
    "  \n",
    "def get_class_to_id_dict():\n",
    "    id_dict = get_id_dictionary()\n",
    "    all_classes = {}\n",
    "    result = {}\n",
    "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
    "        n_id, word = line.replace('\\n', '').split('\\t')[:2]\n",
    "        all_classes[n_id] = word\n",
    "    for key, value in id_dict.items():\n",
    "        result[value] = (key, all_classes[key])      \n",
    "    return result\n",
    "\n",
    "def get_data(id_dict):\n",
    "    print('starting loading data')\n",
    "    train_data, test_data = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "    t = time.time()\n",
    "    for key, value in id_dict.items():\n",
    "        train_data += [cv2.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i))) for i in range(500)]\n",
    "        train_labels_ = np.array([[0]*200]*500)\n",
    "        train_labels_[:, value] = 1\n",
    "        train_labels += train_labels_.tolist()\n",
    "\n",
    "    for line in open( path + 'val/val_annotations.txt'):\n",
    "        img_name, class_id = line.split('\\t')[:2]\n",
    "        test_data.append(cv2.imread( path + 'val/images/{}'.format(img_name)))\n",
    "        test_labels_ = np.array([[0]*200])\n",
    "        test_labels_[0, id_dict[class_id]] = 1\n",
    "        test_labels += test_labels_.tolist()\n",
    "\n",
    "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
    "    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting loading data\n",
      "finished loading data, in 86.07648301124573 seconds\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels, test_data, test_labels = get_data(get_id_dictionary())\n",
    "train_labels = train_labels.argmax(axis=1)\n",
    "test_labels = test_labels.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla = cv2.imread(path + 'train/{}/images/{}_{}.JPEG'.format('n02124075', 'n02124075', str(70)))\n",
    "bla.shape\n",
    "#D:\\ML\\EVA\\JEDI\\data\\tiny-imagenet-200\\train\\n01443537\\images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"train data shape: \",  train_data.shape )\n",
    "print( \"train label shape: \", train_labels.shape )\n",
    "print( \"test data shape: \",   test_data.shape )\n",
    "print( \"test_labels.shape: \", test_labels.shape )\n",
    "#(64,64,3) == (64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "image = PIL.Image.fromarray(train_data[0]).convert('RGB')\n",
    "image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "image = torch.tensor(image, dtype=torch.float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\EVA\\JEDi\\tsai.jedi\n"
     ]
    }
   ],
   "source": [
    "cd D:/ML/EVA/JEDi/tsai.jedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datatransforms import train_transform_tinyimagenet,test_transform_tinyimagenet\n",
    "import config\n",
    "import torch\n",
    "kwargs = {'num_workers': config.num_workers, 'pin_memory': config.pin_memory} if config.use_cuda else {}\n",
    "trainset = train_transform_tinyimagenet(image_list=train_data, label=train_labels)\n",
    "train_loader_tinyimgnet_s12 = torch.utils.data.DataLoader(trainset,\n",
    "                                                   batch_size=config.batch_size, shuffle=True, **kwargs)\n",
    "testset = test_transform_tinyimagenet(image_list=test_data, label=test_labels)\n",
    "test_loader_tinyimgnet_s12 = torch.utils.data.DataLoader(testset,\n",
    "                                                  batch_size=config.batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data, train_labels, test_data, test_labels, testset, trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:/ML/EVA/JEDI/tsai.jedi/Models')\n",
    "from S9_resnet import resnet18\n",
    "from S7 import model_summary\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = resnet18(num_classes=200, pretrained=False).to(config.device)\n",
    "#print(model_summary(model_, (3,64,64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\EVA\\JEDi\\tsai.jedi\n"
     ]
    }
   ],
   "source": [
    "cd D:/ML/EVA/JEDi/tsai.jedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config \n",
    "config.imagenet_directory = 'D:/ML/EVA/JEDi/data'\n",
    "import config\n",
    "config.update_var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "starting loading data\n",
      "finished loading data, in 24.184310913085938 seconds\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from lr_finder import LRFinder\n",
    "import torch.nn as nn\n",
    "from dataloader import train_loader_tinyimgnet_s12, test_loader_tinyimgnet_s12\n",
    "from aftereffects import get_image_with_target, plots\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0333bc64ba6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m51\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     train_a, train_l = train_cyclic(model_, config.device, train_loader_tinyimgnet_s12, optimizer, epoch,\n\u001b[1;32m---> 14\u001b[1;33m                              is_cyclicLR = True,scheduler = scheduler,l1_regularization=[0, 1])\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mtrain_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\EVA\\JEDi\\tsai.jedi\\Engine_train_test.py\u001b[0m in \u001b[0;36mtrain_cyclic\u001b[1;34m(model, device, train_loader, optimizer, epoch, l1_regularization, is_cyclicLR, scheduler)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# get the index of the max log-probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mtrain_correct\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf'loss={train_loss.item()} batch_id={batch_idx}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR, OneCycleLR\n",
    "from Engine_train_test import train_cyclic, test\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model_.parameters(), lr=9.9E-03, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = OneCycleLR(optimizer,max_lr=9.9E-03,epochs = 50,steps_per_epoch = len(train_loader_tinyimgnet_s12),\n",
    "                       pct_start = 0.21,div_factor = 10,final_div_factor = 1)\n",
    "valid_acc = []\n",
    "valid_loss = []\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "for epoch in range(1, 51):\n",
    "    train_a, train_l = train_cyclic(model_, config.device, train_loader_tinyimgnet_s12, optimizer, epoch,\n",
    "                             is_cyclicLR = True,scheduler = scheduler,l1_regularization=[0, 1])\n",
    "    train_acc.append(train_a)\n",
    "    train_loss.append(train_l)\n",
    "    valid_a, valid_l = test(model_, config.device, test_loader_tinyimgnet_s12) \n",
    "    # Appending to loss and accuracy lists\n",
    "    valid_acc.append(valid_a)\n",
    "    train_loss.append(valid_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_, 'D:/ML/EVA/JEDI/tsai.jedi/model_objects/s12.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 3            |        cudaMalloc retries: 3         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    3651 MB |    3652 MB |    4918 MB |    1266 MB |\\n|       from large pool |    3647 MB |    3647 MB |    4894 MB |    1246 MB |\\n|       from small pool |       4 MB |      19 MB |      24 MB |      19 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    3651 MB |    3652 MB |    4918 MB |    1266 MB |\\n|       from large pool |    3647 MB |    3647 MB |    4894 MB |    1246 MB |\\n|       from small pool |       4 MB |      19 MB |      24 MB |      19 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    3776 MB |    3810 MB |    3810 MB |   34816 KB |\\n|       from large pool |    3770 MB |    3790 MB |    3790 MB |   20480 KB |\\n|       from small pool |       6 MB |      20 MB |      20 MB |   14336 KB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  127147 KB |  127148 KB |  238282 KB |  111135 KB |\\n|       from large pool |  125568 KB |  125568 KB |  208387 KB |   82819 KB |\\n|       from small pool |    1579 KB |    2383 KB |   29895 KB |   28316 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     137    |     202    |     263    |     126    |\\n|       from large pool |      16    |      19    |      37    |      21    |\\n|       from small pool |     121    |     184    |     226    |     105    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     137    |     202    |     263    |     126    |\\n|       from large pool |      16    |      19    |      37    |      21    |\\n|       from small pool |     121    |     184    |     226    |     105    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      14    |      22    |      22    |       8    |\\n|       from large pool |      11    |      12    |      12    |       1    |\\n|       from small pool |       3    |      10    |      10    |       7    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      17    |      29    |      85    |      68    |\\n|       from large pool |       6    |       6    |      12    |       6    |\\n|       from small pool |      11    |      25    |      73    |      62    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
