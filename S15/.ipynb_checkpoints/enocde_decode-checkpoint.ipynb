{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnext Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\EVA\\JEDi\\Midas\n"
     ]
    }
   ],
   "source": [
    "cd D:/ML/EVA/JEDi/Midas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import utils\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Compose\n",
    "#from midas.midas_net import MidasNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\realp/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to C:\\Users\\realp/.cache\\torch\\hub\\checkpoints\\resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68525353e174430580941a51f1155fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def _make_resnet_backbone(resnet):\n",
    "    pretrained = nn.Module()\n",
    "    pretrained.layer1 = nn.Sequential(\n",
    "        resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool, resnet.layer1\n",
    "    )\n",
    "\n",
    "    pretrained.layer2 = resnet.layer2\n",
    "    pretrained.layer3 = resnet.layer3\n",
    "    pretrained.layer4 = resnet.layer4\n",
    "\n",
    "    return pretrained\n",
    "\n",
    "\n",
    "def _make_pretrained_resnext101_wsl(use_pretrained):\n",
    "    #resnet = torch.hub.load(\"facebookresearch/WSL-Images\", \"resnext101_32x8d_wsl\")\n",
    "    resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "    return _make_resnet_backbone(resnet)\n",
    "\n",
    "resnet18 = _make_pretrained_resnext101_wsl(use_pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class enc(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(enc,self).__init__()\n",
    "        layer = []\n",
    "        for child in resnet18.children(): \n",
    "            layer.append(child)   \n",
    "                \n",
    "        self.res1 = layer[0]\n",
    "        self.res2 = layer[1]\n",
    "        self.res3 = layer[2]\n",
    "        self.res4 = layer[3]\n",
    "        \n",
    "            \n",
    "    def forward(self,x): \n",
    "        EC1 = self.res1(x) #res /8, k_out = 256 \n",
    "        EC2= self.res2(EC1)  #res /16, k_out = 512\n",
    "        EC3 = self.res3(EC2) #res /32, k_out = 1024\n",
    "        out = self.res4(EC3)#res /64, k_out = 2048\n",
    "        return EC1, EC2, EC3, out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res1.0.weight \t torch.Size([64, 3, 7, 7])\n",
      "res1.1.weight \t torch.Size([64])\n",
      "res1.1.bias \t torch.Size([64])\n",
      "res1.1.running_mean \t torch.Size([64])\n",
      "res1.1.running_var \t torch.Size([64])\n",
      "res1.1.num_batches_tracked \t torch.Size([])\n",
      "res1.4.0.conv1.weight \t torch.Size([256, 64, 1, 1])\n",
      "res1.4.0.bn1.weight \t torch.Size([256])\n",
      "res1.4.0.bn1.bias \t torch.Size([256])\n",
      "res1.4.0.bn1.running_mean \t torch.Size([256])\n",
      "res1.4.0.bn1.running_var \t torch.Size([256])\n",
      "res1.4.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "res1.4.0.conv2.weight \t torch.Size([256, 8, 3, 3])\n",
      "res1.4.0.bn2.weight \t torch.Size([256])\n",
      "res1.4.0.bn2.bias \t torch.Size([256])\n",
      "res1.4.0.bn2.running_mean \t torch.Size([256])\n",
      "res1.4.0.bn2.running_var \t torch.Size([256])\n",
      "res1.4.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "res1.4.0.conv3.weight \t torch.Size([256, 256, 1, 1])\n",
      "res1.4.0.bn3.weight \t torch.Size([256])\n",
      "res1.4.0.bn3.bias \t torch.Size([256])\n",
      "res1.4.0.bn3.running_mean \t torch.Size([256])\n",
      "res1.4.0.bn3.running_var \t torch.Size([256])\n",
      "res1.4.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "res1.4.0.downsample.0.weight \t torch.Size([256, 64, 1, 1])\n",
      "res1.4.0.downsample.1.weight \t torch.Size([256])\n",
      "res1.4.0.downsample.1.bias \t torch.Size([256])\n",
      "res1.4.0.downsample.1.running_mean \t torch.Size([256])\n",
      "res1.4.0.downsample.1.running_var \t torch.Size([256])\n",
      "res1.4.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "res1.4.1.conv1.weight \t torch.Size([256, 256, 1, 1])\n",
      "res1.4.1.bn1.weight \t torch.Size([256])\n",
      "res1.4.1.bn1.bias \t torch.Size([256])\n",
      "res1.4.1.bn1.running_mean \t torch.Size([256])\n",
      "res1.4.1.bn1.running_var \t torch.Size([256])\n",
      "res1.4.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "res1.4.1.conv2.weight \t torch.Size([256, 8, 3, 3])\n",
      "res1.4.1.bn2.weight \t torch.Size([256])\n",
      "res1.4.1.bn2.bias \t torch.Size([256])\n",
      "res1.4.1.bn2.running_mean \t torch.Size([256])\n",
      "res1.4.1.bn2.running_var \t torch.Size([256])\n",
      "res1.4.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "res1.4.1.conv3.weight \t torch.Size([256, 256, 1, 1])\n",
      "res1.4.1.bn3.weight \t torch.Size([256])\n",
      "res1.4.1.bn3.bias \t torch.Size([256])\n",
      "res1.4.1.bn3.running_mean \t torch.Size([256])\n",
      "res1.4.1.bn3.running_var \t torch.Size([256])\n",
      "res1.4.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "res1.4.2.conv1.weight \t torch.Size([256, 256, 1, 1])\n",
      "res1.4.2.bn1.weight \t torch.Size([256])\n",
      "res1.4.2.bn1.bias \t torch.Size([256])\n",
      "res1.4.2.bn1.running_mean \t torch.Size([256])\n",
      "res1.4.2.bn1.running_var \t torch.Size([256])\n",
      "res1.4.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "res1.4.2.conv2.weight \t torch.Size([256, 8, 3, 3])\n",
      "res1.4.2.bn2.weight \t torch.Size([256])\n",
      "res1.4.2.bn2.bias \t torch.Size([256])\n",
      "res1.4.2.bn2.running_mean \t torch.Size([256])\n",
      "res1.4.2.bn2.running_var \t torch.Size([256])\n",
      "res1.4.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "res1.4.2.conv3.weight \t torch.Size([256, 256, 1, 1])\n",
      "res1.4.2.bn3.weight \t torch.Size([256])\n",
      "res1.4.2.bn3.bias \t torch.Size([256])\n",
      "res1.4.2.bn3.running_mean \t torch.Size([256])\n",
      "res1.4.2.bn3.running_var \t torch.Size([256])\n",
      "res1.4.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "res2.0.conv1.weight \t torch.Size([512, 256, 1, 1])\n",
      "res2.0.bn1.weight \t torch.Size([512])\n",
      "res2.0.bn1.bias \t torch.Size([512])\n",
      "res2.0.bn1.running_mean \t torch.Size([512])\n",
      "res2.0.bn1.running_var \t torch.Size([512])\n",
      "res2.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "res2.0.conv2.weight \t torch.Size([512, 16, 3, 3])\n",
      "res2.0.bn2.weight \t torch.Size([512])\n",
      "res2.0.bn2.bias \t torch.Size([512])\n",
      "res2.0.bn2.running_mean \t torch.Size([512])\n",
      "res2.0.bn2.running_var \t torch.Size([512])\n",
      "res2.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "res2.0.conv3.weight \t torch.Size([512, 512, 1, 1])\n",
      "res2.0.bn3.weight \t torch.Size([512])\n",
      "res2.0.bn3.bias \t torch.Size([512])\n",
      "res2.0.bn3.running_mean \t torch.Size([512])\n",
      "res2.0.bn3.running_var \t torch.Size([512])\n",
      "res2.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "res2.0.downsample.0.weight \t torch.Size([512, 256, 1, 1])\n",
      "res2.0.downsample.1.weight \t torch.Size([512])\n",
      "res2.0.downsample.1.bias \t torch.Size([512])\n",
      "res2.0.downsample.1.running_mean \t torch.Size([512])\n",
      "res2.0.downsample.1.running_var \t torch.Size([512])\n",
      "res2.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "res2.1.conv1.weight \t torch.Size([512, 512, 1, 1])\n",
      "res2.1.bn1.weight \t torch.Size([512])\n",
      "res2.1.bn1.bias \t torch.Size([512])\n",
      "res2.1.bn1.running_mean \t torch.Size([512])\n",
      "res2.1.bn1.running_var \t torch.Size([512])\n",
      "res2.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "res2.1.conv2.weight \t torch.Size([512, 16, 3, 3])\n",
      "res2.1.bn2.weight \t torch.Size([512])\n",
      "res2.1.bn2.bias \t torch.Size([512])\n",
      "res2.1.bn2.running_mean \t torch.Size([512])\n",
      "res2.1.bn2.running_var \t torch.Size([512])\n",
      "res2.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "res2.1.conv3.weight \t torch.Size([512, 512, 1, 1])\n",
      "res2.1.bn3.weight \t torch.Size([512])\n",
      "res2.1.bn3.bias \t torch.Size([512])\n",
      "res2.1.bn3.running_mean \t torch.Size([512])\n",
      "res2.1.bn3.running_var \t torch.Size([512])\n",
      "res2.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "res2.2.conv1.weight \t torch.Size([512, 512, 1, 1])\n",
      "res2.2.bn1.weight \t torch.Size([512])\n",
      "res2.2.bn1.bias \t torch.Size([512])\n",
      "res2.2.bn1.running_mean \t torch.Size([512])\n",
      "res2.2.bn1.running_var \t torch.Size([512])\n",
      "res2.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "res2.2.conv2.weight \t torch.Size([512, 16, 3, 3])\n",
      "res2.2.bn2.weight \t torch.Size([512])\n",
      "res2.2.bn2.bias \t torch.Size([512])\n",
      "res2.2.bn2.running_mean \t torch.Size([512])\n",
      "res2.2.bn2.running_var \t torch.Size([512])\n",
      "res2.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "res2.2.conv3.weight \t torch.Size([512, 512, 1, 1])\n",
      "res2.2.bn3.weight \t torch.Size([512])\n",
      "res2.2.bn3.bias \t torch.Size([512])\n",
      "res2.2.bn3.running_mean \t torch.Size([512])\n",
      "res2.2.bn3.running_var \t torch.Size([512])\n",
      "res2.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "res2.3.conv1.weight \t torch.Size([512, 512, 1, 1])\n",
      "res2.3.bn1.weight \t torch.Size([512])\n",
      "res2.3.bn1.bias \t torch.Size([512])\n",
      "res2.3.bn1.running_mean \t torch.Size([512])\n",
      "res2.3.bn1.running_var \t torch.Size([512])\n",
      "res2.3.bn1.num_batches_tracked \t torch.Size([])\n",
      "res2.3.conv2.weight \t torch.Size([512, 16, 3, 3])\n",
      "res2.3.bn2.weight \t torch.Size([512])\n",
      "res2.3.bn2.bias \t torch.Size([512])\n",
      "res2.3.bn2.running_mean \t torch.Size([512])\n",
      "res2.3.bn2.running_var \t torch.Size([512])\n",
      "res2.3.bn2.num_batches_tracked \t torch.Size([])\n",
      "res2.3.conv3.weight \t torch.Size([512, 512, 1, 1])\n",
      "res2.3.bn3.weight \t torch.Size([512])\n",
      "res2.3.bn3.bias \t torch.Size([512])\n",
      "res2.3.bn3.running_mean \t torch.Size([512])\n",
      "res2.3.bn3.running_var \t torch.Size([512])\n",
      "res2.3.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.0.conv1.weight \t torch.Size([1024, 512, 1, 1])\n",
      "res3.0.bn1.weight \t torch.Size([1024])\n",
      "res3.0.bn1.bias \t torch.Size([1024])\n",
      "res3.0.bn1.running_mean \t torch.Size([1024])\n",
      "res3.0.bn1.running_var \t torch.Size([1024])\n",
      "res3.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.0.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.0.bn2.weight \t torch.Size([1024])\n",
      "res3.0.bn2.bias \t torch.Size([1024])\n",
      "res3.0.bn2.running_mean \t torch.Size([1024])\n",
      "res3.0.bn2.running_var \t torch.Size([1024])\n",
      "res3.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.0.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.0.bn3.weight \t torch.Size([1024])\n",
      "res3.0.bn3.bias \t torch.Size([1024])\n",
      "res3.0.bn3.running_mean \t torch.Size([1024])\n",
      "res3.0.bn3.running_var \t torch.Size([1024])\n",
      "res3.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.0.downsample.0.weight \t torch.Size([1024, 512, 1, 1])\n",
      "res3.0.downsample.1.weight \t torch.Size([1024])\n",
      "res3.0.downsample.1.bias \t torch.Size([1024])\n",
      "res3.0.downsample.1.running_mean \t torch.Size([1024])\n",
      "res3.0.downsample.1.running_var \t torch.Size([1024])\n",
      "res3.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "res3.1.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.1.bn1.weight \t torch.Size([1024])\n",
      "res3.1.bn1.bias \t torch.Size([1024])\n",
      "res3.1.bn1.running_mean \t torch.Size([1024])\n",
      "res3.1.bn1.running_var \t torch.Size([1024])\n",
      "res3.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.1.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.1.bn2.weight \t torch.Size([1024])\n",
      "res3.1.bn2.bias \t torch.Size([1024])\n",
      "res3.1.bn2.running_mean \t torch.Size([1024])\n",
      "res3.1.bn2.running_var \t torch.Size([1024])\n",
      "res3.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.1.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.1.bn3.weight \t torch.Size([1024])\n",
      "res3.1.bn3.bias \t torch.Size([1024])\n",
      "res3.1.bn3.running_mean \t torch.Size([1024])\n",
      "res3.1.bn3.running_var \t torch.Size([1024])\n",
      "res3.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.2.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.2.bn1.weight \t torch.Size([1024])\n",
      "res3.2.bn1.bias \t torch.Size([1024])\n",
      "res3.2.bn1.running_mean \t torch.Size([1024])\n",
      "res3.2.bn1.running_var \t torch.Size([1024])\n",
      "res3.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.2.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.2.bn2.weight \t torch.Size([1024])\n",
      "res3.2.bn2.bias \t torch.Size([1024])\n",
      "res3.2.bn2.running_mean \t torch.Size([1024])\n",
      "res3.2.bn2.running_var \t torch.Size([1024])\n",
      "res3.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.2.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.2.bn3.weight \t torch.Size([1024])\n",
      "res3.2.bn3.bias \t torch.Size([1024])\n",
      "res3.2.bn3.running_mean \t torch.Size([1024])\n",
      "res3.2.bn3.running_var \t torch.Size([1024])\n",
      "res3.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.3.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res3.3.bn1.weight \t torch.Size([1024])\n",
      "res3.3.bn1.bias \t torch.Size([1024])\n",
      "res3.3.bn1.running_mean \t torch.Size([1024])\n",
      "res3.3.bn1.running_var \t torch.Size([1024])\n",
      "res3.3.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.3.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.3.bn2.weight \t torch.Size([1024])\n",
      "res3.3.bn2.bias \t torch.Size([1024])\n",
      "res3.3.bn2.running_mean \t torch.Size([1024])\n",
      "res3.3.bn2.running_var \t torch.Size([1024])\n",
      "res3.3.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.3.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.3.bn3.weight \t torch.Size([1024])\n",
      "res3.3.bn3.bias \t torch.Size([1024])\n",
      "res3.3.bn3.running_mean \t torch.Size([1024])\n",
      "res3.3.bn3.running_var \t torch.Size([1024])\n",
      "res3.3.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.4.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.4.bn1.weight \t torch.Size([1024])\n",
      "res3.4.bn1.bias \t torch.Size([1024])\n",
      "res3.4.bn1.running_mean \t torch.Size([1024])\n",
      "res3.4.bn1.running_var \t torch.Size([1024])\n",
      "res3.4.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.4.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.4.bn2.weight \t torch.Size([1024])\n",
      "res3.4.bn2.bias \t torch.Size([1024])\n",
      "res3.4.bn2.running_mean \t torch.Size([1024])\n",
      "res3.4.bn2.running_var \t torch.Size([1024])\n",
      "res3.4.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.4.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.4.bn3.weight \t torch.Size([1024])\n",
      "res3.4.bn3.bias \t torch.Size([1024])\n",
      "res3.4.bn3.running_mean \t torch.Size([1024])\n",
      "res3.4.bn3.running_var \t torch.Size([1024])\n",
      "res3.4.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.5.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.5.bn1.weight \t torch.Size([1024])\n",
      "res3.5.bn1.bias \t torch.Size([1024])\n",
      "res3.5.bn1.running_mean \t torch.Size([1024])\n",
      "res3.5.bn1.running_var \t torch.Size([1024])\n",
      "res3.5.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.5.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.5.bn2.weight \t torch.Size([1024])\n",
      "res3.5.bn2.bias \t torch.Size([1024])\n",
      "res3.5.bn2.running_mean \t torch.Size([1024])\n",
      "res3.5.bn2.running_var \t torch.Size([1024])\n",
      "res3.5.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.5.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.5.bn3.weight \t torch.Size([1024])\n",
      "res3.5.bn3.bias \t torch.Size([1024])\n",
      "res3.5.bn3.running_mean \t torch.Size([1024])\n",
      "res3.5.bn3.running_var \t torch.Size([1024])\n",
      "res3.5.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.6.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.6.bn1.weight \t torch.Size([1024])\n",
      "res3.6.bn1.bias \t torch.Size([1024])\n",
      "res3.6.bn1.running_mean \t torch.Size([1024])\n",
      "res3.6.bn1.running_var \t torch.Size([1024])\n",
      "res3.6.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.6.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.6.bn2.weight \t torch.Size([1024])\n",
      "res3.6.bn2.bias \t torch.Size([1024])\n",
      "res3.6.bn2.running_mean \t torch.Size([1024])\n",
      "res3.6.bn2.running_var \t torch.Size([1024])\n",
      "res3.6.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.6.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.6.bn3.weight \t torch.Size([1024])\n",
      "res3.6.bn3.bias \t torch.Size([1024])\n",
      "res3.6.bn3.running_mean \t torch.Size([1024])\n",
      "res3.6.bn3.running_var \t torch.Size([1024])\n",
      "res3.6.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.7.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.7.bn1.weight \t torch.Size([1024])\n",
      "res3.7.bn1.bias \t torch.Size([1024])\n",
      "res3.7.bn1.running_mean \t torch.Size([1024])\n",
      "res3.7.bn1.running_var \t torch.Size([1024])\n",
      "res3.7.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.7.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.7.bn2.weight \t torch.Size([1024])\n",
      "res3.7.bn2.bias \t torch.Size([1024])\n",
      "res3.7.bn2.running_mean \t torch.Size([1024])\n",
      "res3.7.bn2.running_var \t torch.Size([1024])\n",
      "res3.7.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.7.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.7.bn3.weight \t torch.Size([1024])\n",
      "res3.7.bn3.bias \t torch.Size([1024])\n",
      "res3.7.bn3.running_mean \t torch.Size([1024])\n",
      "res3.7.bn3.running_var \t torch.Size([1024])\n",
      "res3.7.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.8.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.8.bn1.weight \t torch.Size([1024])\n",
      "res3.8.bn1.bias \t torch.Size([1024])\n",
      "res3.8.bn1.running_mean \t torch.Size([1024])\n",
      "res3.8.bn1.running_var \t torch.Size([1024])\n",
      "res3.8.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.8.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.8.bn2.weight \t torch.Size([1024])\n",
      "res3.8.bn2.bias \t torch.Size([1024])\n",
      "res3.8.bn2.running_mean \t torch.Size([1024])\n",
      "res3.8.bn2.running_var \t torch.Size([1024])\n",
      "res3.8.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.8.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.8.bn3.weight \t torch.Size([1024])\n",
      "res3.8.bn3.bias \t torch.Size([1024])\n",
      "res3.8.bn3.running_mean \t torch.Size([1024])\n",
      "res3.8.bn3.running_var \t torch.Size([1024])\n",
      "res3.8.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.9.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.9.bn1.weight \t torch.Size([1024])\n",
      "res3.9.bn1.bias \t torch.Size([1024])\n",
      "res3.9.bn1.running_mean \t torch.Size([1024])\n",
      "res3.9.bn1.running_var \t torch.Size([1024])\n",
      "res3.9.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.9.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.9.bn2.weight \t torch.Size([1024])\n",
      "res3.9.bn2.bias \t torch.Size([1024])\n",
      "res3.9.bn2.running_mean \t torch.Size([1024])\n",
      "res3.9.bn2.running_var \t torch.Size([1024])\n",
      "res3.9.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.9.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.9.bn3.weight \t torch.Size([1024])\n",
      "res3.9.bn3.bias \t torch.Size([1024])\n",
      "res3.9.bn3.running_mean \t torch.Size([1024])\n",
      "res3.9.bn3.running_var \t torch.Size([1024])\n",
      "res3.9.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.10.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.10.bn1.weight \t torch.Size([1024])\n",
      "res3.10.bn1.bias \t torch.Size([1024])\n",
      "res3.10.bn1.running_mean \t torch.Size([1024])\n",
      "res3.10.bn1.running_var \t torch.Size([1024])\n",
      "res3.10.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.10.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.10.bn2.weight \t torch.Size([1024])\n",
      "res3.10.bn2.bias \t torch.Size([1024])\n",
      "res3.10.bn2.running_mean \t torch.Size([1024])\n",
      "res3.10.bn2.running_var \t torch.Size([1024])\n",
      "res3.10.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.10.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.10.bn3.weight \t torch.Size([1024])\n",
      "res3.10.bn3.bias \t torch.Size([1024])\n",
      "res3.10.bn3.running_mean \t torch.Size([1024])\n",
      "res3.10.bn3.running_var \t torch.Size([1024])\n",
      "res3.10.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.11.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.11.bn1.weight \t torch.Size([1024])\n",
      "res3.11.bn1.bias \t torch.Size([1024])\n",
      "res3.11.bn1.running_mean \t torch.Size([1024])\n",
      "res3.11.bn1.running_var \t torch.Size([1024])\n",
      "res3.11.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.11.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.11.bn2.weight \t torch.Size([1024])\n",
      "res3.11.bn2.bias \t torch.Size([1024])\n",
      "res3.11.bn2.running_mean \t torch.Size([1024])\n",
      "res3.11.bn2.running_var \t torch.Size([1024])\n",
      "res3.11.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.11.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.11.bn3.weight \t torch.Size([1024])\n",
      "res3.11.bn3.bias \t torch.Size([1024])\n",
      "res3.11.bn3.running_mean \t torch.Size([1024])\n",
      "res3.11.bn3.running_var \t torch.Size([1024])\n",
      "res3.11.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.12.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.12.bn1.weight \t torch.Size([1024])\n",
      "res3.12.bn1.bias \t torch.Size([1024])\n",
      "res3.12.bn1.running_mean \t torch.Size([1024])\n",
      "res3.12.bn1.running_var \t torch.Size([1024])\n",
      "res3.12.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.12.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.12.bn2.weight \t torch.Size([1024])\n",
      "res3.12.bn2.bias \t torch.Size([1024])\n",
      "res3.12.bn2.running_mean \t torch.Size([1024])\n",
      "res3.12.bn2.running_var \t torch.Size([1024])\n",
      "res3.12.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.12.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.12.bn3.weight \t torch.Size([1024])\n",
      "res3.12.bn3.bias \t torch.Size([1024])\n",
      "res3.12.bn3.running_mean \t torch.Size([1024])\n",
      "res3.12.bn3.running_var \t torch.Size([1024])\n",
      "res3.12.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.13.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.13.bn1.weight \t torch.Size([1024])\n",
      "res3.13.bn1.bias \t torch.Size([1024])\n",
      "res3.13.bn1.running_mean \t torch.Size([1024])\n",
      "res3.13.bn1.running_var \t torch.Size([1024])\n",
      "res3.13.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.13.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.13.bn2.weight \t torch.Size([1024])\n",
      "res3.13.bn2.bias \t torch.Size([1024])\n",
      "res3.13.bn2.running_mean \t torch.Size([1024])\n",
      "res3.13.bn2.running_var \t torch.Size([1024])\n",
      "res3.13.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.13.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.13.bn3.weight \t torch.Size([1024])\n",
      "res3.13.bn3.bias \t torch.Size([1024])\n",
      "res3.13.bn3.running_mean \t torch.Size([1024])\n",
      "res3.13.bn3.running_var \t torch.Size([1024])\n",
      "res3.13.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.14.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res3.14.bn1.weight \t torch.Size([1024])\n",
      "res3.14.bn1.bias \t torch.Size([1024])\n",
      "res3.14.bn1.running_mean \t torch.Size([1024])\n",
      "res3.14.bn1.running_var \t torch.Size([1024])\n",
      "res3.14.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.14.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.14.bn2.weight \t torch.Size([1024])\n",
      "res3.14.bn2.bias \t torch.Size([1024])\n",
      "res3.14.bn2.running_mean \t torch.Size([1024])\n",
      "res3.14.bn2.running_var \t torch.Size([1024])\n",
      "res3.14.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.14.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.14.bn3.weight \t torch.Size([1024])\n",
      "res3.14.bn3.bias \t torch.Size([1024])\n",
      "res3.14.bn3.running_mean \t torch.Size([1024])\n",
      "res3.14.bn3.running_var \t torch.Size([1024])\n",
      "res3.14.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.15.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.15.bn1.weight \t torch.Size([1024])\n",
      "res3.15.bn1.bias \t torch.Size([1024])\n",
      "res3.15.bn1.running_mean \t torch.Size([1024])\n",
      "res3.15.bn1.running_var \t torch.Size([1024])\n",
      "res3.15.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.15.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.15.bn2.weight \t torch.Size([1024])\n",
      "res3.15.bn2.bias \t torch.Size([1024])\n",
      "res3.15.bn2.running_mean \t torch.Size([1024])\n",
      "res3.15.bn2.running_var \t torch.Size([1024])\n",
      "res3.15.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.15.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.15.bn3.weight \t torch.Size([1024])\n",
      "res3.15.bn3.bias \t torch.Size([1024])\n",
      "res3.15.bn3.running_mean \t torch.Size([1024])\n",
      "res3.15.bn3.running_var \t torch.Size([1024])\n",
      "res3.15.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.16.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.16.bn1.weight \t torch.Size([1024])\n",
      "res3.16.bn1.bias \t torch.Size([1024])\n",
      "res3.16.bn1.running_mean \t torch.Size([1024])\n",
      "res3.16.bn1.running_var \t torch.Size([1024])\n",
      "res3.16.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.16.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.16.bn2.weight \t torch.Size([1024])\n",
      "res3.16.bn2.bias \t torch.Size([1024])\n",
      "res3.16.bn2.running_mean \t torch.Size([1024])\n",
      "res3.16.bn2.running_var \t torch.Size([1024])\n",
      "res3.16.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.16.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.16.bn3.weight \t torch.Size([1024])\n",
      "res3.16.bn3.bias \t torch.Size([1024])\n",
      "res3.16.bn3.running_mean \t torch.Size([1024])\n",
      "res3.16.bn3.running_var \t torch.Size([1024])\n",
      "res3.16.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.17.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.17.bn1.weight \t torch.Size([1024])\n",
      "res3.17.bn1.bias \t torch.Size([1024])\n",
      "res3.17.bn1.running_mean \t torch.Size([1024])\n",
      "res3.17.bn1.running_var \t torch.Size([1024])\n",
      "res3.17.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.17.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.17.bn2.weight \t torch.Size([1024])\n",
      "res3.17.bn2.bias \t torch.Size([1024])\n",
      "res3.17.bn2.running_mean \t torch.Size([1024])\n",
      "res3.17.bn2.running_var \t torch.Size([1024])\n",
      "res3.17.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.17.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.17.bn3.weight \t torch.Size([1024])\n",
      "res3.17.bn3.bias \t torch.Size([1024])\n",
      "res3.17.bn3.running_mean \t torch.Size([1024])\n",
      "res3.17.bn3.running_var \t torch.Size([1024])\n",
      "res3.17.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.18.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.18.bn1.weight \t torch.Size([1024])\n",
      "res3.18.bn1.bias \t torch.Size([1024])\n",
      "res3.18.bn1.running_mean \t torch.Size([1024])\n",
      "res3.18.bn1.running_var \t torch.Size([1024])\n",
      "res3.18.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.18.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.18.bn2.weight \t torch.Size([1024])\n",
      "res3.18.bn2.bias \t torch.Size([1024])\n",
      "res3.18.bn2.running_mean \t torch.Size([1024])\n",
      "res3.18.bn2.running_var \t torch.Size([1024])\n",
      "res3.18.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.18.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.18.bn3.weight \t torch.Size([1024])\n",
      "res3.18.bn3.bias \t torch.Size([1024])\n",
      "res3.18.bn3.running_mean \t torch.Size([1024])\n",
      "res3.18.bn3.running_var \t torch.Size([1024])\n",
      "res3.18.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.19.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.19.bn1.weight \t torch.Size([1024])\n",
      "res3.19.bn1.bias \t torch.Size([1024])\n",
      "res3.19.bn1.running_mean \t torch.Size([1024])\n",
      "res3.19.bn1.running_var \t torch.Size([1024])\n",
      "res3.19.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.19.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.19.bn2.weight \t torch.Size([1024])\n",
      "res3.19.bn2.bias \t torch.Size([1024])\n",
      "res3.19.bn2.running_mean \t torch.Size([1024])\n",
      "res3.19.bn2.running_var \t torch.Size([1024])\n",
      "res3.19.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.19.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.19.bn3.weight \t torch.Size([1024])\n",
      "res3.19.bn3.bias \t torch.Size([1024])\n",
      "res3.19.bn3.running_mean \t torch.Size([1024])\n",
      "res3.19.bn3.running_var \t torch.Size([1024])\n",
      "res3.19.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.20.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.20.bn1.weight \t torch.Size([1024])\n",
      "res3.20.bn1.bias \t torch.Size([1024])\n",
      "res3.20.bn1.running_mean \t torch.Size([1024])\n",
      "res3.20.bn1.running_var \t torch.Size([1024])\n",
      "res3.20.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.20.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.20.bn2.weight \t torch.Size([1024])\n",
      "res3.20.bn2.bias \t torch.Size([1024])\n",
      "res3.20.bn2.running_mean \t torch.Size([1024])\n",
      "res3.20.bn2.running_var \t torch.Size([1024])\n",
      "res3.20.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.20.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.20.bn3.weight \t torch.Size([1024])\n",
      "res3.20.bn3.bias \t torch.Size([1024])\n",
      "res3.20.bn3.running_mean \t torch.Size([1024])\n",
      "res3.20.bn3.running_var \t torch.Size([1024])\n",
      "res3.20.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.21.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.21.bn1.weight \t torch.Size([1024])\n",
      "res3.21.bn1.bias \t torch.Size([1024])\n",
      "res3.21.bn1.running_mean \t torch.Size([1024])\n",
      "res3.21.bn1.running_var \t torch.Size([1024])\n",
      "res3.21.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.21.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.21.bn2.weight \t torch.Size([1024])\n",
      "res3.21.bn2.bias \t torch.Size([1024])\n",
      "res3.21.bn2.running_mean \t torch.Size([1024])\n",
      "res3.21.bn2.running_var \t torch.Size([1024])\n",
      "res3.21.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.21.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.21.bn3.weight \t torch.Size([1024])\n",
      "res3.21.bn3.bias \t torch.Size([1024])\n",
      "res3.21.bn3.running_mean \t torch.Size([1024])\n",
      "res3.21.bn3.running_var \t torch.Size([1024])\n",
      "res3.21.bn3.num_batches_tracked \t torch.Size([])\n",
      "res3.22.conv1.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.22.bn1.weight \t torch.Size([1024])\n",
      "res3.22.bn1.bias \t torch.Size([1024])\n",
      "res3.22.bn1.running_mean \t torch.Size([1024])\n",
      "res3.22.bn1.running_var \t torch.Size([1024])\n",
      "res3.22.bn1.num_batches_tracked \t torch.Size([])\n",
      "res3.22.conv2.weight \t torch.Size([1024, 32, 3, 3])\n",
      "res3.22.bn2.weight \t torch.Size([1024])\n",
      "res3.22.bn2.bias \t torch.Size([1024])\n",
      "res3.22.bn2.running_mean \t torch.Size([1024])\n",
      "res3.22.bn2.running_var \t torch.Size([1024])\n",
      "res3.22.bn2.num_batches_tracked \t torch.Size([])\n",
      "res3.22.conv3.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "res3.22.bn3.weight \t torch.Size([1024])\n",
      "res3.22.bn3.bias \t torch.Size([1024])\n",
      "res3.22.bn3.running_mean \t torch.Size([1024])\n",
      "res3.22.bn3.running_var \t torch.Size([1024])\n",
      "res3.22.bn3.num_batches_tracked \t torch.Size([])\n",
      "res4.0.conv1.weight \t torch.Size([2048, 1024, 1, 1])\n",
      "res4.0.bn1.weight \t torch.Size([2048])\n",
      "res4.0.bn1.bias \t torch.Size([2048])\n",
      "res4.0.bn1.running_mean \t torch.Size([2048])\n",
      "res4.0.bn1.running_var \t torch.Size([2048])\n",
      "res4.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "res4.0.conv2.weight \t torch.Size([2048, 64, 3, 3])\n",
      "res4.0.bn2.weight \t torch.Size([2048])\n",
      "res4.0.bn2.bias \t torch.Size([2048])\n",
      "res4.0.bn2.running_mean \t torch.Size([2048])\n",
      "res4.0.bn2.running_var \t torch.Size([2048])\n",
      "res4.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "res4.0.conv3.weight \t torch.Size([2048, 2048, 1, 1])\n",
      "res4.0.bn3.weight \t torch.Size([2048])\n",
      "res4.0.bn3.bias \t torch.Size([2048])\n",
      "res4.0.bn3.running_mean \t torch.Size([2048])\n",
      "res4.0.bn3.running_var \t torch.Size([2048])\n",
      "res4.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "res4.0.downsample.0.weight \t torch.Size([2048, 1024, 1, 1])\n",
      "res4.0.downsample.1.weight \t torch.Size([2048])\n",
      "res4.0.downsample.1.bias \t torch.Size([2048])\n",
      "res4.0.downsample.1.running_mean \t torch.Size([2048])\n",
      "res4.0.downsample.1.running_var \t torch.Size([2048])\n",
      "res4.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "res4.1.conv1.weight \t torch.Size([2048, 2048, 1, 1])\n",
      "res4.1.bn1.weight \t torch.Size([2048])\n",
      "res4.1.bn1.bias \t torch.Size([2048])\n",
      "res4.1.bn1.running_mean \t torch.Size([2048])\n",
      "res4.1.bn1.running_var \t torch.Size([2048])\n",
      "res4.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "res4.1.conv2.weight \t torch.Size([2048, 64, 3, 3])\n",
      "res4.1.bn2.weight \t torch.Size([2048])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res4.1.bn2.bias \t torch.Size([2048])\n",
      "res4.1.bn2.running_mean \t torch.Size([2048])\n",
      "res4.1.bn2.running_var \t torch.Size([2048])\n",
      "res4.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "res4.1.conv3.weight \t torch.Size([2048, 2048, 1, 1])\n",
      "res4.1.bn3.weight \t torch.Size([2048])\n",
      "res4.1.bn3.bias \t torch.Size([2048])\n",
      "res4.1.bn3.running_mean \t torch.Size([2048])\n",
      "res4.1.bn3.running_var \t torch.Size([2048])\n",
      "res4.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "res4.2.conv1.weight \t torch.Size([2048, 2048, 1, 1])\n",
      "res4.2.bn1.weight \t torch.Size([2048])\n",
      "res4.2.bn1.bias \t torch.Size([2048])\n",
      "res4.2.bn1.running_mean \t torch.Size([2048])\n",
      "res4.2.bn1.running_var \t torch.Size([2048])\n",
      "res4.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "res4.2.conv2.weight \t torch.Size([2048, 64, 3, 3])\n",
      "res4.2.bn2.weight \t torch.Size([2048])\n",
      "res4.2.bn2.bias \t torch.Size([2048])\n",
      "res4.2.bn2.running_mean \t torch.Size([2048])\n",
      "res4.2.bn2.running_var \t torch.Size([2048])\n",
      "res4.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "res4.2.conv3.weight \t torch.Size([2048, 2048, 1, 1])\n",
      "res4.2.bn3.weight \t torch.Size([2048])\n",
      "res4.2.bn3.bias \t torch.Size([2048])\n",
      "res4.2.bn3.running_mean \t torch.Size([2048])\n",
      "res4.2.bn3.running_var \t torch.Size([2048])\n",
      "res4.2.bn3.num_batches_tracked \t torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "#for param_tensor in model.state_dict(): print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# midas Depth decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scratch connections\n",
    "from midas.blocks import _make_scratch\n",
    "def gt_scratch(features = 256):\n",
    "    scratch = _make_scratch([256, 512, 1024, 2048], features)\n",
    "    return scratch\n",
    "#bla = scratch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#depth.midas decoder\n",
    "from midas.blocks import FeatureFusionBlock, Interpolate\n",
    "class depth_decoder(nn.Module): \n",
    "    def __init__(self,features = 256, non_negative=True): \n",
    "        super(depth_decoder, self).__init__()\n",
    "        self.scratch = gt_scratch()\n",
    "        \n",
    "        self.scratch.refinenet4 = FeatureFusionBlock(features)\n",
    "        self.scratch.refinenet3 = FeatureFusionBlock(features)\n",
    "        self.scratch.refinenet2 = FeatureFusionBlock(features)\n",
    "        self.scratch.refinenet1 = FeatureFusionBlock(features)\n",
    "        self.scratch.output_conv = nn.Sequential(\n",
    "            nn.Conv2d(features, 128, kernel_size=3, stride=1, padding=1),\n",
    "            Interpolate(scale_factor=2, mode=\"bilinear\"),\n",
    "            nn.Conv2d(128, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 1, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ReLU(True) if non_negative else nn.Identity(),\n",
    "        )\n",
    "        \n",
    "    def forward(self,EC1,EC2,EC3,out): \n",
    "        layer_1_rn = self.scratch.layer1_rn(EC1)\n",
    "        layer_2_rn = self.scratch.layer2_rn(EC2)\n",
    "        layer_3_rn = self.scratch.layer3_rn(EC3)\n",
    "        layer_4_rn = self.scratch.layer4_rn(out)\n",
    "        \n",
    "        path_4 = self.scratch.refinenet4(layer_4_rn)\n",
    "        path_3 = self.scratch.refinenet3(path_4, layer_3_rn)\n",
    "        path_2 = self.scratch.refinenet2(path_3, layer_2_rn)\n",
    "        path_1 = self.scratch.refinenet1(path_2, layer_1_rn)\n",
    "\n",
    "        out = self.scratch.output_conv(path_1)\n",
    "\n",
    "        return torch.squeeze(out, dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\EVA\\JEDI\\YoloV3master\n"
     ]
    }
   ],
   "source": [
    "cd D:/ML/EVA/JEDI/YoloV3master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _FeatureConcat(layers):\n",
    "        return torch.cat([i for i in layers], 1)\n",
    "\n",
    "def _gt_darknet_child(x):\n",
    "    if isinstance(list(Darknet.children())[0][x], nn.Sequential):\n",
    "        return list(list(Darknet.children())[0][x].children())\n",
    "    else: \n",
    "        temp = []\n",
    "        temp.append(list(Darknet.children())[0][x])\n",
    "        return temp\n",
    "    \n",
    "def _gt_darknet_children(l):\n",
    "    layer_list = []\n",
    "    for x in l: \n",
    "        layer_list.extend(_gt_darknet_child(x))\n",
    "    return layer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 225 layers, 6.25895e+07 parameters, 6.25895e+07 gradients\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "from utils_yolo.utils import *\n",
    "cfg = 'D:/ML/EVA/JEDI/YoloV3master/cfg/yolov3-custom.cfg'\n",
    "Darknet = Darknet(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class yolo_decoder(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(yolo_decoder, self).__init__()\n",
    "        #anchors for 13x13, 26X26, 52X52\n",
    "        val = \"10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\"\n",
    "        anc_13 = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[6,7,8]]\n",
    "        anc_26 = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[3,4,5]]\n",
    "        anc_52 = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[0,1,2]]\n",
    "        #13x13 yolo layer\n",
    "        self.yolo_13_bottle_neck = nn.Conv2d(2048, 2048, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.yolo_13_path = nn.Sequential(*_gt_darknet_children(list(range(84,87))))\n",
    "        self.yolo_13_tail = nn.Sequential(*_gt_darknet_children(list(range(87,89))))\n",
    "        self.yolo_13 = YOLOLayer(anchors=anc_13,  # anchor list\n",
    "                                nc=4,  # number of classes\n",
    "                                img_size= (416, 416),  # (416, 416)\n",
    "                                yolo_index=0,  # 0, 1, 2...\n",
    "                                layers=[],  # output layers\n",
    "                                stride=32)\n",
    "        #26x26 yolo layer\n",
    "        self.yolo_26_upsample = nn.Sequential(*_gt_darknet_children(list(range(91,93))))\n",
    "        self.yolo_26_bottle_neck = nn.Conv2d(1024, 512, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.yolo_26_path =  nn.Sequential(*_gt_darknet_children(list(range(94,99))))\n",
    "        self.yolo_26_tail = nn.Sequential(*_gt_darknet_children(list(range(99,101))))\n",
    "        self.yolo_26 = YOLOLayer(anchors=anc_26,  # anchor list\n",
    "                                nc=4,  # number of classes\n",
    "                                img_size= (416, 416),  # (416, 416)\n",
    "                                yolo_index=0,  # 0, 1, 2...\n",
    "                                layers=[],  # output layers\n",
    "                                stride=16)\n",
    "        \n",
    "      #52X52 yolo layer \n",
    "        self.yolo_52_upsample = nn.Sequential(*_gt_darknet_children(list(range(103,105))))\n",
    "        self.yolo_52_bottle_neck = nn.Conv2d(512, 256, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.yolo_52_path_tail = nn.Sequential(*_gt_darknet_children(list(range(106,113))))\n",
    "        self.yolo_52 = YOLOLayer(anchors=anc_52,  # anchor list\n",
    "                                nc=4,  # number of classes\n",
    "                                img_size= (416, 416),  # (416, 416)\n",
    "                                yolo_index=0,  # 0, 1, 2...\n",
    "                                layers=[],  # output layers\n",
    "                                stride=8)\n",
    "    \n",
    "    def forward(self, EC2,EC3,out):\n",
    "        #yolo 13\n",
    "        out_bn = self.yolo_13_bottle_neck(out)\n",
    "        out_13_path = self.yolo_13_path(out_bn)\n",
    "        out_13_tail = self.yolo_13_tail(out_13_path)\n",
    "        out_13_yolo = self.yolo_13(out_13_tail,[])\n",
    "        #yolo 26\n",
    "        out_26_upsample = self.yolo_26_upsample(out_13_path)\n",
    "        out_EC3_bn = self.yolo_26_bottle_neck(EC3)\n",
    "        out_26_FC = _FeatureConcat([out_26_upsample,out_EC3_bn])\n",
    "        out_26_path = self.yolo_26_path(out_26_FC)\n",
    "        out_26_tail = self.yolo_26_tail(out_26_path)\n",
    "        out_26_yolo = self.yolo_26(out_26_tail,[])\n",
    "        #yolo 52\n",
    "        out_52_upsample = self.yolo_52_upsample(out_26_path)\n",
    "        out_EC2_bn = self.yolo_52_bottle_neck(EC2)\n",
    "        out_52_FC = _FeatureConcat([out_52_upsample,out_EC2_bn])\n",
    "        out_52_tail = self.yolo_52_path_tail(out_52_FC)\n",
    "        out_52_yolo = self.yolo_52(out_52_tail,[])\n",
    "        return out_13_yolo,out_26_yolo,out_52_yolo\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Fork Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final fork model\n",
    "class fork(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(fork,self).__init__()\n",
    "        self.encoder = enc()\n",
    "        self.decoder = depth_decoder(features = 256)\n",
    "        self.yolo_decoder = yolo_decoder()\n",
    "    \n",
    "    def forward(self,x): \n",
    "        EC1, EC2, EC3, out = self.encoder(x)\n",
    "        depth_out = self.decoder(EC1,EC2,EC3,out)\n",
    "        out_13_yolo, out_26_yolo, out_52_yolo = self.yolo_decoder(EC2,EC3,out)\n",
    "        return depth_out, out_13_yolo, out_26_yolo, out_52_yolo\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 208, 208]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 208, 208]             128\n",
      "              ReLU-3         [-1, 64, 208, 208]               0\n",
      "         MaxPool2d-4         [-1, 64, 104, 104]               0\n",
      "            Conv2d-5         [-1, 64, 104, 104]           4,096\n",
      "       BatchNorm2d-6         [-1, 64, 104, 104]             128\n",
      "              ReLU-7         [-1, 64, 104, 104]               0\n",
      "            Conv2d-8         [-1, 64, 104, 104]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 104, 104]             128\n",
      "             ReLU-10         [-1, 64, 104, 104]               0\n",
      "           Conv2d-11        [-1, 256, 104, 104]          16,384\n",
      "      BatchNorm2d-12        [-1, 256, 104, 104]             512\n",
      "           Conv2d-13        [-1, 256, 104, 104]          16,384\n",
      "      BatchNorm2d-14        [-1, 256, 104, 104]             512\n",
      "             ReLU-15        [-1, 256, 104, 104]               0\n",
      "       Bottleneck-16        [-1, 256, 104, 104]               0\n",
      "           Conv2d-17         [-1, 64, 104, 104]          16,384\n",
      "      BatchNorm2d-18         [-1, 64, 104, 104]             128\n",
      "             ReLU-19         [-1, 64, 104, 104]               0\n",
      "           Conv2d-20         [-1, 64, 104, 104]          36,864\n",
      "      BatchNorm2d-21         [-1, 64, 104, 104]             128\n",
      "             ReLU-22         [-1, 64, 104, 104]               0\n",
      "           Conv2d-23        [-1, 256, 104, 104]          16,384\n",
      "      BatchNorm2d-24        [-1, 256, 104, 104]             512\n",
      "             ReLU-25        [-1, 256, 104, 104]               0\n",
      "       Bottleneck-26        [-1, 256, 104, 104]               0\n",
      "           Conv2d-27         [-1, 64, 104, 104]          16,384\n",
      "      BatchNorm2d-28         [-1, 64, 104, 104]             128\n",
      "             ReLU-29         [-1, 64, 104, 104]               0\n",
      "           Conv2d-30         [-1, 64, 104, 104]          36,864\n",
      "      BatchNorm2d-31         [-1, 64, 104, 104]             128\n",
      "             ReLU-32         [-1, 64, 104, 104]               0\n",
      "           Conv2d-33        [-1, 256, 104, 104]          16,384\n",
      "      BatchNorm2d-34        [-1, 256, 104, 104]             512\n",
      "             ReLU-35        [-1, 256, 104, 104]               0\n",
      "       Bottleneck-36        [-1, 256, 104, 104]               0\n",
      "           Conv2d-37        [-1, 128, 104, 104]          32,768\n",
      "      BatchNorm2d-38        [-1, 128, 104, 104]             256\n",
      "             ReLU-39        [-1, 128, 104, 104]               0\n",
      "           Conv2d-40          [-1, 128, 52, 52]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 52, 52]             256\n",
      "             ReLU-42          [-1, 128, 52, 52]               0\n",
      "           Conv2d-43          [-1, 512, 52, 52]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 52, 52]           1,024\n",
      "           Conv2d-45          [-1, 512, 52, 52]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-47          [-1, 512, 52, 52]               0\n",
      "       Bottleneck-48          [-1, 512, 52, 52]               0\n",
      "           Conv2d-49          [-1, 128, 52, 52]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 52, 52]             256\n",
      "             ReLU-51          [-1, 128, 52, 52]               0\n",
      "           Conv2d-52          [-1, 128, 52, 52]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 52, 52]             256\n",
      "             ReLU-54          [-1, 128, 52, 52]               0\n",
      "           Conv2d-55          [-1, 512, 52, 52]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-57          [-1, 512, 52, 52]               0\n",
      "       Bottleneck-58          [-1, 512, 52, 52]               0\n",
      "           Conv2d-59          [-1, 128, 52, 52]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 52, 52]             256\n",
      "             ReLU-61          [-1, 128, 52, 52]               0\n",
      "           Conv2d-62          [-1, 128, 52, 52]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 52, 52]             256\n",
      "             ReLU-64          [-1, 128, 52, 52]               0\n",
      "           Conv2d-65          [-1, 512, 52, 52]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-67          [-1, 512, 52, 52]               0\n",
      "       Bottleneck-68          [-1, 512, 52, 52]               0\n",
      "           Conv2d-69          [-1, 128, 52, 52]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 52, 52]             256\n",
      "             ReLU-71          [-1, 128, 52, 52]               0\n",
      "           Conv2d-72          [-1, 128, 52, 52]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 52, 52]             256\n",
      "             ReLU-74          [-1, 128, 52, 52]               0\n",
      "           Conv2d-75          [-1, 512, 52, 52]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-77          [-1, 512, 52, 52]               0\n",
      "       Bottleneck-78          [-1, 512, 52, 52]               0\n",
      "           Conv2d-79          [-1, 256, 52, 52]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 52, 52]             512\n",
      "             ReLU-81          [-1, 256, 52, 52]               0\n",
      "           Conv2d-82          [-1, 256, 26, 26]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 26, 26]             512\n",
      "             ReLU-84          [-1, 256, 26, 26]               0\n",
      "           Conv2d-85         [-1, 1024, 26, 26]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 26, 26]           2,048\n",
      "           Conv2d-87         [-1, 1024, 26, 26]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 26, 26]           2,048\n",
      "             ReLU-89         [-1, 1024, 26, 26]               0\n",
      "       Bottleneck-90         [-1, 1024, 26, 26]               0\n",
      "           Conv2d-91          [-1, 256, 26, 26]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 26, 26]             512\n",
      "             ReLU-93          [-1, 256, 26, 26]               0\n",
      "           Conv2d-94          [-1, 256, 26, 26]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 26, 26]             512\n",
      "             ReLU-96          [-1, 256, 26, 26]               0\n",
      "           Conv2d-97         [-1, 1024, 26, 26]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 26, 26]           2,048\n",
      "             ReLU-99         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-100         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-101          [-1, 256, 26, 26]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 26, 26]             512\n",
      "            ReLU-103          [-1, 256, 26, 26]               0\n",
      "          Conv2d-104          [-1, 256, 26, 26]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 26, 26]             512\n",
      "            ReLU-106          [-1, 256, 26, 26]               0\n",
      "          Conv2d-107         [-1, 1024, 26, 26]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-109         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-110         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-111          [-1, 256, 26, 26]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 26, 26]             512\n",
      "            ReLU-113          [-1, 256, 26, 26]               0\n",
      "          Conv2d-114          [-1, 256, 26, 26]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 26, 26]             512\n",
      "            ReLU-116          [-1, 256, 26, 26]               0\n",
      "          Conv2d-117         [-1, 1024, 26, 26]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-119         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-120         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-121          [-1, 256, 26, 26]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 26, 26]             512\n",
      "            ReLU-123          [-1, 256, 26, 26]               0\n",
      "          Conv2d-124          [-1, 256, 26, 26]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 26, 26]             512\n",
      "            ReLU-126          [-1, 256, 26, 26]               0\n",
      "          Conv2d-127         [-1, 1024, 26, 26]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-129         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-130         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-131          [-1, 256, 26, 26]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 26, 26]             512\n",
      "            ReLU-133          [-1, 256, 26, 26]               0\n",
      "          Conv2d-134          [-1, 256, 26, 26]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 26, 26]             512\n",
      "            ReLU-136          [-1, 256, 26, 26]               0\n",
      "          Conv2d-137         [-1, 1024, 26, 26]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-139         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-140         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-141          [-1, 512, 26, 26]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 26, 26]           1,024\n",
      "            ReLU-143          [-1, 512, 26, 26]               0\n",
      "          Conv2d-144          [-1, 512, 13, 13]       2,359,296\n",
      "     BatchNorm2d-145          [-1, 512, 13, 13]           1,024\n",
      "            ReLU-146          [-1, 512, 13, 13]               0\n",
      "          Conv2d-147         [-1, 2048, 13, 13]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 2048, 13, 13]           4,096\n",
      "          Conv2d-149         [-1, 2048, 13, 13]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 13, 13]           4,096\n",
      "            ReLU-151         [-1, 2048, 13, 13]               0\n",
      "      Bottleneck-152         [-1, 2048, 13, 13]               0\n",
      "          Conv2d-153          [-1, 512, 13, 13]       1,048,576\n",
      "     BatchNorm2d-154          [-1, 512, 13, 13]           1,024\n",
      "            ReLU-155          [-1, 512, 13, 13]               0\n",
      "          Conv2d-156          [-1, 512, 13, 13]       2,359,296\n",
      "     BatchNorm2d-157          [-1, 512, 13, 13]           1,024\n",
      "            ReLU-158          [-1, 512, 13, 13]               0\n",
      "          Conv2d-159         [-1, 2048, 13, 13]       1,048,576\n",
      "     BatchNorm2d-160         [-1, 2048, 13, 13]           4,096\n",
      "            ReLU-161         [-1, 2048, 13, 13]               0\n",
      "      Bottleneck-162         [-1, 2048, 13, 13]               0\n",
      "          Conv2d-163          [-1, 512, 13, 13]       1,048,576\n",
      "     BatchNorm2d-164          [-1, 512, 13, 13]           1,024\n",
      "            ReLU-165          [-1, 512, 13, 13]               0\n",
      "          Conv2d-166          [-1, 512, 13, 13]       2,359,296\n",
      "     BatchNorm2d-167          [-1, 512, 13, 13]           1,024\n",
      "            ReLU-168          [-1, 512, 13, 13]               0\n",
      "          Conv2d-169         [-1, 2048, 13, 13]       1,048,576\n",
      "     BatchNorm2d-170         [-1, 2048, 13, 13]           4,096\n",
      "            ReLU-171         [-1, 2048, 13, 13]               0\n",
      "      Bottleneck-172         [-1, 2048, 13, 13]               0\n",
      "             enc-173  [[-1, 256, 104, 104], [-1, 512, 52, 52], [-1, 1024, 26, 26], [-1, 2048, 13, 13]]               0\n",
      "          Conv2d-174        [-1, 256, 104, 104]         589,824\n",
      "          Conv2d-175          [-1, 256, 52, 52]       1,179,648\n",
      "          Conv2d-176          [-1, 256, 26, 26]       2,359,296\n",
      "          Conv2d-177          [-1, 256, 13, 13]       4,718,592\n",
      "            ReLU-178          [-1, 256, 13, 13]               0\n",
      "          Conv2d-179          [-1, 256, 13, 13]         590,080\n",
      "            ReLU-180          [-1, 256, 13, 13]               0\n",
      "          Conv2d-181          [-1, 256, 13, 13]         590,080\n",
      "ResidualConvUnit-182          [-1, 256, 13, 13]               0\n",
      "FeatureFusionBlock-183          [-1, 256, 26, 26]               0\n",
      "            ReLU-184          [-1, 256, 26, 26]               0\n",
      "          Conv2d-185          [-1, 256, 26, 26]         590,080\n",
      "            ReLU-186          [-1, 256, 26, 26]               0\n",
      "          Conv2d-187          [-1, 256, 26, 26]         590,080\n",
      "ResidualConvUnit-188          [-1, 256, 26, 26]               0\n",
      "            ReLU-189          [-1, 256, 26, 26]               0\n",
      "          Conv2d-190          [-1, 256, 26, 26]         590,080\n",
      "            ReLU-191          [-1, 256, 26, 26]               0\n",
      "          Conv2d-192          [-1, 256, 26, 26]         590,080\n",
      "ResidualConvUnit-193          [-1, 256, 26, 26]               0\n",
      "FeatureFusionBlock-194          [-1, 256, 52, 52]               0\n",
      "            ReLU-195          [-1, 256, 52, 52]               0\n",
      "          Conv2d-196          [-1, 256, 52, 52]         590,080\n",
      "            ReLU-197          [-1, 256, 52, 52]               0\n",
      "          Conv2d-198          [-1, 256, 52, 52]         590,080\n",
      "ResidualConvUnit-199          [-1, 256, 52, 52]               0\n",
      "            ReLU-200          [-1, 256, 52, 52]               0\n",
      "          Conv2d-201          [-1, 256, 52, 52]         590,080\n",
      "            ReLU-202          [-1, 256, 52, 52]               0\n",
      "          Conv2d-203          [-1, 256, 52, 52]         590,080\n",
      "ResidualConvUnit-204          [-1, 256, 52, 52]               0\n",
      "FeatureFusionBlock-205        [-1, 256, 104, 104]               0\n",
      "            ReLU-206        [-1, 256, 104, 104]               0\n",
      "          Conv2d-207        [-1, 256, 104, 104]         590,080\n",
      "            ReLU-208        [-1, 256, 104, 104]               0\n",
      "          Conv2d-209        [-1, 256, 104, 104]         590,080\n",
      "ResidualConvUnit-210        [-1, 256, 104, 104]               0\n",
      "            ReLU-211        [-1, 256, 104, 104]               0\n",
      "          Conv2d-212        [-1, 256, 104, 104]         590,080\n",
      "            ReLU-213        [-1, 256, 104, 104]               0\n",
      "          Conv2d-214        [-1, 256, 104, 104]         590,080\n",
      "ResidualConvUnit-215        [-1, 256, 104, 104]               0\n",
      "FeatureFusionBlock-216        [-1, 256, 208, 208]               0\n",
      "          Conv2d-217        [-1, 128, 208, 208]         295,040\n",
      "     Interpolate-218        [-1, 128, 416, 416]               0\n",
      "          Conv2d-219         [-1, 32, 416, 416]          36,896\n",
      "            ReLU-220         [-1, 32, 416, 416]               0\n",
      "          Conv2d-221          [-1, 1, 416, 416]              33\n",
      "            ReLU-222          [-1, 1, 416, 416]               0\n",
      "   depth_decoder-223             [-1, 416, 416]               0\n",
      "          Conv2d-224         [-1, 2048, 13, 13]       4,194,304\n",
      "          Conv2d-225          [-1, 512, 13, 13]       1,048,576\n",
      "     BatchNorm2d-226          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-227          [-1, 512, 13, 13]               0\n",
      "          Conv2d-228         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-229         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-230         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-231          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-232          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-233          [-1, 512, 13, 13]               0\n",
      "          Conv2d-234         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-235         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-236         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-237           [-1, 27, 13, 13]          27,675\n",
      "       YOLOLayer-238         [-1, 3, 13, 13, 9]               0\n",
      "          Conv2d-239          [-1, 256, 13, 13]         131,072\n",
      "     BatchNorm2d-240          [-1, 256, 13, 13]             512\n",
      "       LeakyReLU-241          [-1, 256, 13, 13]               0\n",
      "        Upsample-242          [-1, 256, 26, 26]               0\n",
      "          Conv2d-243          [-1, 512, 26, 26]         524,288\n",
      "          Conv2d-244          [-1, 256, 26, 26]         196,608\n",
      "     BatchNorm2d-245          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-246          [-1, 256, 26, 26]               0\n",
      "          Conv2d-247          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-248          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-249          [-1, 512, 26, 26]               0\n",
      "          Conv2d-250          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-251          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-252          [-1, 256, 26, 26]               0\n",
      "          Conv2d-253          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-254          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-255          [-1, 512, 26, 26]               0\n",
      "          Conv2d-256          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-257          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-258          [-1, 256, 26, 26]               0\n",
      "          Conv2d-259          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-260          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-261          [-1, 512, 26, 26]               0\n",
      "          Conv2d-262           [-1, 27, 26, 26]          13,851\n",
      "       YOLOLayer-263         [-1, 3, 26, 26, 9]               0\n",
      "          Conv2d-264          [-1, 128, 26, 26]          32,768\n",
      "     BatchNorm2d-265          [-1, 128, 26, 26]             256\n",
      "       LeakyReLU-266          [-1, 128, 26, 26]               0\n",
      "        Upsample-267          [-1, 128, 52, 52]               0\n",
      "          Conv2d-268          [-1, 256, 52, 52]         131,072\n",
      "          Conv2d-269          [-1, 128, 52, 52]          49,152\n",
      "     BatchNorm2d-270          [-1, 128, 52, 52]             256\n",
      "       LeakyReLU-271          [-1, 128, 52, 52]               0\n",
      "          Conv2d-272          [-1, 256, 52, 52]         294,912\n",
      "     BatchNorm2d-273          [-1, 256, 52, 52]             512\n",
      "       LeakyReLU-274          [-1, 256, 52, 52]               0\n",
      "          Conv2d-275          [-1, 128, 52, 52]          32,768\n",
      "     BatchNorm2d-276          [-1, 128, 52, 52]             256\n",
      "       LeakyReLU-277          [-1, 128, 52, 52]               0\n",
      "          Conv2d-278          [-1, 256, 52, 52]         294,912\n",
      "     BatchNorm2d-279          [-1, 256, 52, 52]             512\n",
      "       LeakyReLU-280          [-1, 256, 52, 52]               0\n",
      "          Conv2d-281          [-1, 128, 52, 52]          32,768\n",
      "     BatchNorm2d-282          [-1, 128, 52, 52]             256\n",
      "       LeakyReLU-283          [-1, 128, 52, 52]               0\n",
      "          Conv2d-284          [-1, 256, 52, 52]         294,912\n",
      "     BatchNorm2d-285          [-1, 256, 52, 52]             512\n",
      "       LeakyReLU-286          [-1, 256, 52, 52]               0\n",
      "          Conv2d-287           [-1, 27, 52, 52]           6,939\n",
      "       YOLOLayer-288         [-1, 3, 52, 52, 9]               0\n",
      "    yolo_decoder-289  [[-1, 3, 13, 13, 9], [-1, 3, 26, 26, 9], [-1, 3, 52, 52, 9]]               0\n",
      "================================================================\n",
      "Total params: 62,031,442\n",
      "Trainable params: 62,031,442\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.98\n",
      "Forward/backward pass size (MB): 7954.80\n",
      "Params size (MB): 236.63\n",
      "Estimated Total Size (MB): 8193.41\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = fork().to(device)\n",
    "from torchsummary import summary\n",
    "print(summary(model, (3,416,416)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\EVA\\JEDI\\MiDas\n"
     ]
    }
   ],
   "source": [
    "cd D:\\ML\\EVA\\JEDI\\MiDas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "image = torch.load('D:/ML/EVA/JEDI/test_image_tensor.pt')\n",
    "image_cuda = image.to(device)\n",
    "model = enc().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model output\n",
    "EC1, EC2, EC3, out = model.forward(image_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64, 104, 104]),\n",
       " torch.Size([1, 128, 52, 52]),\n",
       " torch.Size([1, 256, 26, 26]),\n",
       " torch.Size([1, 512, 13, 13]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EC1.shape, EC2.shape, EC3.shape, out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP/Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\EVA\\JEDi\\Midas\n"
     ]
    }
   ],
   "source": [
    "cd D:/ML/EVA/JEDi/Midas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((549, 976, 3), torch.Size([1, 3, 416, 416]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import utils\n",
    "import cv2\n",
    "\n",
    "from torchvision.transforms import Compose\n",
    "from midas.midas_net import MidasNet\n",
    "from midas.transforms import Resize, NormalizeImage, PrepareForNet\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Resize(\n",
    "            416,\n",
    "            416,\n",
    "            resize_target=None,\n",
    "            keep_aspect_ratio=False,\n",
    "            ensure_multiple_of=32,\n",
    "            resize_method=\"upper_bound\",\n",
    "            image_interpolation_method=cv2.INTER_CUBIC,\n",
    "        ),\n",
    "        NormalizeImage(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        PrepareForNet(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "input_path = 'D:\\ML\\EVA\\JEDI\\MiDaS\\input'\n",
    "img_names = glob.glob(os.path.join(input_path, \"*\"))\n",
    "num_images = len(img_names)\n",
    "\n",
    "img = cv2.imread(img_names[7])\n",
    "img_input = transform({\"image\": img})[\"image\"]\n",
    "image = torch.from_numpy(img_input).unsqueeze(0)\n",
    "img.shape, image.shape\n",
    "#image_cuda = image.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(image, 'D:/ML/EVA/JEDI/test_image_tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(Darknet.modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Sequential(\n",
       "    (Conv2d): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (Conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (Conv2d): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (Conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (4): WeightedFeatureFusion()\n",
       "  (5): Sequential(\n",
       "    (Conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (Conv2d): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (Conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (8): WeightedFeatureFusion()\n",
       "  (9): Sequential(\n",
       "    (Conv2d): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (10): Sequential(\n",
       "    (Conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (11): WeightedFeatureFusion()\n",
       "  (12): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (13): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (14): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (15): WeightedFeatureFusion()\n",
       "  (16): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (17): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (18): WeightedFeatureFusion()\n",
       "  (19): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (20): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (21): WeightedFeatureFusion()\n",
       "  (22): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (23): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (24): WeightedFeatureFusion()\n",
       "  (25): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (26): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (27): WeightedFeatureFusion()\n",
       "  (28): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (29): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (30): WeightedFeatureFusion()\n",
       "  (31): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (32): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (33): WeightedFeatureFusion()\n",
       "  (34): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (35): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (36): WeightedFeatureFusion()\n",
       "  (37): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (38): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (39): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (40): WeightedFeatureFusion()\n",
       "  (41): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (42): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (43): WeightedFeatureFusion()\n",
       "  (44): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (45): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (46): WeightedFeatureFusion()\n",
       "  (47): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (48): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (49): WeightedFeatureFusion()\n",
       "  (50): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (51): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (52): WeightedFeatureFusion()\n",
       "  (53): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (54): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (55): WeightedFeatureFusion()\n",
       "  (56): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (57): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (58): WeightedFeatureFusion()\n",
       "  (59): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (60): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (61): WeightedFeatureFusion()\n",
       "  (62): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (63): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (64): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (65): WeightedFeatureFusion()\n",
       "  (66): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (67): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (68): WeightedFeatureFusion()\n",
       "  (69): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (70): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (71): WeightedFeatureFusion()\n",
       "  (72): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (73): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (74): WeightedFeatureFusion()\n",
       "  (75): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (76): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (77): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (78): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "  (79): FeatureConcat()\n",
       "  (80): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "  (81): FeatureConcat()\n",
       "  (82): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "  (83): FeatureConcat()\n",
       "  (84): Sequential(\n",
       "    (Conv2d): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (85): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (86): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (87): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (88): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (89): YOLOLayer()\n",
       "  (90): FeatureConcat()\n",
       "  (91): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (92): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (93): FeatureConcat()\n",
       "  (94): Sequential(\n",
       "    (Conv2d): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (95): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (96): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (97): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (98): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (99): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (100): Sequential(\n",
       "    (Conv2d): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (101): YOLOLayer()\n",
       "  (102): FeatureConcat()\n",
       "  (103): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (104): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (105): FeatureConcat()\n",
       "  (106): Sequential(\n",
       "    (Conv2d): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (107): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (108): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (109): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (110): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (111): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (112): Sequential(\n",
       "    (Conv2d): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (113): YOLOLayer()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0].module_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\EVA\\JEDI\\YoloV3master\n"
     ]
    }
   ],
   "source": [
    "cd D:/ML/EVA/JEDI/YoloV3master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = 'D:/ML/EVA/JEDI/YoloV3master/cfg/yolov3-custom.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 225 layers, 6.25895e+07 parameters, 6.25895e+07 gradients\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "from utils_yolo.utils import *\n",
    "Darknet = Darknet(cfg)\n",
    "#Darknet = Darknet(cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.ModuleList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 416, 416]             864\n",
      "       BatchNorm2d-2         [-1, 32, 416, 416]              64\n",
      "         LeakyReLU-3         [-1, 32, 416, 416]               0\n",
      "            Conv2d-4         [-1, 64, 208, 208]          18,432\n",
      "       BatchNorm2d-5         [-1, 64, 208, 208]             128\n",
      "         LeakyReLU-6         [-1, 64, 208, 208]               0\n",
      "            Conv2d-7         [-1, 32, 208, 208]           2,048\n",
      "       BatchNorm2d-8         [-1, 32, 208, 208]              64\n",
      "         LeakyReLU-9         [-1, 32, 208, 208]               0\n",
      "           Conv2d-10         [-1, 64, 208, 208]          18,432\n",
      "      BatchNorm2d-11         [-1, 64, 208, 208]             128\n",
      "        LeakyReLU-12         [-1, 64, 208, 208]               0\n",
      "WeightedFeatureFusion-13         [-1, 64, 208, 208]               0\n",
      "           Conv2d-14        [-1, 128, 104, 104]          73,728\n",
      "      BatchNorm2d-15        [-1, 128, 104, 104]             256\n",
      "        LeakyReLU-16        [-1, 128, 104, 104]               0\n",
      "           Conv2d-17         [-1, 64, 104, 104]           8,192\n",
      "      BatchNorm2d-18         [-1, 64, 104, 104]             128\n",
      "        LeakyReLU-19         [-1, 64, 104, 104]               0\n",
      "           Conv2d-20        [-1, 128, 104, 104]          73,728\n",
      "      BatchNorm2d-21        [-1, 128, 104, 104]             256\n",
      "        LeakyReLU-22        [-1, 128, 104, 104]               0\n",
      "WeightedFeatureFusion-23        [-1, 128, 104, 104]               0\n",
      "           Conv2d-24         [-1, 64, 104, 104]           8,192\n",
      "      BatchNorm2d-25         [-1, 64, 104, 104]             128\n",
      "        LeakyReLU-26         [-1, 64, 104, 104]               0\n",
      "           Conv2d-27        [-1, 128, 104, 104]          73,728\n",
      "      BatchNorm2d-28        [-1, 128, 104, 104]             256\n",
      "        LeakyReLU-29        [-1, 128, 104, 104]               0\n",
      "WeightedFeatureFusion-30        [-1, 128, 104, 104]               0\n",
      "           Conv2d-31          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-32          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-33          [-1, 256, 52, 52]               0\n",
      "           Conv2d-34          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-35          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-36          [-1, 128, 52, 52]               0\n",
      "           Conv2d-37          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-38          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-39          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-40          [-1, 256, 52, 52]               0\n",
      "           Conv2d-41          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-42          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-43          [-1, 128, 52, 52]               0\n",
      "           Conv2d-44          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-45          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-46          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-47          [-1, 256, 52, 52]               0\n",
      "           Conv2d-48          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-49          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-50          [-1, 128, 52, 52]               0\n",
      "           Conv2d-51          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-52          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-53          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-54          [-1, 256, 52, 52]               0\n",
      "           Conv2d-55          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-56          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-57          [-1, 128, 52, 52]               0\n",
      "           Conv2d-58          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-59          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-60          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-61          [-1, 256, 52, 52]               0\n",
      "           Conv2d-62          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-63          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-64          [-1, 128, 52, 52]               0\n",
      "           Conv2d-65          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-66          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-67          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-68          [-1, 256, 52, 52]               0\n",
      "           Conv2d-69          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-70          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-71          [-1, 128, 52, 52]               0\n",
      "           Conv2d-72          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-73          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-74          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-75          [-1, 256, 52, 52]               0\n",
      "           Conv2d-76          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-77          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-78          [-1, 128, 52, 52]               0\n",
      "           Conv2d-79          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-80          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-81          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-82          [-1, 256, 52, 52]               0\n",
      "           Conv2d-83          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-84          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-85          [-1, 128, 52, 52]               0\n",
      "           Conv2d-86          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-87          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-88          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-89          [-1, 256, 52, 52]               0\n",
      "           Conv2d-90          [-1, 512, 26, 26]       1,179,648\n",
      "      BatchNorm2d-91          [-1, 512, 26, 26]           1,024\n",
      "        LeakyReLU-92          [-1, 512, 26, 26]               0\n",
      "           Conv2d-93          [-1, 256, 26, 26]         131,072\n",
      "      BatchNorm2d-94          [-1, 256, 26, 26]             512\n",
      "        LeakyReLU-95          [-1, 256, 26, 26]               0\n",
      "           Conv2d-96          [-1, 512, 26, 26]       1,179,648\n",
      "      BatchNorm2d-97          [-1, 512, 26, 26]           1,024\n",
      "        LeakyReLU-98          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-99          [-1, 512, 26, 26]               0\n",
      "          Conv2d-100          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-101          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-102          [-1, 256, 26, 26]               0\n",
      "          Conv2d-103          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-104          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-105          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-106          [-1, 512, 26, 26]               0\n",
      "          Conv2d-107          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-108          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-109          [-1, 256, 26, 26]               0\n",
      "          Conv2d-110          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-111          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-112          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-113          [-1, 512, 26, 26]               0\n",
      "          Conv2d-114          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-115          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-116          [-1, 256, 26, 26]               0\n",
      "          Conv2d-117          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-118          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-119          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-120          [-1, 512, 26, 26]               0\n",
      "          Conv2d-121          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-122          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-123          [-1, 256, 26, 26]               0\n",
      "          Conv2d-124          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-125          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-126          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-127          [-1, 512, 26, 26]               0\n",
      "          Conv2d-128          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-129          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-130          [-1, 256, 26, 26]               0\n",
      "          Conv2d-131          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-132          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-133          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-134          [-1, 512, 26, 26]               0\n",
      "          Conv2d-135          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-136          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-137          [-1, 256, 26, 26]               0\n",
      "          Conv2d-138          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-139          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-140          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-141          [-1, 512, 26, 26]               0\n",
      "          Conv2d-142          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-143          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-144          [-1, 256, 26, 26]               0\n",
      "          Conv2d-145          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-146          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-147          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-148          [-1, 512, 26, 26]               0\n",
      "          Conv2d-149         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-150         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-151         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-152          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-153          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-154          [-1, 512, 13, 13]               0\n",
      "          Conv2d-155         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-156         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-157         [-1, 1024, 13, 13]               0\n",
      "WeightedFeatureFusion-158         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-159          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-160          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-161          [-1, 512, 13, 13]               0\n",
      "          Conv2d-162         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-163         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-164         [-1, 1024, 13, 13]               0\n",
      "WeightedFeatureFusion-165         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-166          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-167          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-168          [-1, 512, 13, 13]               0\n",
      "          Conv2d-169         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-170         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-171         [-1, 1024, 13, 13]               0\n",
      "WeightedFeatureFusion-172         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-173          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-174          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-175          [-1, 512, 13, 13]               0\n",
      "          Conv2d-176         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-177         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-178         [-1, 1024, 13, 13]               0\n",
      "WeightedFeatureFusion-179         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-180          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-181          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-182          [-1, 512, 13, 13]               0\n",
      "          Conv2d-183         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-184         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-185         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-186          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-187          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-188          [-1, 512, 13, 13]               0\n",
      "       MaxPool2d-189          [-1, 512, 13, 13]               0\n",
      "   FeatureConcat-190          [-1, 512, 13, 13]               0\n",
      "       MaxPool2d-191          [-1, 512, 13, 13]               0\n",
      "   FeatureConcat-192          [-1, 512, 13, 13]               0\n",
      "       MaxPool2d-193          [-1, 512, 13, 13]               0\n",
      "   FeatureConcat-194         [-1, 2048, 13, 13]               0\n",
      "          Conv2d-195          [-1, 512, 13, 13]       1,048,576\n",
      "     BatchNorm2d-196          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-197          [-1, 512, 13, 13]               0\n",
      "          Conv2d-198         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-199         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-200         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-201          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-202          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-203          [-1, 512, 13, 13]               0\n",
      "          Conv2d-204         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-205         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-206         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-207          [-1, 255, 13, 13]         261,375\n",
      "       YOLOLayer-208        [-1, 3, 13, 13, 85]               0\n",
      "   FeatureConcat-209          [-1, 512, 13, 13]               0\n",
      "          Conv2d-210          [-1, 256, 13, 13]         131,072\n",
      "     BatchNorm2d-211          [-1, 256, 13, 13]             512\n",
      "       LeakyReLU-212          [-1, 256, 13, 13]               0\n",
      "        Upsample-213          [-1, 256, 26, 26]               0\n",
      "   FeatureConcat-214          [-1, 768, 26, 26]               0\n",
      "          Conv2d-215          [-1, 256, 26, 26]         196,608\n",
      "     BatchNorm2d-216          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-217          [-1, 256, 26, 26]               0\n",
      "          Conv2d-218          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-219          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-220          [-1, 512, 26, 26]               0\n",
      "          Conv2d-221          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-222          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-223          [-1, 256, 26, 26]               0\n",
      "          Conv2d-224          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-225          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-226          [-1, 512, 26, 26]               0\n",
      "          Conv2d-227          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-228          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-229          [-1, 256, 26, 26]               0\n",
      "          Conv2d-230          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-231          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-232          [-1, 512, 26, 26]               0\n",
      "          Conv2d-233          [-1, 255, 26, 26]         130,815\n",
      "       YOLOLayer-234        [-1, 3, 26, 26, 85]               0\n",
      "   FeatureConcat-235          [-1, 256, 26, 26]               0\n",
      "          Conv2d-236          [-1, 128, 26, 26]          32,768\n",
      "     BatchNorm2d-237          [-1, 128, 26, 26]             256\n",
      "       LeakyReLU-238          [-1, 128, 26, 26]               0\n",
      "        Upsample-239          [-1, 128, 52, 52]               0\n",
      "   FeatureConcat-240          [-1, 384, 52, 52]               0\n",
      "          Conv2d-241          [-1, 128, 52, 52]          49,152\n",
      "     BatchNorm2d-242          [-1, 128, 52, 52]             256\n",
      "       LeakyReLU-243          [-1, 128, 52, 52]               0\n",
      "          Conv2d-244          [-1, 256, 52, 52]         294,912\n",
      "     BatchNorm2d-245          [-1, 256, 52, 52]             512\n",
      "       LeakyReLU-246          [-1, 256, 52, 52]               0\n",
      "          Conv2d-247          [-1, 128, 52, 52]          32,768\n",
      "     BatchNorm2d-248          [-1, 128, 52, 52]             256\n",
      "       LeakyReLU-249          [-1, 128, 52, 52]               0\n",
      "          Conv2d-250          [-1, 256, 52, 52]         294,912\n",
      "     BatchNorm2d-251          [-1, 256, 52, 52]             512\n",
      "       LeakyReLU-252          [-1, 256, 52, 52]               0\n",
      "          Conv2d-253          [-1, 128, 52, 52]          32,768\n",
      "     BatchNorm2d-254          [-1, 128, 52, 52]             256\n",
      "       LeakyReLU-255          [-1, 128, 52, 52]               0\n",
      "          Conv2d-256          [-1, 256, 52, 52]         294,912\n",
      "     BatchNorm2d-257          [-1, 256, 52, 52]             512\n",
      "       LeakyReLU-258          [-1, 256, 52, 52]               0\n",
      "          Conv2d-259          [-1, 255, 52, 52]          65,535\n",
      "       YOLOLayer-260        [-1, 3, 52, 52, 85]               0\n",
      "================================================================\n",
      "Total params: 62,998,749\n",
      "Trainable params: 62,998,749\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.98\n",
      "Forward/backward pass size (MB): 1026.82\n",
      "Params size (MB): 240.32\n",
      "Estimated Total Size (MB): 1269.12\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "print(summary(model, (3,416,416)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True),\n",
       " LeakyReLU(negative_slope=0.1, inplace=True)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(list(vgg_model.children())), len(list(Darknet.children()))\n",
    "#list(list(Darknet.children())[0][0].children())\n",
    "#list(Darknet.children())[0][1]\n",
    "def _gt_darknet_child(x):\n",
    "    if isinstance(list(Darknet.children())[0][x], nn.Sequential):\n",
    "        return list(list(Darknet.children())[0][x].children())\n",
    "    else: \n",
    "        temp = []\n",
    "        temp.append(list(Darknet.children())[0][x])\n",
    "        return temp\n",
    "    \n",
    "def _gt_darknet_children(l):\n",
    "    layer_list = []\n",
    "    for x in l: \n",
    "        layer_list.extend(_gt_darknet_child(x))\n",
    "    return layer_list\n",
    "    \n",
    "        \n",
    "_gt_darknet_child(99)\n",
    "#_gt_darknet_children(list(range(84,89)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = \"10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\"\n",
    "k = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[6,7,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class yolo_decoder(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(yolo_decoder, self).__init__()\n",
    "        #anchors for 13x13, 26X26, 52X52\n",
    "        val = \"10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\"\n",
    "        anc_13 = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[6,7,8]]\n",
    "        anc_26 = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[3,4,5]]\n",
    "        anc_52 = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[0,1,2]]\n",
    "        #13x13 yolo layer\n",
    "        self.yolo_13_bottle_neck = nn.Conv2d(2048, 2048, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.yolo_13_path = nn.Sequential(*_gt_darknet_children(list(range(84,87))))\n",
    "        self.yolo_13_tail = nn.Sequential(*_gt_darknet_children(list(range(87,89))))\n",
    "        self.yolo_13 = YOLOLayer(anchors=anc_13,  # anchor list\n",
    "                                nc=4,  # number of classes\n",
    "                                img_size= (416, 416),  # (416, 416)\n",
    "                                yolo_index=0,  # 0, 1, 2...\n",
    "                                layers=[],  # output layers\n",
    "                                stride=32)\n",
    "        #26x26 yolo layer\n",
    "        self.yolo_26_upsample = nn.Sequential(*_gt_darknet_children(list(range(91,93))))\n",
    "        self.yolo_26_bottle_neck = nn.Conv2d(1024, 512, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.yolo_26_path =  nn.Sequential(*_gt_darknet_children(list(range(94,99))))\n",
    "        self.yolo_26_tail = nn.Sequential(*_gt_darknet_children(list(range(99,101))))\n",
    "        self.yolo_26 = YOLOLayer(anchors=anc_26,  # anchor list\n",
    "                                nc=4,  # number of classes\n",
    "                                img_size= (416, 416),  # (416, 416)\n",
    "                                yolo_index=0,  # 0, 1, 2...\n",
    "                                layers=[],  # output layers\n",
    "                                stride=16)\n",
    "        \n",
    "      #52X52 yolo layer \n",
    "        self.yolo_52_upsample = nn.Sequential(*_gt_darknet_children(list(range(103,105))))\n",
    "        self.yolo_52_bottle_neck = nn.Conv2d(512, 256, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.yolo_52_path_tail = nn.Sequential(*_gt_darknet_children(list(range(106,113))))\n",
    "        self.yolo_52 = YOLOLayer(anchors=anc_52,  # anchor list\n",
    "                                nc=4,  # number of classes\n",
    "                                img_size= (416, 416),  # (416, 416)\n",
    "                                yolo_index=0,  # 0, 1, 2...\n",
    "                                layers=[],  # output layers\n",
    "                                stride=8)\n",
    "    \n",
    "    def forward(self, out, EC3, EC2):\n",
    "        #yolo 13\n",
    "        out_bn = self.yolo_13_bottle_neck(out)\n",
    "        out_13_path = self.yolo_13_path(out_bn)\n",
    "        out_13_tail = self.yolo_13_tail(out_13_path)\n",
    "        out_13_yolo = self.yolo_13(out_13_tail,[])\n",
    "        #yolo 26\n",
    "        out_26_upsample = self.yolo_26_upsample(out_13_path)\n",
    "        out_EC3_bn = self.yolo_26_bottle_neck(EC3)\n",
    "        out_26_FC = _FeatureConcat([out_26_upsample,out_EC3_bn])\n",
    "        out_26_path = self.yolo_26_path(out_26_FC)\n",
    "        out_26_tail = self.yolo_26_tail(out_26_path)\n",
    "        out_26_yolo = self.yolo_26(out_26_tail,[])\n",
    "        #yolo 52\n",
    "        out_52_upsample = self.yolo_52_upsample(out_26_path)\n",
    "        out_EC2_bn = self.yolo_52_bottle_neck(EC2)\n",
    "        out_52_FC = _FeatureConcat([out_52_upsample,out_EC2_bn])\n",
    "        out_52_tail = self.yolo_52_path_tail(out_52_FC)\n",
    "        out_52_yolo = self.yolo_52(out_52_tail,[])\n",
    "        return out_13_yolo,out_26_yolo,out_52_yolo\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 52, 52, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo_test = yolo_decoder().to(device)\n",
    "yolo_test.forward(out,EC3, EC2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 13, 13])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.modules at 0x0000026BB9D3E0C8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model = torchvision.models.vgg16(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (Conv2d): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "  (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Darknet.children())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#isinstance(list(Darknet.children())[0][77], nn.Sequential)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
