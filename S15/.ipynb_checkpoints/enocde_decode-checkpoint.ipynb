{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnext Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\EVA\\JEDi\\Midas\n"
     ]
    }
   ],
   "source": [
    "cd D:/ML/EVA/JEDi/Midas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import utils\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Compose\n",
    "#from midas.midas_net import MidasNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_resnet_backbone(resnet):\n",
    "    pretrained = nn.Module()\n",
    "    pretrained.layer1 = nn.Sequential(\n",
    "        resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool, resnet.layer1\n",
    "    )\n",
    "\n",
    "    pretrained.layer2 = resnet.layer2\n",
    "    pretrained.layer3 = resnet.layer3\n",
    "    pretrained.layer4 = resnet.layer4\n",
    "\n",
    "    return pretrained\n",
    "\n",
    "\n",
    "def _make_pretrained_resnet(use_pretrained = False):\n",
    "    resnet = torch.hub.load(\"facebookresearch/WSL-Images\", \"resnext101_32x8d_wsl\")\n",
    "    #resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=use_pretrained)\n",
    "    return _make_resnet_backbone(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class enc(nn.Module):\n",
    "    def __init__(self,preload = True, prelaod_pt = 'D:/ML/EVA/JEDi/Midas/model-f46da743.pt', freeze = True): \n",
    "        super(enc,self).__init__()\n",
    "        resnet101 = _make_pretrained_resnet(use_pretrained = False)\n",
    "        if preload:\n",
    "            checkpoint = torch.load(prelaod_pt)\n",
    "            dl_list = [\"pretrained.layer1.0.weight\", \"pretrained.layer1.1.weight\", \"pretrained.layer1.1.bias\", \"pretrained.layer1.1.running_mean\", \"pretrained.layer1.1.running_var\", \"pretrained.layer1.1.num_batches_tracked\", \"pretrained.layer1.4.0.conv1.weight\", \"pretrained.layer1.4.0.bn1.weight\", \"pretrained.layer1.4.0.bn1.bias\", \"pretrained.layer1.4.0.bn1.running_mean\", \"pretrained.layer1.4.0.bn1.running_var\", \"pretrained.layer1.4.0.bn1.num_batches_tracked\", \"pretrained.layer1.4.0.conv2.weight\", \"pretrained.layer1.4.0.bn2.weight\", \"pretrained.layer1.4.0.bn2.bias\", \"pretrained.layer1.4.0.bn2.running_mean\", \"pretrained.layer1.4.0.bn2.running_var\", \"pretrained.layer1.4.0.bn2.num_batches_tracked\", \"pretrained.layer1.4.0.conv3.weight\", \"pretrained.layer1.4.0.bn3.weight\", \"pretrained.layer1.4.0.bn3.bias\", \"pretrained.layer1.4.0.bn3.running_mean\", \"pretrained.layer1.4.0.bn3.running_var\", \"pretrained.layer1.4.0.bn3.num_batches_tracked\", \"pretrained.layer1.4.0.downsample.0.weight\", \"pretrained.layer1.4.0.downsample.1.weight\", \"pretrained.layer1.4.0.downsample.1.bias\", \"pretrained.layer1.4.0.downsample.1.running_mean\", \"pretrained.layer1.4.0.downsample.1.running_var\", \"pretrained.layer1.4.0.downsample.1.num_batches_tracked\", \"pretrained.layer1.4.1.conv1.weight\", \"pretrained.layer1.4.1.bn1.weight\", \"pretrained.layer1.4.1.bn1.bias\", \"pretrained.layer1.4.1.bn1.running_mean\", \"pretrained.layer1.4.1.bn1.running_var\", \"pretrained.layer1.4.1.bn1.num_batches_tracked\", \"pretrained.layer1.4.1.conv2.weight\", \"pretrained.layer1.4.1.bn2.weight\", \"pretrained.layer1.4.1.bn2.bias\", \"pretrained.layer1.4.1.bn2.running_mean\", \"pretrained.layer1.4.1.bn2.running_var\", \"pretrained.layer1.4.1.bn2.num_batches_tracked\", \"pretrained.layer1.4.1.conv3.weight\", \"pretrained.layer1.4.1.bn3.weight\", \"pretrained.layer1.4.1.bn3.bias\", \"pretrained.layer1.4.1.bn3.running_mean\", \"pretrained.layer1.4.1.bn3.running_var\", \"pretrained.layer1.4.1.bn3.num_batches_tracked\", \"pretrained.layer1.4.2.conv1.weight\", \"pretrained.layer1.4.2.bn1.weight\", \"pretrained.layer1.4.2.bn1.bias\", \"pretrained.layer1.4.2.bn1.running_mean\", \"pretrained.layer1.4.2.bn1.running_var\", \"pretrained.layer1.4.2.bn1.num_batches_tracked\", \"pretrained.layer1.4.2.conv2.weight\", \"pretrained.layer1.4.2.bn2.weight\", \"pretrained.layer1.4.2.bn2.bias\", \"pretrained.layer1.4.2.bn2.running_mean\", \"pretrained.layer1.4.2.bn2.running_var\", \"pretrained.layer1.4.2.bn2.num_batches_tracked\", \"pretrained.layer1.4.2.conv3.weight\", \"pretrained.layer1.4.2.bn3.weight\", \"pretrained.layer1.4.2.bn3.bias\", \"pretrained.layer1.4.2.bn3.running_mean\", \"pretrained.layer1.4.2.bn3.running_var\", \"pretrained.layer1.4.2.bn3.num_batches_tracked\", \"pretrained.layer2.0.conv1.weight\", \"pretrained.layer2.0.bn1.weight\", \"pretrained.layer2.0.bn1.bias\", \"pretrained.layer2.0.bn1.running_mean\", \"pretrained.layer2.0.bn1.running_var\", \"pretrained.layer2.0.bn1.num_batches_tracked\", \"pretrained.layer2.0.conv2.weight\", \"pretrained.layer2.0.bn2.weight\", \"pretrained.layer2.0.bn2.bias\", \"pretrained.layer2.0.bn2.running_mean\", \"pretrained.layer2.0.bn2.running_var\", \"pretrained.layer2.0.bn2.num_batches_tracked\", \"pretrained.layer2.0.conv3.weight\", \"pretrained.layer2.0.bn3.weight\", \"pretrained.layer2.0.bn3.bias\", \"pretrained.layer2.0.bn3.running_mean\", \"pretrained.layer2.0.bn3.running_var\", \"pretrained.layer2.0.bn3.num_batches_tracked\", \"pretrained.layer2.0.downsample.0.weight\", \"pretrained.layer2.0.downsample.1.weight\", \"pretrained.layer2.0.downsample.1.bias\", \"pretrained.layer2.0.downsample.1.running_mean\", \"pretrained.layer2.0.downsample.1.running_var\", \"pretrained.layer2.0.downsample.1.num_batches_tracked\", \"pretrained.layer2.1.conv1.weight\", \"pretrained.layer2.1.bn1.weight\", \"pretrained.layer2.1.bn1.bias\", \"pretrained.layer2.1.bn1.running_mean\", \"pretrained.layer2.1.bn1.running_var\", \"pretrained.layer2.1.bn1.num_batches_tracked\", \"pretrained.layer2.1.conv2.weight\", \"pretrained.layer2.1.bn2.weight\", \"pretrained.layer2.1.bn2.bias\", \"pretrained.layer2.1.bn2.running_mean\", \"pretrained.layer2.1.bn2.running_var\", \"pretrained.layer2.1.bn2.num_batches_tracked\", \"pretrained.layer2.1.conv3.weight\", \"pretrained.layer2.1.bn3.weight\", \"pretrained.layer2.1.bn3.bias\", \"pretrained.layer2.1.bn3.running_mean\", \"pretrained.layer2.1.bn3.running_var\", \"pretrained.layer2.1.bn3.num_batches_tracked\", \"pretrained.layer2.2.conv1.weight\", \"pretrained.layer2.2.bn1.weight\", \"pretrained.layer2.2.bn1.bias\", \"pretrained.layer2.2.bn1.running_mean\", \"pretrained.layer2.2.bn1.running_var\", \"pretrained.layer2.2.bn1.num_batches_tracked\", \"pretrained.layer2.2.conv2.weight\", \"pretrained.layer2.2.bn2.weight\", \"pretrained.layer2.2.bn2.bias\", \"pretrained.layer2.2.bn2.running_mean\", \"pretrained.layer2.2.bn2.running_var\", \"pretrained.layer2.2.bn2.num_batches_tracked\", \"pretrained.layer2.2.conv3.weight\", \"pretrained.layer2.2.bn3.weight\", \"pretrained.layer2.2.bn3.bias\", \"pretrained.layer2.2.bn3.running_mean\", \"pretrained.layer2.2.bn3.running_var\", \"pretrained.layer2.2.bn3.num_batches_tracked\", \"pretrained.layer2.3.conv1.weight\", \"pretrained.layer2.3.bn1.weight\", \"pretrained.layer2.3.bn1.bias\", \"pretrained.layer2.3.bn1.running_mean\", \"pretrained.layer2.3.bn1.running_var\", \"pretrained.layer2.3.bn1.num_batches_tracked\", \"pretrained.layer2.3.conv2.weight\", \"pretrained.layer2.3.bn2.weight\", \"pretrained.layer2.3.bn2.bias\", \"pretrained.layer2.3.bn2.running_mean\", \"pretrained.layer2.3.bn2.running_var\", \"pretrained.layer2.3.bn2.num_batches_tracked\", \"pretrained.layer2.3.conv3.weight\", \"pretrained.layer2.3.bn3.weight\", \"pretrained.layer2.3.bn3.bias\", \"pretrained.layer2.3.bn3.running_mean\", \"pretrained.layer2.3.bn3.running_var\", \"pretrained.layer2.3.bn3.num_batches_tracked\", \"pretrained.layer3.0.conv1.weight\", \"pretrained.layer3.0.bn1.weight\", \"pretrained.layer3.0.bn1.bias\", \"pretrained.layer3.0.bn1.running_mean\", \"pretrained.layer3.0.bn1.running_var\", \"pretrained.layer3.0.bn1.num_batches_tracked\", \"pretrained.layer3.0.conv2.weight\", \"pretrained.layer3.0.bn2.weight\", \"pretrained.layer3.0.bn2.bias\", \"pretrained.layer3.0.bn2.running_mean\", \"pretrained.layer3.0.bn2.running_var\", \"pretrained.layer3.0.bn2.num_batches_tracked\", \"pretrained.layer3.0.conv3.weight\", \"pretrained.layer3.0.bn3.weight\", \"pretrained.layer3.0.bn3.bias\", \"pretrained.layer3.0.bn3.running_mean\", \"pretrained.layer3.0.bn3.running_var\", \"pretrained.layer3.0.bn3.num_batches_tracked\", \"pretrained.layer3.0.downsample.0.weight\", \"pretrained.layer3.0.downsample.1.weight\", \"pretrained.layer3.0.downsample.1.bias\", \"pretrained.layer3.0.downsample.1.running_mean\", \"pretrained.layer3.0.downsample.1.running_var\", \"pretrained.layer3.0.downsample.1.num_batches_tracked\", \"pretrained.layer3.1.conv1.weight\", \"pretrained.layer3.1.bn1.weight\", \"pretrained.layer3.1.bn1.bias\", \"pretrained.layer3.1.bn1.running_mean\", \"pretrained.layer3.1.bn1.running_var\", \"pretrained.layer3.1.bn1.num_batches_tracked\", \"pretrained.layer3.1.conv2.weight\", \"pretrained.layer3.1.bn2.weight\", \"pretrained.layer3.1.bn2.bias\", \"pretrained.layer3.1.bn2.running_mean\", \"pretrained.layer3.1.bn2.running_var\", \"pretrained.layer3.1.bn2.num_batches_tracked\", \"pretrained.layer3.1.conv3.weight\", \"pretrained.layer3.1.bn3.weight\", \"pretrained.layer3.1.bn3.bias\", \"pretrained.layer3.1.bn3.running_mean\", \"pretrained.layer3.1.bn3.running_var\", \"pretrained.layer3.1.bn3.num_batches_tracked\", \"pretrained.layer3.2.conv1.weight\", \"pretrained.layer3.2.bn1.weight\", \"pretrained.layer3.2.bn1.bias\", \"pretrained.layer3.2.bn1.running_mean\", \"pretrained.layer3.2.bn1.running_var\", \"pretrained.layer3.2.bn1.num_batches_tracked\", \"pretrained.layer3.2.conv2.weight\", \"pretrained.layer3.2.bn2.weight\", \"pretrained.layer3.2.bn2.bias\", \"pretrained.layer3.2.bn2.running_mean\", \"pretrained.layer3.2.bn2.running_var\", \"pretrained.layer3.2.bn2.num_batches_tracked\", \"pretrained.layer3.2.conv3.weight\", \"pretrained.layer3.2.bn3.weight\", \"pretrained.layer3.2.bn3.bias\", \"pretrained.layer3.2.bn3.running_mean\", \"pretrained.layer3.2.bn3.running_var\", \"pretrained.layer3.2.bn3.num_batches_tracked\", \"pretrained.layer3.3.conv1.weight\", \"pretrained.layer3.3.bn1.weight\", \"pretrained.layer3.3.bn1.bias\", \"pretrained.layer3.3.bn1.running_mean\", \"pretrained.layer3.3.bn1.running_var\", \"pretrained.layer3.3.bn1.num_batches_tracked\", \"pretrained.layer3.3.conv2.weight\", \"pretrained.layer3.3.bn2.weight\", \"pretrained.layer3.3.bn2.bias\", \"pretrained.layer3.3.bn2.running_mean\", \"pretrained.layer3.3.bn2.running_var\", \"pretrained.layer3.3.bn2.num_batches_tracked\", \"pretrained.layer3.3.conv3.weight\", \"pretrained.layer3.3.bn3.weight\", \"pretrained.layer3.3.bn3.bias\", \"pretrained.layer3.3.bn3.running_mean\", \"pretrained.layer3.3.bn3.running_var\", \"pretrained.layer3.3.bn3.num_batches_tracked\", \"pretrained.layer3.4.conv1.weight\", \"pretrained.layer3.4.bn1.weight\", \"pretrained.layer3.4.bn1.bias\", \"pretrained.layer3.4.bn1.running_mean\", \"pretrained.layer3.4.bn1.running_var\", \"pretrained.layer3.4.bn1.num_batches_tracked\", \"pretrained.layer3.4.conv2.weight\", \"pretrained.layer3.4.bn2.weight\", \"pretrained.layer3.4.bn2.bias\", \"pretrained.layer3.4.bn2.running_mean\", \"pretrained.layer3.4.bn2.running_var\", \"pretrained.layer3.4.bn2.num_batches_tracked\", \"pretrained.layer3.4.conv3.weight\", \"pretrained.layer3.4.bn3.weight\", \"pretrained.layer3.4.bn3.bias\", \"pretrained.layer3.4.bn3.running_mean\", \"pretrained.layer3.4.bn3.running_var\", \"pretrained.layer3.4.bn3.num_batches_tracked\", \"pretrained.layer3.5.conv1.weight\", \"pretrained.layer3.5.bn1.weight\", \"pretrained.layer3.5.bn1.bias\", \"pretrained.layer3.5.bn1.running_mean\", \"pretrained.layer3.5.bn1.running_var\", \"pretrained.layer3.5.bn1.num_batches_tracked\", \"pretrained.layer3.5.conv2.weight\", \"pretrained.layer3.5.bn2.weight\", \"pretrained.layer3.5.bn2.bias\", \"pretrained.layer3.5.bn2.running_mean\", \"pretrained.layer3.5.bn2.running_var\", \"pretrained.layer3.5.bn2.num_batches_tracked\", \"pretrained.layer3.5.conv3.weight\", \"pretrained.layer3.5.bn3.weight\", \"pretrained.layer3.5.bn3.bias\", \"pretrained.layer3.5.bn3.running_mean\", \"pretrained.layer3.5.bn3.running_var\", \"pretrained.layer3.5.bn3.num_batches_tracked\", \"pretrained.layer3.6.conv1.weight\", \"pretrained.layer3.6.bn1.weight\", \"pretrained.layer3.6.bn1.bias\", \"pretrained.layer3.6.bn1.running_mean\", \"pretrained.layer3.6.bn1.running_var\", \"pretrained.layer3.6.bn1.num_batches_tracked\", \"pretrained.layer3.6.conv2.weight\", \"pretrained.layer3.6.bn2.weight\", \"pretrained.layer3.6.bn2.bias\", \"pretrained.layer3.6.bn2.running_mean\", \"pretrained.layer3.6.bn2.running_var\", \"pretrained.layer3.6.bn2.num_batches_tracked\", \"pretrained.layer3.6.conv3.weight\", \"pretrained.layer3.6.bn3.weight\", \"pretrained.layer3.6.bn3.bias\", \"pretrained.layer3.6.bn3.running_mean\", \"pretrained.layer3.6.bn3.running_var\", \"pretrained.layer3.6.bn3.num_batches_tracked\", \"pretrained.layer3.7.conv1.weight\", \"pretrained.layer3.7.bn1.weight\", \"pretrained.layer3.7.bn1.bias\", \"pretrained.layer3.7.bn1.running_mean\", \"pretrained.layer3.7.bn1.running_var\", \"pretrained.layer3.7.bn1.num_batches_tracked\", \"pretrained.layer3.7.conv2.weight\", \"pretrained.layer3.7.bn2.weight\", \"pretrained.layer3.7.bn2.bias\", \"pretrained.layer3.7.bn2.running_mean\", \"pretrained.layer3.7.bn2.running_var\", \"pretrained.layer3.7.bn2.num_batches_tracked\", \"pretrained.layer3.7.conv3.weight\", \"pretrained.layer3.7.bn3.weight\", \"pretrained.layer3.7.bn3.bias\", \"pretrained.layer3.7.bn3.running_mean\", \"pretrained.layer3.7.bn3.running_var\", \"pretrained.layer3.7.bn3.num_batches_tracked\", \"pretrained.layer3.8.conv1.weight\", \"pretrained.layer3.8.bn1.weight\", \"pretrained.layer3.8.bn1.bias\", \"pretrained.layer3.8.bn1.running_mean\", \"pretrained.layer3.8.bn1.running_var\", \"pretrained.layer3.8.bn1.num_batches_tracked\", \"pretrained.layer3.8.conv2.weight\", \"pretrained.layer3.8.bn2.weight\", \"pretrained.layer3.8.bn2.bias\", \"pretrained.layer3.8.bn2.running_mean\", \"pretrained.layer3.8.bn2.running_var\", \"pretrained.layer3.8.bn2.num_batches_tracked\", \"pretrained.layer3.8.conv3.weight\", \"pretrained.layer3.8.bn3.weight\", \"pretrained.layer3.8.bn3.bias\", \"pretrained.layer3.8.bn3.running_mean\", \"pretrained.layer3.8.bn3.running_var\", \"pretrained.layer3.8.bn3.num_batches_tracked\", \"pretrained.layer3.9.conv1.weight\", \"pretrained.layer3.9.bn1.weight\", \"pretrained.layer3.9.bn1.bias\", \"pretrained.layer3.9.bn1.running_mean\", \"pretrained.layer3.9.bn1.running_var\", \"pretrained.layer3.9.bn1.num_batches_tracked\", \"pretrained.layer3.9.conv2.weight\", \"pretrained.layer3.9.bn2.weight\", \"pretrained.layer3.9.bn2.bias\", \"pretrained.layer3.9.bn2.running_mean\", \"pretrained.layer3.9.bn2.running_var\", \"pretrained.layer3.9.bn2.num_batches_tracked\", \"pretrained.layer3.9.conv3.weight\", \"pretrained.layer3.9.bn3.weight\", \"pretrained.layer3.9.bn3.bias\", \"pretrained.layer3.9.bn3.running_mean\", \"pretrained.layer3.9.bn3.running_var\", \"pretrained.layer3.9.bn3.num_batches_tracked\", \"pretrained.layer3.10.conv1.weight\", \"pretrained.layer3.10.bn1.weight\", \"pretrained.layer3.10.bn1.bias\", \"pretrained.layer3.10.bn1.running_mean\", \"pretrained.layer3.10.bn1.running_var\", \"pretrained.layer3.10.bn1.num_batches_tracked\", \"pretrained.layer3.10.conv2.weight\", \"pretrained.layer3.10.bn2.weight\", \"pretrained.layer3.10.bn2.bias\", \"pretrained.layer3.10.bn2.running_mean\", \"pretrained.layer3.10.bn2.running_var\", \"pretrained.layer3.10.bn2.num_batches_tracked\", \"pretrained.layer3.10.conv3.weight\", \"pretrained.layer3.10.bn3.weight\", \"pretrained.layer3.10.bn3.bias\", \"pretrained.layer3.10.bn3.running_mean\", \"pretrained.layer3.10.bn3.running_var\", \"pretrained.layer3.10.bn3.num_batches_tracked\", \"pretrained.layer3.11.conv1.weight\", \"pretrained.layer3.11.bn1.weight\", \"pretrained.layer3.11.bn1.bias\", \"pretrained.layer3.11.bn1.running_mean\", \"pretrained.layer3.11.bn1.running_var\", \"pretrained.layer3.11.bn1.num_batches_tracked\", \"pretrained.layer3.11.conv2.weight\", \"pretrained.layer3.11.bn2.weight\", \"pretrained.layer3.11.bn2.bias\", \"pretrained.layer3.11.bn2.running_mean\", \"pretrained.layer3.11.bn2.running_var\", \"pretrained.layer3.11.bn2.num_batches_tracked\", \"pretrained.layer3.11.conv3.weight\", \"pretrained.layer3.11.bn3.weight\", \"pretrained.layer3.11.bn3.bias\", \"pretrained.layer3.11.bn3.running_mean\", \"pretrained.layer3.11.bn3.running_var\", \"pretrained.layer3.11.bn3.num_batches_tracked\", \"pretrained.layer3.12.conv1.weight\", \"pretrained.layer3.12.bn1.weight\", \"pretrained.layer3.12.bn1.bias\", \"pretrained.layer3.12.bn1.running_mean\", \"pretrained.layer3.12.bn1.running_var\", \"pretrained.layer3.12.bn1.num_batches_tracked\", \"pretrained.layer3.12.conv2.weight\", \"pretrained.layer3.12.bn2.weight\", \"pretrained.layer3.12.bn2.bias\", \"pretrained.layer3.12.bn2.running_mean\", \"pretrained.layer3.12.bn2.running_var\", \"pretrained.layer3.12.bn2.num_batches_tracked\", \"pretrained.layer3.12.conv3.weight\", \"pretrained.layer3.12.bn3.weight\", \"pretrained.layer3.12.bn3.bias\", \"pretrained.layer3.12.bn3.running_mean\", \"pretrained.layer3.12.bn3.running_var\", \"pretrained.layer3.12.bn3.num_batches_tracked\", \"pretrained.layer3.13.conv1.weight\", \"pretrained.layer3.13.bn1.weight\", \"pretrained.layer3.13.bn1.bias\", \"pretrained.layer3.13.bn1.running_mean\", \"pretrained.layer3.13.bn1.running_var\", \"pretrained.layer3.13.bn1.num_batches_tracked\", \"pretrained.layer3.13.conv2.weight\", \"pretrained.layer3.13.bn2.weight\", \"pretrained.layer3.13.bn2.bias\", \"pretrained.layer3.13.bn2.running_mean\", \"pretrained.layer3.13.bn2.running_var\", \"pretrained.layer3.13.bn2.num_batches_tracked\", \"pretrained.layer3.13.conv3.weight\", \"pretrained.layer3.13.bn3.weight\", \"pretrained.layer3.13.bn3.bias\", \"pretrained.layer3.13.bn3.running_mean\", \"pretrained.layer3.13.bn3.running_var\", \"pretrained.layer3.13.bn3.num_batches_tracked\", \"pretrained.layer3.14.conv1.weight\", \"pretrained.layer3.14.bn1.weight\", \"pretrained.layer3.14.bn1.bias\", \"pretrained.layer3.14.bn1.running_mean\", \"pretrained.layer3.14.bn1.running_var\", \"pretrained.layer3.14.bn1.num_batches_tracked\", \"pretrained.layer3.14.conv2.weight\", \"pretrained.layer3.14.bn2.weight\", \"pretrained.layer3.14.bn2.bias\", \"pretrained.layer3.14.bn2.running_mean\", \"pretrained.layer3.14.bn2.running_var\", \"pretrained.layer3.14.bn2.num_batches_tracked\", \"pretrained.layer3.14.conv3.weight\", \"pretrained.layer3.14.bn3.weight\", \"pretrained.layer3.14.bn3.bias\", \"pretrained.layer3.14.bn3.running_mean\", \"pretrained.layer3.14.bn3.running_var\", \"pretrained.layer3.14.bn3.num_batches_tracked\", \"pretrained.layer3.15.conv1.weight\", \"pretrained.layer3.15.bn1.weight\", \"pretrained.layer3.15.bn1.bias\", \"pretrained.layer3.15.bn1.running_mean\", \"pretrained.layer3.15.bn1.running_var\", \"pretrained.layer3.15.bn1.num_batches_tracked\", \"pretrained.layer3.15.conv2.weight\", \"pretrained.layer3.15.bn2.weight\", \"pretrained.layer3.15.bn2.bias\", \"pretrained.layer3.15.bn2.running_mean\", \"pretrained.layer3.15.bn2.running_var\", \"pretrained.layer3.15.bn2.num_batches_tracked\", \"pretrained.layer3.15.conv3.weight\", \"pretrained.layer3.15.bn3.weight\", \"pretrained.layer3.15.bn3.bias\", \"pretrained.layer3.15.bn3.running_mean\", \"pretrained.layer3.15.bn3.running_var\", \"pretrained.layer3.15.bn3.num_batches_tracked\", \"pretrained.layer3.16.conv1.weight\", \"pretrained.layer3.16.bn1.weight\", \"pretrained.layer3.16.bn1.bias\", \"pretrained.layer3.16.bn1.running_mean\", \"pretrained.layer3.16.bn1.running_var\", \"pretrained.layer3.16.bn1.num_batches_tracked\", \"pretrained.layer3.16.conv2.weight\", \"pretrained.layer3.16.bn2.weight\", \"pretrained.layer3.16.bn2.bias\", \"pretrained.layer3.16.bn2.running_mean\", \"pretrained.layer3.16.bn2.running_var\", \"pretrained.layer3.16.bn2.num_batches_tracked\", \"pretrained.layer3.16.conv3.weight\", \"pretrained.layer3.16.bn3.weight\", \"pretrained.layer3.16.bn3.bias\", \"pretrained.layer3.16.bn3.running_mean\", \"pretrained.layer3.16.bn3.running_var\", \"pretrained.layer3.16.bn3.num_batches_tracked\", \"pretrained.layer3.17.conv1.weight\", \"pretrained.layer3.17.bn1.weight\", \"pretrained.layer3.17.bn1.bias\", \"pretrained.layer3.17.bn1.running_mean\", \"pretrained.layer3.17.bn1.running_var\", \"pretrained.layer3.17.bn1.num_batches_tracked\", \"pretrained.layer3.17.conv2.weight\", \"pretrained.layer3.17.bn2.weight\", \"pretrained.layer3.17.bn2.bias\", \"pretrained.layer3.17.bn2.running_mean\", \"pretrained.layer3.17.bn2.running_var\", \"pretrained.layer3.17.bn2.num_batches_tracked\", \"pretrained.layer3.17.conv3.weight\", \"pretrained.layer3.17.bn3.weight\", \"pretrained.layer3.17.bn3.bias\", \"pretrained.layer3.17.bn3.running_mean\", \"pretrained.layer3.17.bn3.running_var\", \"pretrained.layer3.17.bn3.num_batches_tracked\", \"pretrained.layer3.18.conv1.weight\", \"pretrained.layer3.18.bn1.weight\", \"pretrained.layer3.18.bn1.bias\", \"pretrained.layer3.18.bn1.running_mean\", \"pretrained.layer3.18.bn1.running_var\", \"pretrained.layer3.18.bn1.num_batches_tracked\", \"pretrained.layer3.18.conv2.weight\", \"pretrained.layer3.18.bn2.weight\", \"pretrained.layer3.18.bn2.bias\", \"pretrained.layer3.18.bn2.running_mean\", \"pretrained.layer3.18.bn2.running_var\", \"pretrained.layer3.18.bn2.num_batches_tracked\", \"pretrained.layer3.18.conv3.weight\", \"pretrained.layer3.18.bn3.weight\", \"pretrained.layer3.18.bn3.bias\", \"pretrained.layer3.18.bn3.running_mean\", \"pretrained.layer3.18.bn3.running_var\", \"pretrained.layer3.18.bn3.num_batches_tracked\", \"pretrained.layer3.19.conv1.weight\", \"pretrained.layer3.19.bn1.weight\", \"pretrained.layer3.19.bn1.bias\", \"pretrained.layer3.19.bn1.running_mean\", \"pretrained.layer3.19.bn1.running_var\", \"pretrained.layer3.19.bn1.num_batches_tracked\", \"pretrained.layer3.19.conv2.weight\", \"pretrained.layer3.19.bn2.weight\", \"pretrained.layer3.19.bn2.bias\", \"pretrained.layer3.19.bn2.running_mean\", \"pretrained.layer3.19.bn2.running_var\", \"pretrained.layer3.19.bn2.num_batches_tracked\", \"pretrained.layer3.19.conv3.weight\", \"pretrained.layer3.19.bn3.weight\", \"pretrained.layer3.19.bn3.bias\", \"pretrained.layer3.19.bn3.running_mean\", \"pretrained.layer3.19.bn3.running_var\", \"pretrained.layer3.19.bn3.num_batches_tracked\", \"pretrained.layer3.20.conv1.weight\", \"pretrained.layer3.20.bn1.weight\", \"pretrained.layer3.20.bn1.bias\", \"pretrained.layer3.20.bn1.running_mean\", \"pretrained.layer3.20.bn1.running_var\", \"pretrained.layer3.20.bn1.num_batches_tracked\", \"pretrained.layer3.20.conv2.weight\", \"pretrained.layer3.20.bn2.weight\", \"pretrained.layer3.20.bn2.bias\", \"pretrained.layer3.20.bn2.running_mean\", \"pretrained.layer3.20.bn2.running_var\", \"pretrained.layer3.20.bn2.num_batches_tracked\", \"pretrained.layer3.20.conv3.weight\", \"pretrained.layer3.20.bn3.weight\", \"pretrained.layer3.20.bn3.bias\", \"pretrained.layer3.20.bn3.running_mean\", \"pretrained.layer3.20.bn3.running_var\", \"pretrained.layer3.20.bn3.num_batches_tracked\", \"pretrained.layer3.21.conv1.weight\", \"pretrained.layer3.21.bn1.weight\", \"pretrained.layer3.21.bn1.bias\", \"pretrained.layer3.21.bn1.running_mean\", \"pretrained.layer3.21.bn1.running_var\", \"pretrained.layer3.21.bn1.num_batches_tracked\", \"pretrained.layer3.21.conv2.weight\", \"pretrained.layer3.21.bn2.weight\", \"pretrained.layer3.21.bn2.bias\", \"pretrained.layer3.21.bn2.running_mean\", \"pretrained.layer3.21.bn2.running_var\", \"pretrained.layer3.21.bn2.num_batches_tracked\", \"pretrained.layer3.21.conv3.weight\", \"pretrained.layer3.21.bn3.weight\", \"pretrained.layer3.21.bn3.bias\", \"pretrained.layer3.21.bn3.running_mean\", \"pretrained.layer3.21.bn3.running_var\", \"pretrained.layer3.21.bn3.num_batches_tracked\", \"pretrained.layer3.22.conv1.weight\", \"pretrained.layer3.22.bn1.weight\", \"pretrained.layer3.22.bn1.bias\", \"pretrained.layer3.22.bn1.running_mean\", \"pretrained.layer3.22.bn1.running_var\", \"pretrained.layer3.22.bn1.num_batches_tracked\", \"pretrained.layer3.22.conv2.weight\", \"pretrained.layer3.22.bn2.weight\", \"pretrained.layer3.22.bn2.bias\", \"pretrained.layer3.22.bn2.running_mean\", \"pretrained.layer3.22.bn2.running_var\", \"pretrained.layer3.22.bn2.num_batches_tracked\", \"pretrained.layer3.22.conv3.weight\", \"pretrained.layer3.22.bn3.weight\", \"pretrained.layer3.22.bn3.bias\", \"pretrained.layer3.22.bn3.running_mean\", \"pretrained.layer3.22.bn3.running_var\", \"pretrained.layer3.22.bn3.num_batches_tracked\", \"pretrained.layer4.0.conv1.weight\", \"pretrained.layer4.0.bn1.weight\", \"pretrained.layer4.0.bn1.bias\", \"pretrained.layer4.0.bn1.running_mean\", \"pretrained.layer4.0.bn1.running_var\", \"pretrained.layer4.0.bn1.num_batches_tracked\", \"pretrained.layer4.0.conv2.weight\", \"pretrained.layer4.0.bn2.weight\", \"pretrained.layer4.0.bn2.bias\", \"pretrained.layer4.0.bn2.running_mean\", \"pretrained.layer4.0.bn2.running_var\", \"pretrained.layer4.0.bn2.num_batches_tracked\", \"pretrained.layer4.0.conv3.weight\", \"pretrained.layer4.0.bn3.weight\", \"pretrained.layer4.0.bn3.bias\", \"pretrained.layer4.0.bn3.running_mean\", \"pretrained.layer4.0.bn3.running_var\", \"pretrained.layer4.0.bn3.num_batches_tracked\", \"pretrained.layer4.0.downsample.0.weight\", \"pretrained.layer4.0.downsample.1.weight\", \"pretrained.layer4.0.downsample.1.bias\", \"pretrained.layer4.0.downsample.1.running_mean\", \"pretrained.layer4.0.downsample.1.running_var\", \"pretrained.layer4.0.downsample.1.num_batches_tracked\", \"pretrained.layer4.1.conv1.weight\", \"pretrained.layer4.1.bn1.weight\", \"pretrained.layer4.1.bn1.bias\", \"pretrained.layer4.1.bn1.running_mean\", \"pretrained.layer4.1.bn1.running_var\", \"pretrained.layer4.1.bn1.num_batches_tracked\", \"pretrained.layer4.1.conv2.weight\", \"pretrained.layer4.1.bn2.weight\", \"pretrained.layer4.1.bn2.bias\", \"pretrained.layer4.1.bn2.running_mean\", \"pretrained.layer4.1.bn2.running_var\", \"pretrained.layer4.1.bn2.num_batches_tracked\", \"pretrained.layer4.1.conv3.weight\", \"pretrained.layer4.1.bn3.weight\", \"pretrained.layer4.1.bn3.bias\", \"pretrained.layer4.1.bn3.running_mean\", \"pretrained.layer4.1.bn3.running_var\", \"pretrained.layer4.1.bn3.num_batches_tracked\", \"pretrained.layer4.2.conv1.weight\", \"pretrained.layer4.2.bn1.weight\", \"pretrained.layer4.2.bn1.bias\", \"pretrained.layer4.2.bn1.running_mean\", \"pretrained.layer4.2.bn1.running_var\", \"pretrained.layer4.2.bn1.num_batches_tracked\", \"pretrained.layer4.2.conv2.weight\", \"pretrained.layer4.2.bn2.weight\", \"pretrained.layer4.2.bn2.bias\", \"pretrained.layer4.2.bn2.running_mean\", \"pretrained.layer4.2.bn2.running_var\", \"pretrained.layer4.2.bn2.num_batches_tracked\", \"pretrained.layer4.2.conv3.weight\", \"pretrained.layer4.2.bn3.weight\", \"pretrained.layer4.2.bn3.bias\", \"pretrained.layer4.2.bn3.running_mean\", \"pretrained.layer4.2.bn3.running_var\", \"pretrained.layer4.2.bn3.num_batches_tracked\"]\n",
    "            checkpoint_needed = {x: checkpoint[x] for x in dl_list if x in checkpoint}\n",
    "            resnet101.state_dict().update(checkpoint_needed)\n",
    "            print('encoder loaded weights from',prelaod_pt)\n",
    "        layer = []\n",
    "        child_counter = 0\n",
    "        for child in resnet101.children():\n",
    "            if freeze: \n",
    "                print(\"resnet_layer\",child_counter,\"was frozen\")\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "                child_counter += 1  \n",
    "            layer.append(child)   \n",
    "                \n",
    "        self.res1 = layer[0]\n",
    "        self.res2 = layer[1]\n",
    "        self.res3 = layer[2]\n",
    "        self.res4 = layer[3]\n",
    "        \n",
    "            \n",
    "    def forward(self,x):         \n",
    "        EC1 = self.res1(x) #res /8, k_out = 256 \n",
    "        EC2= self.res2(EC1)  #res /16, k_out = 512\n",
    "        EC3 = self.res3(EC2) #res /32, k_out = 1024\n",
    "        out = self.res4(EC3)#res /64, k_out = 2048\n",
    "        return EC1, EC2, EC3, out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# midas Depth decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scratch connections\n",
    "from midas.blocks import _make_scratch\n",
    "def gt_scratch(features = 256):\n",
    "    scratch = _make_scratch([256, 512, 1024, 2048], features)\n",
    "    return scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#depth.midas decoder\n",
    "from midas.blocks import FeatureFusionBlock, Interpolate\n",
    "class depth_decoder(nn.Module): \n",
    "    def __init__(self,features = 256, non_negative=True, pre_load = False): \n",
    "        super(depth_decoder, self).__init__()\n",
    "        self.scratch = gt_scratch()\n",
    "        \n",
    "        self.scratch.refinenet4 = FeatureFusionBlock(features)\n",
    "        self.scratch.refinenet3 = FeatureFusionBlock(features)\n",
    "        self.scratch.refinenet2 = FeatureFusionBlock(features)\n",
    "        self.scratch.refinenet1 = FeatureFusionBlock(features)\n",
    "        self.scratch.output_conv = nn.Sequential(\n",
    "            nn.Conv2d(features, 128, kernel_size=3, stride=1, padding=1),\n",
    "            Interpolate(scale_factor=2, mode=\"bilinear\"),\n",
    "            nn.Conv2d(128, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 1, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ReLU(True) if non_negative else nn.Identity(),\n",
    "        )\n",
    "        \n",
    "    def forward(self,EC1,EC2,EC3,out): \n",
    "        layer_1_rn = self.scratch.layer1_rn(EC1)\n",
    "        layer_2_rn = self.scratch.layer2_rn(EC2)\n",
    "        layer_3_rn = self.scratch.layer3_rn(EC3)\n",
    "        layer_4_rn = self.scratch.layer4_rn(out)\n",
    "        \n",
    "        path_4 = self.scratch.refinenet4(layer_4_rn)\n",
    "        path_3 = self.scratch.refinenet3(path_4, layer_3_rn)\n",
    "        path_2 = self.scratch.refinenet2(path_3, layer_2_rn)\n",
    "        path_1 = self.scratch.refinenet1(path_2, layer_1_rn)\n",
    "\n",
    "        out = self.scratch.output_conv(path_1)\n",
    "\n",
    "        return torch.squeeze(out, dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\EVA\\JEDI\\YoloV3master\n"
     ]
    }
   ],
   "source": [
    "cd D:/ML/EVA/JEDI/YoloV3master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _FeatureConcat(layers):\n",
    "        return torch.cat([i for i in layers], 1)\n",
    "\n",
    "def _gt_darknet_child(x):\n",
    "    if isinstance(list(Darknet.children())[0][x], nn.Sequential):\n",
    "        return list(list(Darknet.children())[0][x].children())\n",
    "    else: \n",
    "        temp = []\n",
    "        temp.append(list(Darknet.children())[0][x])\n",
    "        return temp\n",
    "    \n",
    "def _gt_darknet_children(l):\n",
    "    layer_list = []\n",
    "    for x in l: \n",
    "        layer_list.extend(_gt_darknet_child(x))\n",
    "    return layer_list\n",
    "\n",
    "def _get_seq_block(seqlist): \n",
    "    module = nn.Sequential()\n",
    "    for i,mod in enumerate(seqlist):\n",
    "        if isinstance(mod,nn.Conv2d):\n",
    "            module.add_module(module = mod,name = 'Conv2d'+'_'+str(i))\n",
    "        elif isinstance(mod,nn.BatchNorm2d):\n",
    "            module.add_module(module = mod,name = 'BatchNorm2d'+'_'+str(i))\n",
    "        else :\n",
    "            module.add_module(module = mod,name = 'others'+'_'+str(i))\n",
    "        #print(i)\n",
    "    return(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (Conv2d): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (Conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (Conv2d): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (Conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (4): WeightedFeatureFusion()\n",
      "  (5): Sequential(\n",
      "    (Conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (Conv2d): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (Conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (8): WeightedFeatureFusion()\n",
      "  (9): Sequential(\n",
      "    (Conv2d): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (10): Sequential(\n",
      "    (Conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (11): WeightedFeatureFusion()\n",
      "  (12): Sequential(\n",
      "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (13): Sequential(\n",
      "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (14): Sequential(\n",
      "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (15): WeightedFeatureFusion()\n",
      "  (16): Sequential(\n",
      "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (17): Sequential(\n",
      "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (18): WeightedFeatureFusion()\n",
      "  (19): Sequential(\n",
      "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (20): Sequential(\n",
      "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (21): WeightedFeatureFusion()\n",
      "  (22): Sequential(\n",
      "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (23): Sequential(\n",
      "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (24): WeightedFeatureFusion()\n",
      "  (25): Sequential(\n",
      "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (26): Sequential(\n",
      "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (27): WeightedFeatureFusion()\n",
      "  (28): Sequential(\n",
      "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (29): Sequential(\n",
      "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (30): WeightedFeatureFusion()\n",
      "  (31): Sequential(\n",
      "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (32): Sequential(\n",
      "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (33): WeightedFeatureFusion()\n",
      "  (34): Sequential(\n",
      "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (35): Sequential(\n",
      "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (36): WeightedFeatureFusion()\n",
      "  (37): Sequential(\n",
      "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (38): Sequential(\n",
      "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (39): Sequential(\n",
      "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (40): WeightedFeatureFusion()\n",
      "  (41): Sequential(\n",
      "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (42): Sequential(\n",
      "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (43): WeightedFeatureFusion()\n",
      "  (44): Sequential(\n",
      "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (45): Sequential(\n",
      "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (46): WeightedFeatureFusion()\n",
      "  (47): Sequential(\n",
      "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (48): Sequential(\n",
      "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (49): WeightedFeatureFusion()\n",
      "  (50): Sequential(\n",
      "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (51): Sequential(\n",
      "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (52): WeightedFeatureFusion()\n",
      "  (53): Sequential(\n",
      "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (54): Sequential(\n",
      "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (55): WeightedFeatureFusion()\n",
      "  (56): Sequential(\n",
      "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (57): Sequential(\n",
      "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (58): WeightedFeatureFusion()\n",
      "  (59): Sequential(\n",
      "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (60): Sequential(\n",
      "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (61): WeightedFeatureFusion()\n",
      "  (62): Sequential(\n",
      "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (63): Sequential(\n",
      "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (64): Sequential(\n",
      "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (65): WeightedFeatureFusion()\n",
      "  (66): Sequential(\n",
      "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (67): Sequential(\n",
      "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (68): WeightedFeatureFusion()\n",
      "  (69): Sequential(\n",
      "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (70): Sequential(\n",
      "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (71): WeightedFeatureFusion()\n",
      "  (72): Sequential(\n",
      "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (73): Sequential(\n",
      "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (74): WeightedFeatureFusion()\n",
      "  (75): Sequential(\n",
      "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (76): Sequential(\n",
      "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (77): Sequential(\n",
      "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (78): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "  (79): FeatureConcat()\n",
      "  (80): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
      "  (81): FeatureConcat()\n",
      "  (82): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
      "  (83): FeatureConcat()\n",
      "  (84): Sequential(\n",
      "    (Conv2d): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (85): Sequential(\n",
      "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (86): Sequential(\n",
      "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (87): Sequential(\n",
      "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (88): Sequential(\n",
      "    (Conv2d): Conv2d(1024, 27, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (89): YOLOLayer()\n",
      "  (90): FeatureConcat()\n",
      "  (91): Sequential(\n",
      "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (92): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  (93): FeatureConcat()\n",
      "  (94): Sequential(\n",
      "    (Conv2d): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (95): Sequential(\n",
      "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (96): Sequential(\n",
      "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (97): Sequential(\n",
      "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (98): Sequential(\n",
      "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (99): Sequential(\n",
      "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (100): Sequential(\n",
      "    (Conv2d): Conv2d(512, 27, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (101): YOLOLayer()\n",
      "  (102): FeatureConcat()\n",
      "  (103): Sequential(\n",
      "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (104): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  (105): FeatureConcat()\n",
      "  (106): Sequential(\n",
      "    (Conv2d): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (107): Sequential(\n",
      "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (108): Sequential(\n",
      "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (109): Sequential(\n",
      "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (110): Sequential(\n",
      "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (111): Sequential(\n",
      "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (112): Sequential(\n",
      "    (Conv2d): Conv2d(256, 27, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (113): YOLOLayer()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for x in Darknet.children(): \n",
    "    ifinstance(x, nn.Sequential): \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True),\n",
       " LeakyReLU(negative_slope=0.1, inplace=True),\n",
       " Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True),\n",
       " LeakyReLU(negative_slope=0.1, inplace=True),\n",
       " Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True),\n",
       " LeakyReLU(negative_slope=0.1, inplace=True)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_gt_darknet_children(list(range(84,87)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 225 layers, 6.25895e+07 parameters, 6.25895e+07 gradients\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "from utils_yolo.utils import *\n",
    "cfg = 'D:/ML/EVA/JEDI/YoloV3master/cfg/yolov3-custom.cfg'\n",
    "Darknet = Darknet(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conv2d_0.weight',\n",
       " 'BatchNorm2d_1.weight',\n",
       " 'BatchNorm2d_1.bias',\n",
       " 'Conv2d_3.weight',\n",
       " 'BatchNorm2d_4.weight',\n",
       " 'BatchNorm2d_4.bias',\n",
       " 'Conv2d_6.weight',\n",
       " 'BatchNorm2d_7.weight',\n",
       " 'BatchNorm2d_7.bias']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "#k = _gt_darknet_children(list(range(84,87)))\n",
    "\n",
    "def _get_seq_block(seqlist): \n",
    "    module = nn.Sequential()\n",
    "    for i,mod in enumerate(seqlist):\n",
    "        if isinstance(mod,nn.Conv2d):\n",
    "            module.add_module(module = mod,name = 'Conv2d'+'_'+str(i))\n",
    "        elif isinstance(mod,nn.BatchNorm2d):\n",
    "            module.add_module(module = mod,name = 'BatchNorm2d'+'_'+str(i))\n",
    "        else :\n",
    "            module.add_module(module = mod,name = 'others'+'_'+str(i))\n",
    "        #print(i)\n",
    "    return(module)\n",
    "\n",
    "bla = _get_seq_block(_gt_darknet_children(list(range(84,87))))\n",
    "trainables = [name for name, param in bla.named_parameters()]\n",
    "trainables\n",
    "#list(bla.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-95c29c5b9b80>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-48-95c29c5b9b80>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    list(Darknet.children())[0][84])\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "list(Darknet.children())[0][84])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['module_list.0.Conv2d.weight',\n",
       " 'module_list.0.BatchNorm2d.weight',\n",
       " 'module_list.0.BatchNorm2d.bias',\n",
       " 'module_list.1.Conv2d.weight',\n",
       " 'module_list.1.BatchNorm2d.weight',\n",
       " 'module_list.1.BatchNorm2d.bias',\n",
       " 'module_list.2.Conv2d.weight',\n",
       " 'module_list.2.BatchNorm2d.weight',\n",
       " 'module_list.2.BatchNorm2d.bias',\n",
       " 'module_list.3.Conv2d.weight',\n",
       " 'module_list.3.BatchNorm2d.weight',\n",
       " 'module_list.3.BatchNorm2d.bias',\n",
       " 'module_list.5.Conv2d.weight',\n",
       " 'module_list.5.BatchNorm2d.weight',\n",
       " 'module_list.5.BatchNorm2d.bias',\n",
       " 'module_list.6.Conv2d.weight',\n",
       " 'module_list.6.BatchNorm2d.weight',\n",
       " 'module_list.6.BatchNorm2d.bias',\n",
       " 'module_list.7.Conv2d.weight',\n",
       " 'module_list.7.BatchNorm2d.weight',\n",
       " 'module_list.7.BatchNorm2d.bias',\n",
       " 'module_list.9.Conv2d.weight',\n",
       " 'module_list.9.BatchNorm2d.weight',\n",
       " 'module_list.9.BatchNorm2d.bias',\n",
       " 'module_list.10.Conv2d.weight',\n",
       " 'module_list.10.BatchNorm2d.weight',\n",
       " 'module_list.10.BatchNorm2d.bias',\n",
       " 'module_list.12.Conv2d.weight',\n",
       " 'module_list.12.BatchNorm2d.weight',\n",
       " 'module_list.12.BatchNorm2d.bias',\n",
       " 'module_list.13.Conv2d.weight',\n",
       " 'module_list.13.BatchNorm2d.weight',\n",
       " 'module_list.13.BatchNorm2d.bias',\n",
       " 'module_list.14.Conv2d.weight',\n",
       " 'module_list.14.BatchNorm2d.weight',\n",
       " 'module_list.14.BatchNorm2d.bias',\n",
       " 'module_list.16.Conv2d.weight',\n",
       " 'module_list.16.BatchNorm2d.weight',\n",
       " 'module_list.16.BatchNorm2d.bias',\n",
       " 'module_list.17.Conv2d.weight',\n",
       " 'module_list.17.BatchNorm2d.weight',\n",
       " 'module_list.17.BatchNorm2d.bias',\n",
       " 'module_list.19.Conv2d.weight',\n",
       " 'module_list.19.BatchNorm2d.weight',\n",
       " 'module_list.19.BatchNorm2d.bias',\n",
       " 'module_list.20.Conv2d.weight',\n",
       " 'module_list.20.BatchNorm2d.weight',\n",
       " 'module_list.20.BatchNorm2d.bias',\n",
       " 'module_list.22.Conv2d.weight',\n",
       " 'module_list.22.BatchNorm2d.weight',\n",
       " 'module_list.22.BatchNorm2d.bias',\n",
       " 'module_list.23.Conv2d.weight',\n",
       " 'module_list.23.BatchNorm2d.weight',\n",
       " 'module_list.23.BatchNorm2d.bias',\n",
       " 'module_list.25.Conv2d.weight',\n",
       " 'module_list.25.BatchNorm2d.weight',\n",
       " 'module_list.25.BatchNorm2d.bias',\n",
       " 'module_list.26.Conv2d.weight',\n",
       " 'module_list.26.BatchNorm2d.weight',\n",
       " 'module_list.26.BatchNorm2d.bias',\n",
       " 'module_list.28.Conv2d.weight',\n",
       " 'module_list.28.BatchNorm2d.weight',\n",
       " 'module_list.28.BatchNorm2d.bias',\n",
       " 'module_list.29.Conv2d.weight',\n",
       " 'module_list.29.BatchNorm2d.weight',\n",
       " 'module_list.29.BatchNorm2d.bias',\n",
       " 'module_list.31.Conv2d.weight',\n",
       " 'module_list.31.BatchNorm2d.weight',\n",
       " 'module_list.31.BatchNorm2d.bias',\n",
       " 'module_list.32.Conv2d.weight',\n",
       " 'module_list.32.BatchNorm2d.weight',\n",
       " 'module_list.32.BatchNorm2d.bias',\n",
       " 'module_list.34.Conv2d.weight',\n",
       " 'module_list.34.BatchNorm2d.weight',\n",
       " 'module_list.34.BatchNorm2d.bias',\n",
       " 'module_list.35.Conv2d.weight',\n",
       " 'module_list.35.BatchNorm2d.weight',\n",
       " 'module_list.35.BatchNorm2d.bias',\n",
       " 'module_list.37.Conv2d.weight',\n",
       " 'module_list.37.BatchNorm2d.weight',\n",
       " 'module_list.37.BatchNorm2d.bias',\n",
       " 'module_list.38.Conv2d.weight',\n",
       " 'module_list.38.BatchNorm2d.weight',\n",
       " 'module_list.38.BatchNorm2d.bias',\n",
       " 'module_list.39.Conv2d.weight',\n",
       " 'module_list.39.BatchNorm2d.weight',\n",
       " 'module_list.39.BatchNorm2d.bias',\n",
       " 'module_list.41.Conv2d.weight',\n",
       " 'module_list.41.BatchNorm2d.weight',\n",
       " 'module_list.41.BatchNorm2d.bias',\n",
       " 'module_list.42.Conv2d.weight',\n",
       " 'module_list.42.BatchNorm2d.weight',\n",
       " 'module_list.42.BatchNorm2d.bias',\n",
       " 'module_list.44.Conv2d.weight',\n",
       " 'module_list.44.BatchNorm2d.weight',\n",
       " 'module_list.44.BatchNorm2d.bias',\n",
       " 'module_list.45.Conv2d.weight',\n",
       " 'module_list.45.BatchNorm2d.weight',\n",
       " 'module_list.45.BatchNorm2d.bias',\n",
       " 'module_list.47.Conv2d.weight',\n",
       " 'module_list.47.BatchNorm2d.weight',\n",
       " 'module_list.47.BatchNorm2d.bias',\n",
       " 'module_list.48.Conv2d.weight',\n",
       " 'module_list.48.BatchNorm2d.weight',\n",
       " 'module_list.48.BatchNorm2d.bias',\n",
       " 'module_list.50.Conv2d.weight',\n",
       " 'module_list.50.BatchNorm2d.weight',\n",
       " 'module_list.50.BatchNorm2d.bias',\n",
       " 'module_list.51.Conv2d.weight',\n",
       " 'module_list.51.BatchNorm2d.weight',\n",
       " 'module_list.51.BatchNorm2d.bias',\n",
       " 'module_list.53.Conv2d.weight',\n",
       " 'module_list.53.BatchNorm2d.weight',\n",
       " 'module_list.53.BatchNorm2d.bias',\n",
       " 'module_list.54.Conv2d.weight',\n",
       " 'module_list.54.BatchNorm2d.weight',\n",
       " 'module_list.54.BatchNorm2d.bias',\n",
       " 'module_list.56.Conv2d.weight',\n",
       " 'module_list.56.BatchNorm2d.weight',\n",
       " 'module_list.56.BatchNorm2d.bias',\n",
       " 'module_list.57.Conv2d.weight',\n",
       " 'module_list.57.BatchNorm2d.weight',\n",
       " 'module_list.57.BatchNorm2d.bias',\n",
       " 'module_list.59.Conv2d.weight',\n",
       " 'module_list.59.BatchNorm2d.weight',\n",
       " 'module_list.59.BatchNorm2d.bias',\n",
       " 'module_list.60.Conv2d.weight',\n",
       " 'module_list.60.BatchNorm2d.weight',\n",
       " 'module_list.60.BatchNorm2d.bias',\n",
       " 'module_list.62.Conv2d.weight',\n",
       " 'module_list.62.BatchNorm2d.weight',\n",
       " 'module_list.62.BatchNorm2d.bias',\n",
       " 'module_list.63.Conv2d.weight',\n",
       " 'module_list.63.BatchNorm2d.weight',\n",
       " 'module_list.63.BatchNorm2d.bias',\n",
       " 'module_list.64.Conv2d.weight',\n",
       " 'module_list.64.BatchNorm2d.weight',\n",
       " 'module_list.64.BatchNorm2d.bias',\n",
       " 'module_list.66.Conv2d.weight',\n",
       " 'module_list.66.BatchNorm2d.weight',\n",
       " 'module_list.66.BatchNorm2d.bias',\n",
       " 'module_list.67.Conv2d.weight',\n",
       " 'module_list.67.BatchNorm2d.weight',\n",
       " 'module_list.67.BatchNorm2d.bias',\n",
       " 'module_list.69.Conv2d.weight',\n",
       " 'module_list.69.BatchNorm2d.weight',\n",
       " 'module_list.69.BatchNorm2d.bias',\n",
       " 'module_list.70.Conv2d.weight',\n",
       " 'module_list.70.BatchNorm2d.weight',\n",
       " 'module_list.70.BatchNorm2d.bias',\n",
       " 'module_list.72.Conv2d.weight',\n",
       " 'module_list.72.BatchNorm2d.weight',\n",
       " 'module_list.72.BatchNorm2d.bias',\n",
       " 'module_list.73.Conv2d.weight',\n",
       " 'module_list.73.BatchNorm2d.weight',\n",
       " 'module_list.73.BatchNorm2d.bias',\n",
       " 'module_list.75.Conv2d.weight',\n",
       " 'module_list.75.BatchNorm2d.weight',\n",
       " 'module_list.75.BatchNorm2d.bias',\n",
       " 'module_list.76.Conv2d.weight',\n",
       " 'module_list.76.BatchNorm2d.weight',\n",
       " 'module_list.76.BatchNorm2d.bias',\n",
       " 'module_list.77.Conv2d.weight',\n",
       " 'module_list.77.BatchNorm2d.weight',\n",
       " 'module_list.77.BatchNorm2d.bias',\n",
       " 'module_list.84.Conv2d.weight',\n",
       " 'module_list.84.BatchNorm2d.weight',\n",
       " 'module_list.84.BatchNorm2d.bias',\n",
       " 'module_list.85.Conv2d.weight',\n",
       " 'module_list.85.BatchNorm2d.weight',\n",
       " 'module_list.85.BatchNorm2d.bias',\n",
       " 'module_list.86.Conv2d.weight',\n",
       " 'module_list.86.BatchNorm2d.weight',\n",
       " 'module_list.86.BatchNorm2d.bias',\n",
       " 'module_list.87.Conv2d.weight',\n",
       " 'module_list.87.BatchNorm2d.weight',\n",
       " 'module_list.87.BatchNorm2d.bias',\n",
       " 'module_list.88.Conv2d.weight',\n",
       " 'module_list.88.Conv2d.bias',\n",
       " 'module_list.91.Conv2d.weight',\n",
       " 'module_list.91.BatchNorm2d.weight',\n",
       " 'module_list.91.BatchNorm2d.bias',\n",
       " 'module_list.94.Conv2d.weight',\n",
       " 'module_list.94.BatchNorm2d.weight',\n",
       " 'module_list.94.BatchNorm2d.bias',\n",
       " 'module_list.95.Conv2d.weight',\n",
       " 'module_list.95.BatchNorm2d.weight',\n",
       " 'module_list.95.BatchNorm2d.bias',\n",
       " 'module_list.96.Conv2d.weight',\n",
       " 'module_list.96.BatchNorm2d.weight',\n",
       " 'module_list.96.BatchNorm2d.bias',\n",
       " 'module_list.97.Conv2d.weight',\n",
       " 'module_list.97.BatchNorm2d.weight',\n",
       " 'module_list.97.BatchNorm2d.bias',\n",
       " 'module_list.98.Conv2d.weight',\n",
       " 'module_list.98.BatchNorm2d.weight',\n",
       " 'module_list.98.BatchNorm2d.bias',\n",
       " 'module_list.99.Conv2d.weight',\n",
       " 'module_list.99.BatchNorm2d.weight',\n",
       " 'module_list.99.BatchNorm2d.bias',\n",
       " 'module_list.100.Conv2d.weight',\n",
       " 'module_list.100.Conv2d.bias',\n",
       " 'module_list.103.Conv2d.weight',\n",
       " 'module_list.103.BatchNorm2d.weight',\n",
       " 'module_list.103.BatchNorm2d.bias',\n",
       " 'module_list.106.Conv2d.weight',\n",
       " 'module_list.106.BatchNorm2d.weight',\n",
       " 'module_list.106.BatchNorm2d.bias',\n",
       " 'module_list.107.Conv2d.weight',\n",
       " 'module_list.107.BatchNorm2d.weight',\n",
       " 'module_list.107.BatchNorm2d.bias',\n",
       " 'module_list.108.Conv2d.weight',\n",
       " 'module_list.108.BatchNorm2d.weight',\n",
       " 'module_list.108.BatchNorm2d.bias',\n",
       " 'module_list.109.Conv2d.weight',\n",
       " 'module_list.109.BatchNorm2d.weight',\n",
       " 'module_list.109.BatchNorm2d.bias',\n",
       " 'module_list.110.Conv2d.weight',\n",
       " 'module_list.110.BatchNorm2d.weight',\n",
       " 'module_list.110.BatchNorm2d.bias',\n",
       " 'module_list.111.Conv2d.weight',\n",
       " 'module_list.111.BatchNorm2d.weight',\n",
       " 'module_list.111.BatchNorm2d.bias',\n",
       " 'module_list.112.Conv2d.weight',\n",
       " 'module_list.112.Conv2d.bias']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checkpoint = torch.load('D:/ML/EVA/JEDI/YoloV3master/last_ppe.pt')\n",
    "#Darknet.load_state_dict(checkpoint['model'])\n",
    "trainables = [name for name, param in Darknet.named_parameters() if param.requires_grad]\n",
    "trainables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D:/ML/EVA/JEDI/YoloV3master/last_ppe.pt - preload weights location\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "class yolo_decoder(nn.Module): \n",
    "    def __init__(self,pre_load = False, pre_load_pth = ''): \n",
    "        super(yolo_decoder, self).__init__()\n",
    "        #anchors for 13x13, 26X26, 52X52\n",
    "        if pre_load: \n",
    "            checkpoint = torch.load(pre_load_pth)\n",
    "            Darknet.load_state_dict(checkpoint['model'])\n",
    "            print('loaded weight from',pre_load_pth) \n",
    "        \n",
    "        val = \"10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\"\n",
    "        anc_13 = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[6,7,8]]\n",
    "        anc_26 = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[3,4,5]]\n",
    "        anc_52 = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[0,1,2]]\n",
    "        #13x13 yolo layer\n",
    "        self.yolo_13_bottle_neck = nn.Conv2d(2048, 2048, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.yolo_13_path = _get_seq_block(_gt_darknet_children(list(range(84,87))))\n",
    "        self.yolo_13_tail = _get_seq_block(_gt_darknet_children(list(range(87,89))))\n",
    "        self.yolo_13 = YOLOLayer(anchors=anc_13,  # anchor list\n",
    "                                nc=4,  # number of classes\n",
    "                                img_size= (416, 416),  # (416, 416)\n",
    "                                yolo_index=0,  # 0, 1, 2...\n",
    "                                layers=[],  # output layers\n",
    "                                stride=32)\n",
    "        #26x26 yolo layer\n",
    "        self.yolo_26_upsample = _get_seq_block(_gt_darknet_children(list(range(91,93))))\n",
    "        self.yolo_26_bottle_neck = nn.Conv2d(1024, 512, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.yolo_26_path =  _get_seq_block(_gt_darknet_children(list(range(94,99))))\n",
    "        self.yolo_26_tail = _get_seq_block(_gt_darknet_children(list(range(99,101))))\n",
    "        self.yolo_26 = YOLOLayer(anchors=anc_26,  # anchor list\n",
    "                                nc=4,  # number of classes\n",
    "                                img_size= (416, 416),  # (416, 416)\n",
    "                                yolo_index=0,  # 0, 1, 2...\n",
    "                                layers=[],  # output layers\n",
    "                                stride=16)\n",
    "        \n",
    "      #52X52 yolo layer \n",
    "        self.yolo_52_upsample = _get_seq_block(_gt_darknet_children(list(range(103,105))))\n",
    "        self.yolo_52_bottle_neck = nn.Conv2d(512, 256, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.yolo_52_path_tail = _get_seq_block(_gt_darknet_children(list(range(106,113))))\n",
    "        self.yolo_52 = YOLOLayer(anchors=anc_52,  # anchor list\n",
    "                                nc=4,  # number of classes\n",
    "                                img_size= (416, 416),  # (416, 416)\n",
    "                                yolo_index=0,  # 0, 1, 2...\n",
    "                                layers=[],  # output layers\n",
    "                                stride=8)\n",
    "    \n",
    "    def forward(self, EC2,EC3,out):\n",
    "        #yolo 13\n",
    "        out_bn = self.yolo_13_bottle_neck(out)\n",
    "        out_13_path = self.yolo_13_path(out_bn)\n",
    "        out_13_tail = self.yolo_13_tail(out_13_path)\n",
    "        out_13_yolo = self.yolo_13(out_13_tail,[])\n",
    "        #yolo 26\n",
    "        out_26_upsample = self.yolo_26_upsample(out_13_path)\n",
    "        out_EC3_bn = self.yolo_26_bottle_neck(EC3)\n",
    "        out_26_FC = _FeatureConcat([out_26_upsample,out_EC3_bn])\n",
    "        out_26_path = self.yolo_26_path(out_26_FC)\n",
    "        out_26_tail = self.yolo_26_tail(out_26_path)\n",
    "        out_26_yolo = self.yolo_26(out_26_tail,[])\n",
    "        #yolo 52\n",
    "        out_52_upsample = self.yolo_52_upsample(out_26_path)\n",
    "        out_EC2_bn = self.yolo_52_bottle_neck(EC2)\n",
    "        out_52_FC = _FeatureConcat([out_52_upsample,out_EC2_bn])\n",
    "        out_52_tail = self.yolo_52_path_tail(out_52_FC)\n",
    "        out_52_yolo = self.yolo_52(out_52_tail,[])\n",
    "        return out_13_yolo,out_26_yolo,out_52_yolo\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yolo_13_bottle_neck.weight',\n",
       " 'yolo_13_path.Conv2d_0.weight',\n",
       " 'yolo_13_path.BatchNorm2d_1.weight',\n",
       " 'yolo_13_path.BatchNorm2d_1.bias',\n",
       " 'yolo_13_path.Conv2d_3.weight',\n",
       " 'yolo_13_path.BatchNorm2d_4.weight',\n",
       " 'yolo_13_path.BatchNorm2d_4.bias',\n",
       " 'yolo_13_path.Conv2d_6.weight',\n",
       " 'yolo_13_path.BatchNorm2d_7.weight',\n",
       " 'yolo_13_path.BatchNorm2d_7.bias',\n",
       " 'yolo_13_tail.Conv2d_0.weight',\n",
       " 'yolo_13_tail.BatchNorm2d_1.weight',\n",
       " 'yolo_13_tail.BatchNorm2d_1.bias',\n",
       " 'yolo_13_tail.Conv2d_3.weight',\n",
       " 'yolo_13_tail.Conv2d_3.bias',\n",
       " 'yolo_26_upsample.Conv2d_0.weight',\n",
       " 'yolo_26_upsample.BatchNorm2d_1.weight',\n",
       " 'yolo_26_upsample.BatchNorm2d_1.bias',\n",
       " 'yolo_26_bottle_neck.weight',\n",
       " 'yolo_26_path.Conv2d_0.weight',\n",
       " 'yolo_26_path.BatchNorm2d_1.weight',\n",
       " 'yolo_26_path.BatchNorm2d_1.bias',\n",
       " 'yolo_26_path.Conv2d_3.weight',\n",
       " 'yolo_26_path.BatchNorm2d_4.weight',\n",
       " 'yolo_26_path.BatchNorm2d_4.bias',\n",
       " 'yolo_26_path.Conv2d_6.weight',\n",
       " 'yolo_26_path.BatchNorm2d_7.weight',\n",
       " 'yolo_26_path.BatchNorm2d_7.bias',\n",
       " 'yolo_26_path.Conv2d_9.weight',\n",
       " 'yolo_26_path.BatchNorm2d_10.weight',\n",
       " 'yolo_26_path.BatchNorm2d_10.bias',\n",
       " 'yolo_26_path.Conv2d_12.weight',\n",
       " 'yolo_26_path.BatchNorm2d_13.weight',\n",
       " 'yolo_26_path.BatchNorm2d_13.bias',\n",
       " 'yolo_26_tail.Conv2d_0.weight',\n",
       " 'yolo_26_tail.BatchNorm2d_1.weight',\n",
       " 'yolo_26_tail.BatchNorm2d_1.bias',\n",
       " 'yolo_26_tail.Conv2d_3.weight',\n",
       " 'yolo_26_tail.Conv2d_3.bias',\n",
       " 'yolo_52_upsample.Conv2d_0.weight',\n",
       " 'yolo_52_upsample.BatchNorm2d_1.weight',\n",
       " 'yolo_52_upsample.BatchNorm2d_1.bias',\n",
       " 'yolo_52_bottle_neck.weight',\n",
       " 'yolo_52_path_tail.Conv2d_0.weight',\n",
       " 'yolo_52_path_tail.BatchNorm2d_1.weight',\n",
       " 'yolo_52_path_tail.BatchNorm2d_1.bias',\n",
       " 'yolo_52_path_tail.Conv2d_3.weight',\n",
       " 'yolo_52_path_tail.BatchNorm2d_4.weight',\n",
       " 'yolo_52_path_tail.BatchNorm2d_4.bias',\n",
       " 'yolo_52_path_tail.Conv2d_6.weight',\n",
       " 'yolo_52_path_tail.BatchNorm2d_7.weight',\n",
       " 'yolo_52_path_tail.BatchNorm2d_7.bias',\n",
       " 'yolo_52_path_tail.Conv2d_9.weight',\n",
       " 'yolo_52_path_tail.BatchNorm2d_10.weight',\n",
       " 'yolo_52_path_tail.BatchNorm2d_10.bias',\n",
       " 'yolo_52_path_tail.Conv2d_12.weight',\n",
       " 'yolo_52_path_tail.BatchNorm2d_13.weight',\n",
       " 'yolo_52_path_tail.BatchNorm2d_13.bias',\n",
       " 'yolo_52_path_tail.Conv2d_15.weight',\n",
       " 'yolo_52_path_tail.BatchNorm2d_16.weight',\n",
       " 'yolo_52_path_tail.BatchNorm2d_16.bias',\n",
       " 'yolo_52_path_tail.Conv2d_18.weight',\n",
       " 'yolo_52_path_tail.Conv2d_18.bias']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = yolo_decoder()\n",
    "trainables = [name for name, param in model.named_parameters() if param.requires_grad]\n",
    "trainables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Fork Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final fork model\n",
    "#D:/ML/EVA/JEDi/Midas/model-f46da743.pt - depth decoder\n",
    "#D:/ML/EVA/JEDI/YoloV3master/last_ppe.pt - yolo decoder\n",
    "class fork(nn.Module):\n",
    "    def __init__(self, depth_freeze = False, yolo_freeze = False, depth_preload_pth = '', yolo_preload_pth = ''): \n",
    "        super(fork,self).__init__()\n",
    "        self.encoder = enc()\n",
    "        #depth decoder with preload\n",
    "        self.decoder = depth_decoder(features = 256)\n",
    "        if depth_freeze:\n",
    "            child_counter = 0\n",
    "            for child in self.decoder.children():\n",
    "                print(\"depth_layer\",child_counter,\"was frozen\")\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "                child_counter += 1\n",
    "                \n",
    "        if depth_preload_pth != '':\n",
    "            checkpoint = torch.load(depth_preload_pth)\n",
    "            dl_list = [\"pretrained.layer1.0.weight\", \"pretrained.layer1.1.weight\", \"pretrained.layer1.1.bias\", \"pretrained.layer1.1.running_mean\", \"pretrained.layer1.1.running_var\", \"pretrained.layer1.1.num_batches_tracked\", \"pretrained.layer1.4.0.conv1.weight\", \"pretrained.layer1.4.0.bn1.weight\", \"pretrained.layer1.4.0.bn1.bias\", \"pretrained.layer1.4.0.bn1.running_mean\", \"pretrained.layer1.4.0.bn1.running_var\", \"pretrained.layer1.4.0.bn1.num_batches_tracked\", \"pretrained.layer1.4.0.conv2.weight\", \"pretrained.layer1.4.0.bn2.weight\", \"pretrained.layer1.4.0.bn2.bias\", \"pretrained.layer1.4.0.bn2.running_mean\", \"pretrained.layer1.4.0.bn2.running_var\", \"pretrained.layer1.4.0.bn2.num_batches_tracked\", \"pretrained.layer1.4.0.conv3.weight\", \"pretrained.layer1.4.0.bn3.weight\", \"pretrained.layer1.4.0.bn3.bias\", \"pretrained.layer1.4.0.bn3.running_mean\", \"pretrained.layer1.4.0.bn3.running_var\", \"pretrained.layer1.4.0.bn3.num_batches_tracked\", \"pretrained.layer1.4.0.downsample.0.weight\", \"pretrained.layer1.4.0.downsample.1.weight\", \"pretrained.layer1.4.0.downsample.1.bias\", \"pretrained.layer1.4.0.downsample.1.running_mean\", \"pretrained.layer1.4.0.downsample.1.running_var\", \"pretrained.layer1.4.0.downsample.1.num_batches_tracked\", \"pretrained.layer1.4.1.conv1.weight\", \"pretrained.layer1.4.1.bn1.weight\", \"pretrained.layer1.4.1.bn1.bias\", \"pretrained.layer1.4.1.bn1.running_mean\", \"pretrained.layer1.4.1.bn1.running_var\", \"pretrained.layer1.4.1.bn1.num_batches_tracked\", \"pretrained.layer1.4.1.conv2.weight\", \"pretrained.layer1.4.1.bn2.weight\", \"pretrained.layer1.4.1.bn2.bias\", \"pretrained.layer1.4.1.bn2.running_mean\", \"pretrained.layer1.4.1.bn2.running_var\", \"pretrained.layer1.4.1.bn2.num_batches_tracked\", \"pretrained.layer1.4.1.conv3.weight\", \"pretrained.layer1.4.1.bn3.weight\", \"pretrained.layer1.4.1.bn3.bias\", \"pretrained.layer1.4.1.bn3.running_mean\", \"pretrained.layer1.4.1.bn3.running_var\", \"pretrained.layer1.4.1.bn3.num_batches_tracked\", \"pretrained.layer1.4.2.conv1.weight\", \"pretrained.layer1.4.2.bn1.weight\", \"pretrained.layer1.4.2.bn1.bias\", \"pretrained.layer1.4.2.bn1.running_mean\", \"pretrained.layer1.4.2.bn1.running_var\", \"pretrained.layer1.4.2.bn1.num_batches_tracked\", \"pretrained.layer1.4.2.conv2.weight\", \"pretrained.layer1.4.2.bn2.weight\", \"pretrained.layer1.4.2.bn2.bias\", \"pretrained.layer1.4.2.bn2.running_mean\", \"pretrained.layer1.4.2.bn2.running_var\", \"pretrained.layer1.4.2.bn2.num_batches_tracked\", \"pretrained.layer1.4.2.conv3.weight\", \"pretrained.layer1.4.2.bn3.weight\", \"pretrained.layer1.4.2.bn3.bias\", \"pretrained.layer1.4.2.bn3.running_mean\", \"pretrained.layer1.4.2.bn3.running_var\", \"pretrained.layer1.4.2.bn3.num_batches_tracked\", \"pretrained.layer2.0.conv1.weight\", \"pretrained.layer2.0.bn1.weight\", \"pretrained.layer2.0.bn1.bias\", \"pretrained.layer2.0.bn1.running_mean\", \"pretrained.layer2.0.bn1.running_var\", \"pretrained.layer2.0.bn1.num_batches_tracked\", \"pretrained.layer2.0.conv2.weight\", \"pretrained.layer2.0.bn2.weight\", \"pretrained.layer2.0.bn2.bias\", \"pretrained.layer2.0.bn2.running_mean\", \"pretrained.layer2.0.bn2.running_var\", \"pretrained.layer2.0.bn2.num_batches_tracked\", \"pretrained.layer2.0.conv3.weight\", \"pretrained.layer2.0.bn3.weight\", \"pretrained.layer2.0.bn3.bias\", \"pretrained.layer2.0.bn3.running_mean\", \"pretrained.layer2.0.bn3.running_var\", \"pretrained.layer2.0.bn3.num_batches_tracked\", \"pretrained.layer2.0.downsample.0.weight\", \"pretrained.layer2.0.downsample.1.weight\", \"pretrained.layer2.0.downsample.1.bias\", \"pretrained.layer2.0.downsample.1.running_mean\", \"pretrained.layer2.0.downsample.1.running_var\", \"pretrained.layer2.0.downsample.1.num_batches_tracked\", \"pretrained.layer2.1.conv1.weight\", \"pretrained.layer2.1.bn1.weight\", \"pretrained.layer2.1.bn1.bias\", \"pretrained.layer2.1.bn1.running_mean\", \"pretrained.layer2.1.bn1.running_var\", \"pretrained.layer2.1.bn1.num_batches_tracked\", \"pretrained.layer2.1.conv2.weight\", \"pretrained.layer2.1.bn2.weight\", \"pretrained.layer2.1.bn2.bias\", \"pretrained.layer2.1.bn2.running_mean\", \"pretrained.layer2.1.bn2.running_var\", \"pretrained.layer2.1.bn2.num_batches_tracked\", \"pretrained.layer2.1.conv3.weight\", \"pretrained.layer2.1.bn3.weight\", \"pretrained.layer2.1.bn3.bias\", \"pretrained.layer2.1.bn3.running_mean\", \"pretrained.layer2.1.bn3.running_var\", \"pretrained.layer2.1.bn3.num_batches_tracked\", \"pretrained.layer2.2.conv1.weight\", \"pretrained.layer2.2.bn1.weight\", \"pretrained.layer2.2.bn1.bias\", \"pretrained.layer2.2.bn1.running_mean\", \"pretrained.layer2.2.bn1.running_var\", \"pretrained.layer2.2.bn1.num_batches_tracked\", \"pretrained.layer2.2.conv2.weight\", \"pretrained.layer2.2.bn2.weight\", \"pretrained.layer2.2.bn2.bias\", \"pretrained.layer2.2.bn2.running_mean\", \"pretrained.layer2.2.bn2.running_var\", \"pretrained.layer2.2.bn2.num_batches_tracked\", \"pretrained.layer2.2.conv3.weight\", \"pretrained.layer2.2.bn3.weight\", \"pretrained.layer2.2.bn3.bias\", \"pretrained.layer2.2.bn3.running_mean\", \"pretrained.layer2.2.bn3.running_var\", \"pretrained.layer2.2.bn3.num_batches_tracked\", \"pretrained.layer2.3.conv1.weight\", \"pretrained.layer2.3.bn1.weight\", \"pretrained.layer2.3.bn1.bias\", \"pretrained.layer2.3.bn1.running_mean\", \"pretrained.layer2.3.bn1.running_var\", \"pretrained.layer2.3.bn1.num_batches_tracked\", \"pretrained.layer2.3.conv2.weight\", \"pretrained.layer2.3.bn2.weight\", \"pretrained.layer2.3.bn2.bias\", \"pretrained.layer2.3.bn2.running_mean\", \"pretrained.layer2.3.bn2.running_var\", \"pretrained.layer2.3.bn2.num_batches_tracked\", \"pretrained.layer2.3.conv3.weight\", \"pretrained.layer2.3.bn3.weight\", \"pretrained.layer2.3.bn3.bias\", \"pretrained.layer2.3.bn3.running_mean\", \"pretrained.layer2.3.bn3.running_var\", \"pretrained.layer2.3.bn3.num_batches_tracked\", \"pretrained.layer3.0.conv1.weight\", \"pretrained.layer3.0.bn1.weight\", \"pretrained.layer3.0.bn1.bias\", \"pretrained.layer3.0.bn1.running_mean\", \"pretrained.layer3.0.bn1.running_var\", \"pretrained.layer3.0.bn1.num_batches_tracked\", \"pretrained.layer3.0.conv2.weight\", \"pretrained.layer3.0.bn2.weight\", \"pretrained.layer3.0.bn2.bias\", \"pretrained.layer3.0.bn2.running_mean\", \"pretrained.layer3.0.bn2.running_var\", \"pretrained.layer3.0.bn2.num_batches_tracked\", \"pretrained.layer3.0.conv3.weight\", \"pretrained.layer3.0.bn3.weight\", \"pretrained.layer3.0.bn3.bias\", \"pretrained.layer3.0.bn3.running_mean\", \"pretrained.layer3.0.bn3.running_var\", \"pretrained.layer3.0.bn3.num_batches_tracked\", \"pretrained.layer3.0.downsample.0.weight\", \"pretrained.layer3.0.downsample.1.weight\", \"pretrained.layer3.0.downsample.1.bias\", \"pretrained.layer3.0.downsample.1.running_mean\", \"pretrained.layer3.0.downsample.1.running_var\", \"pretrained.layer3.0.downsample.1.num_batches_tracked\", \"pretrained.layer3.1.conv1.weight\", \"pretrained.layer3.1.bn1.weight\", \"pretrained.layer3.1.bn1.bias\", \"pretrained.layer3.1.bn1.running_mean\", \"pretrained.layer3.1.bn1.running_var\", \"pretrained.layer3.1.bn1.num_batches_tracked\", \"pretrained.layer3.1.conv2.weight\", \"pretrained.layer3.1.bn2.weight\", \"pretrained.layer3.1.bn2.bias\", \"pretrained.layer3.1.bn2.running_mean\", \"pretrained.layer3.1.bn2.running_var\", \"pretrained.layer3.1.bn2.num_batches_tracked\", \"pretrained.layer3.1.conv3.weight\", \"pretrained.layer3.1.bn3.weight\", \"pretrained.layer3.1.bn3.bias\", \"pretrained.layer3.1.bn3.running_mean\", \"pretrained.layer3.1.bn3.running_var\", \"pretrained.layer3.1.bn3.num_batches_tracked\", \"pretrained.layer3.2.conv1.weight\", \"pretrained.layer3.2.bn1.weight\", \"pretrained.layer3.2.bn1.bias\", \"pretrained.layer3.2.bn1.running_mean\", \"pretrained.layer3.2.bn1.running_var\", \"pretrained.layer3.2.bn1.num_batches_tracked\", \"pretrained.layer3.2.conv2.weight\", \"pretrained.layer3.2.bn2.weight\", \"pretrained.layer3.2.bn2.bias\", \"pretrained.layer3.2.bn2.running_mean\", \"pretrained.layer3.2.bn2.running_var\", \"pretrained.layer3.2.bn2.num_batches_tracked\", \"pretrained.layer3.2.conv3.weight\", \"pretrained.layer3.2.bn3.weight\", \"pretrained.layer3.2.bn3.bias\", \"pretrained.layer3.2.bn3.running_mean\", \"pretrained.layer3.2.bn3.running_var\", \"pretrained.layer3.2.bn3.num_batches_tracked\", \"pretrained.layer3.3.conv1.weight\", \"pretrained.layer3.3.bn1.weight\", \"pretrained.layer3.3.bn1.bias\", \"pretrained.layer3.3.bn1.running_mean\", \"pretrained.layer3.3.bn1.running_var\", \"pretrained.layer3.3.bn1.num_batches_tracked\", \"pretrained.layer3.3.conv2.weight\", \"pretrained.layer3.3.bn2.weight\", \"pretrained.layer3.3.bn2.bias\", \"pretrained.layer3.3.bn2.running_mean\", \"pretrained.layer3.3.bn2.running_var\", \"pretrained.layer3.3.bn2.num_batches_tracked\", \"pretrained.layer3.3.conv3.weight\", \"pretrained.layer3.3.bn3.weight\", \"pretrained.layer3.3.bn3.bias\", \"pretrained.layer3.3.bn3.running_mean\", \"pretrained.layer3.3.bn3.running_var\", \"pretrained.layer3.3.bn3.num_batches_tracked\", \"pretrained.layer3.4.conv1.weight\", \"pretrained.layer3.4.bn1.weight\", \"pretrained.layer3.4.bn1.bias\", \"pretrained.layer3.4.bn1.running_mean\", \"pretrained.layer3.4.bn1.running_var\", \"pretrained.layer3.4.bn1.num_batches_tracked\", \"pretrained.layer3.4.conv2.weight\", \"pretrained.layer3.4.bn2.weight\", \"pretrained.layer3.4.bn2.bias\", \"pretrained.layer3.4.bn2.running_mean\", \"pretrained.layer3.4.bn2.running_var\", \"pretrained.layer3.4.bn2.num_batches_tracked\", \"pretrained.layer3.4.conv3.weight\", \"pretrained.layer3.4.bn3.weight\", \"pretrained.layer3.4.bn3.bias\", \"pretrained.layer3.4.bn3.running_mean\", \"pretrained.layer3.4.bn3.running_var\", \"pretrained.layer3.4.bn3.num_batches_tracked\", \"pretrained.layer3.5.conv1.weight\", \"pretrained.layer3.5.bn1.weight\", \"pretrained.layer3.5.bn1.bias\", \"pretrained.layer3.5.bn1.running_mean\", \"pretrained.layer3.5.bn1.running_var\", \"pretrained.layer3.5.bn1.num_batches_tracked\", \"pretrained.layer3.5.conv2.weight\", \"pretrained.layer3.5.bn2.weight\", \"pretrained.layer3.5.bn2.bias\", \"pretrained.layer3.5.bn2.running_mean\", \"pretrained.layer3.5.bn2.running_var\", \"pretrained.layer3.5.bn2.num_batches_tracked\", \"pretrained.layer3.5.conv3.weight\", \"pretrained.layer3.5.bn3.weight\", \"pretrained.layer3.5.bn3.bias\", \"pretrained.layer3.5.bn3.running_mean\", \"pretrained.layer3.5.bn3.running_var\", \"pretrained.layer3.5.bn3.num_batches_tracked\", \"pretrained.layer3.6.conv1.weight\", \"pretrained.layer3.6.bn1.weight\", \"pretrained.layer3.6.bn1.bias\", \"pretrained.layer3.6.bn1.running_mean\", \"pretrained.layer3.6.bn1.running_var\", \"pretrained.layer3.6.bn1.num_batches_tracked\", \"pretrained.layer3.6.conv2.weight\", \"pretrained.layer3.6.bn2.weight\", \"pretrained.layer3.6.bn2.bias\", \"pretrained.layer3.6.bn2.running_mean\", \"pretrained.layer3.6.bn2.running_var\", \"pretrained.layer3.6.bn2.num_batches_tracked\", \"pretrained.layer3.6.conv3.weight\", \"pretrained.layer3.6.bn3.weight\", \"pretrained.layer3.6.bn3.bias\", \"pretrained.layer3.6.bn3.running_mean\", \"pretrained.layer3.6.bn3.running_var\", \"pretrained.layer3.6.bn3.num_batches_tracked\", \"pretrained.layer3.7.conv1.weight\", \"pretrained.layer3.7.bn1.weight\", \"pretrained.layer3.7.bn1.bias\", \"pretrained.layer3.7.bn1.running_mean\", \"pretrained.layer3.7.bn1.running_var\", \"pretrained.layer3.7.bn1.num_batches_tracked\", \"pretrained.layer3.7.conv2.weight\", \"pretrained.layer3.7.bn2.weight\", \"pretrained.layer3.7.bn2.bias\", \"pretrained.layer3.7.bn2.running_mean\", \"pretrained.layer3.7.bn2.running_var\", \"pretrained.layer3.7.bn2.num_batches_tracked\", \"pretrained.layer3.7.conv3.weight\", \"pretrained.layer3.7.bn3.weight\", \"pretrained.layer3.7.bn3.bias\", \"pretrained.layer3.7.bn3.running_mean\", \"pretrained.layer3.7.bn3.running_var\", \"pretrained.layer3.7.bn3.num_batches_tracked\", \"pretrained.layer3.8.conv1.weight\", \"pretrained.layer3.8.bn1.weight\", \"pretrained.layer3.8.bn1.bias\", \"pretrained.layer3.8.bn1.running_mean\", \"pretrained.layer3.8.bn1.running_var\", \"pretrained.layer3.8.bn1.num_batches_tracked\", \"pretrained.layer3.8.conv2.weight\", \"pretrained.layer3.8.bn2.weight\", \"pretrained.layer3.8.bn2.bias\", \"pretrained.layer3.8.bn2.running_mean\", \"pretrained.layer3.8.bn2.running_var\", \"pretrained.layer3.8.bn2.num_batches_tracked\", \"pretrained.layer3.8.conv3.weight\", \"pretrained.layer3.8.bn3.weight\", \"pretrained.layer3.8.bn3.bias\", \"pretrained.layer3.8.bn3.running_mean\", \"pretrained.layer3.8.bn3.running_var\", \"pretrained.layer3.8.bn3.num_batches_tracked\", \"pretrained.layer3.9.conv1.weight\", \"pretrained.layer3.9.bn1.weight\", \"pretrained.layer3.9.bn1.bias\", \"pretrained.layer3.9.bn1.running_mean\", \"pretrained.layer3.9.bn1.running_var\", \"pretrained.layer3.9.bn1.num_batches_tracked\", \"pretrained.layer3.9.conv2.weight\", \"pretrained.layer3.9.bn2.weight\", \"pretrained.layer3.9.bn2.bias\", \"pretrained.layer3.9.bn2.running_mean\", \"pretrained.layer3.9.bn2.running_var\", \"pretrained.layer3.9.bn2.num_batches_tracked\", \"pretrained.layer3.9.conv3.weight\", \"pretrained.layer3.9.bn3.weight\", \"pretrained.layer3.9.bn3.bias\", \"pretrained.layer3.9.bn3.running_mean\", \"pretrained.layer3.9.bn3.running_var\", \"pretrained.layer3.9.bn3.num_batches_tracked\", \"pretrained.layer3.10.conv1.weight\", \"pretrained.layer3.10.bn1.weight\", \"pretrained.layer3.10.bn1.bias\", \"pretrained.layer3.10.bn1.running_mean\", \"pretrained.layer3.10.bn1.running_var\", \"pretrained.layer3.10.bn1.num_batches_tracked\", \"pretrained.layer3.10.conv2.weight\", \"pretrained.layer3.10.bn2.weight\", \"pretrained.layer3.10.bn2.bias\", \"pretrained.layer3.10.bn2.running_mean\", \"pretrained.layer3.10.bn2.running_var\", \"pretrained.layer3.10.bn2.num_batches_tracked\", \"pretrained.layer3.10.conv3.weight\", \"pretrained.layer3.10.bn3.weight\", \"pretrained.layer3.10.bn3.bias\", \"pretrained.layer3.10.bn3.running_mean\", \"pretrained.layer3.10.bn3.running_var\", \"pretrained.layer3.10.bn3.num_batches_tracked\", \"pretrained.layer3.11.conv1.weight\", \"pretrained.layer3.11.bn1.weight\", \"pretrained.layer3.11.bn1.bias\", \"pretrained.layer3.11.bn1.running_mean\", \"pretrained.layer3.11.bn1.running_var\", \"pretrained.layer3.11.bn1.num_batches_tracked\", \"pretrained.layer3.11.conv2.weight\", \"pretrained.layer3.11.bn2.weight\", \"pretrained.layer3.11.bn2.bias\", \"pretrained.layer3.11.bn2.running_mean\", \"pretrained.layer3.11.bn2.running_var\", \"pretrained.layer3.11.bn2.num_batches_tracked\", \"pretrained.layer3.11.conv3.weight\", \"pretrained.layer3.11.bn3.weight\", \"pretrained.layer3.11.bn3.bias\", \"pretrained.layer3.11.bn3.running_mean\", \"pretrained.layer3.11.bn3.running_var\", \"pretrained.layer3.11.bn3.num_batches_tracked\", \"pretrained.layer3.12.conv1.weight\", \"pretrained.layer3.12.bn1.weight\", \"pretrained.layer3.12.bn1.bias\", \"pretrained.layer3.12.bn1.running_mean\", \"pretrained.layer3.12.bn1.running_var\", \"pretrained.layer3.12.bn1.num_batches_tracked\", \"pretrained.layer3.12.conv2.weight\", \"pretrained.layer3.12.bn2.weight\", \"pretrained.layer3.12.bn2.bias\", \"pretrained.layer3.12.bn2.running_mean\", \"pretrained.layer3.12.bn2.running_var\", \"pretrained.layer3.12.bn2.num_batches_tracked\", \"pretrained.layer3.12.conv3.weight\", \"pretrained.layer3.12.bn3.weight\", \"pretrained.layer3.12.bn3.bias\", \"pretrained.layer3.12.bn3.running_mean\", \"pretrained.layer3.12.bn3.running_var\", \"pretrained.layer3.12.bn3.num_batches_tracked\", \"pretrained.layer3.13.conv1.weight\", \"pretrained.layer3.13.bn1.weight\", \"pretrained.layer3.13.bn1.bias\", \"pretrained.layer3.13.bn1.running_mean\", \"pretrained.layer3.13.bn1.running_var\", \"pretrained.layer3.13.bn1.num_batches_tracked\", \"pretrained.layer3.13.conv2.weight\", \"pretrained.layer3.13.bn2.weight\", \"pretrained.layer3.13.bn2.bias\", \"pretrained.layer3.13.bn2.running_mean\", \"pretrained.layer3.13.bn2.running_var\", \"pretrained.layer3.13.bn2.num_batches_tracked\", \"pretrained.layer3.13.conv3.weight\", \"pretrained.layer3.13.bn3.weight\", \"pretrained.layer3.13.bn3.bias\", \"pretrained.layer3.13.bn3.running_mean\", \"pretrained.layer3.13.bn3.running_var\", \"pretrained.layer3.13.bn3.num_batches_tracked\", \"pretrained.layer3.14.conv1.weight\", \"pretrained.layer3.14.bn1.weight\", \"pretrained.layer3.14.bn1.bias\", \"pretrained.layer3.14.bn1.running_mean\", \"pretrained.layer3.14.bn1.running_var\", \"pretrained.layer3.14.bn1.num_batches_tracked\", \"pretrained.layer3.14.conv2.weight\", \"pretrained.layer3.14.bn2.weight\", \"pretrained.layer3.14.bn2.bias\", \"pretrained.layer3.14.bn2.running_mean\", \"pretrained.layer3.14.bn2.running_var\", \"pretrained.layer3.14.bn2.num_batches_tracked\", \"pretrained.layer3.14.conv3.weight\", \"pretrained.layer3.14.bn3.weight\", \"pretrained.layer3.14.bn3.bias\", \"pretrained.layer3.14.bn3.running_mean\", \"pretrained.layer3.14.bn3.running_var\", \"pretrained.layer3.14.bn3.num_batches_tracked\", \"pretrained.layer3.15.conv1.weight\", \"pretrained.layer3.15.bn1.weight\", \"pretrained.layer3.15.bn1.bias\", \"pretrained.layer3.15.bn1.running_mean\", \"pretrained.layer3.15.bn1.running_var\", \"pretrained.layer3.15.bn1.num_batches_tracked\", \"pretrained.layer3.15.conv2.weight\", \"pretrained.layer3.15.bn2.weight\", \"pretrained.layer3.15.bn2.bias\", \"pretrained.layer3.15.bn2.running_mean\", \"pretrained.layer3.15.bn2.running_var\", \"pretrained.layer3.15.bn2.num_batches_tracked\", \"pretrained.layer3.15.conv3.weight\", \"pretrained.layer3.15.bn3.weight\", \"pretrained.layer3.15.bn3.bias\", \"pretrained.layer3.15.bn3.running_mean\", \"pretrained.layer3.15.bn3.running_var\", \"pretrained.layer3.15.bn3.num_batches_tracked\", \"pretrained.layer3.16.conv1.weight\", \"pretrained.layer3.16.bn1.weight\", \"pretrained.layer3.16.bn1.bias\", \"pretrained.layer3.16.bn1.running_mean\", \"pretrained.layer3.16.bn1.running_var\", \"pretrained.layer3.16.bn1.num_batches_tracked\", \"pretrained.layer3.16.conv2.weight\", \"pretrained.layer3.16.bn2.weight\", \"pretrained.layer3.16.bn2.bias\", \"pretrained.layer3.16.bn2.running_mean\", \"pretrained.layer3.16.bn2.running_var\", \"pretrained.layer3.16.bn2.num_batches_tracked\", \"pretrained.layer3.16.conv3.weight\", \"pretrained.layer3.16.bn3.weight\", \"pretrained.layer3.16.bn3.bias\", \"pretrained.layer3.16.bn3.running_mean\", \"pretrained.layer3.16.bn3.running_var\", \"pretrained.layer3.16.bn3.num_batches_tracked\", \"pretrained.layer3.17.conv1.weight\", \"pretrained.layer3.17.bn1.weight\", \"pretrained.layer3.17.bn1.bias\", \"pretrained.layer3.17.bn1.running_mean\", \"pretrained.layer3.17.bn1.running_var\", \"pretrained.layer3.17.bn1.num_batches_tracked\", \"pretrained.layer3.17.conv2.weight\", \"pretrained.layer3.17.bn2.weight\", \"pretrained.layer3.17.bn2.bias\", \"pretrained.layer3.17.bn2.running_mean\", \"pretrained.layer3.17.bn2.running_var\", \"pretrained.layer3.17.bn2.num_batches_tracked\", \"pretrained.layer3.17.conv3.weight\", \"pretrained.layer3.17.bn3.weight\", \"pretrained.layer3.17.bn3.bias\", \"pretrained.layer3.17.bn3.running_mean\", \"pretrained.layer3.17.bn3.running_var\", \"pretrained.layer3.17.bn3.num_batches_tracked\", \"pretrained.layer3.18.conv1.weight\", \"pretrained.layer3.18.bn1.weight\", \"pretrained.layer3.18.bn1.bias\", \"pretrained.layer3.18.bn1.running_mean\", \"pretrained.layer3.18.bn1.running_var\", \"pretrained.layer3.18.bn1.num_batches_tracked\", \"pretrained.layer3.18.conv2.weight\", \"pretrained.layer3.18.bn2.weight\", \"pretrained.layer3.18.bn2.bias\", \"pretrained.layer3.18.bn2.running_mean\", \"pretrained.layer3.18.bn2.running_var\", \"pretrained.layer3.18.bn2.num_batches_tracked\", \"pretrained.layer3.18.conv3.weight\", \"pretrained.layer3.18.bn3.weight\", \"pretrained.layer3.18.bn3.bias\", \"pretrained.layer3.18.bn3.running_mean\", \"pretrained.layer3.18.bn3.running_var\", \"pretrained.layer3.18.bn3.num_batches_tracked\", \"pretrained.layer3.19.conv1.weight\", \"pretrained.layer3.19.bn1.weight\", \"pretrained.layer3.19.bn1.bias\", \"pretrained.layer3.19.bn1.running_mean\", \"pretrained.layer3.19.bn1.running_var\", \"pretrained.layer3.19.bn1.num_batches_tracked\", \"pretrained.layer3.19.conv2.weight\", \"pretrained.layer3.19.bn2.weight\", \"pretrained.layer3.19.bn2.bias\", \"pretrained.layer3.19.bn2.running_mean\", \"pretrained.layer3.19.bn2.running_var\", \"pretrained.layer3.19.bn2.num_batches_tracked\", \"pretrained.layer3.19.conv3.weight\", \"pretrained.layer3.19.bn3.weight\", \"pretrained.layer3.19.bn3.bias\", \"pretrained.layer3.19.bn3.running_mean\", \"pretrained.layer3.19.bn3.running_var\", \"pretrained.layer3.19.bn3.num_batches_tracked\", \"pretrained.layer3.20.conv1.weight\", \"pretrained.layer3.20.bn1.weight\", \"pretrained.layer3.20.bn1.bias\", \"pretrained.layer3.20.bn1.running_mean\", \"pretrained.layer3.20.bn1.running_var\", \"pretrained.layer3.20.bn1.num_batches_tracked\", \"pretrained.layer3.20.conv2.weight\", \"pretrained.layer3.20.bn2.weight\", \"pretrained.layer3.20.bn2.bias\", \"pretrained.layer3.20.bn2.running_mean\", \"pretrained.layer3.20.bn2.running_var\", \"pretrained.layer3.20.bn2.num_batches_tracked\", \"pretrained.layer3.20.conv3.weight\", \"pretrained.layer3.20.bn3.weight\", \"pretrained.layer3.20.bn3.bias\", \"pretrained.layer3.20.bn3.running_mean\", \"pretrained.layer3.20.bn3.running_var\", \"pretrained.layer3.20.bn3.num_batches_tracked\", \"pretrained.layer3.21.conv1.weight\", \"pretrained.layer3.21.bn1.weight\", \"pretrained.layer3.21.bn1.bias\", \"pretrained.layer3.21.bn1.running_mean\", \"pretrained.layer3.21.bn1.running_var\", \"pretrained.layer3.21.bn1.num_batches_tracked\", \"pretrained.layer3.21.conv2.weight\", \"pretrained.layer3.21.bn2.weight\", \"pretrained.layer3.21.bn2.bias\", \"pretrained.layer3.21.bn2.running_mean\", \"pretrained.layer3.21.bn2.running_var\", \"pretrained.layer3.21.bn2.num_batches_tracked\", \"pretrained.layer3.21.conv3.weight\", \"pretrained.layer3.21.bn3.weight\", \"pretrained.layer3.21.bn3.bias\", \"pretrained.layer3.21.bn3.running_mean\", \"pretrained.layer3.21.bn3.running_var\", \"pretrained.layer3.21.bn3.num_batches_tracked\", \"pretrained.layer3.22.conv1.weight\", \"pretrained.layer3.22.bn1.weight\", \"pretrained.layer3.22.bn1.bias\", \"pretrained.layer3.22.bn1.running_mean\", \"pretrained.layer3.22.bn1.running_var\", \"pretrained.layer3.22.bn1.num_batches_tracked\", \"pretrained.layer3.22.conv2.weight\", \"pretrained.layer3.22.bn2.weight\", \"pretrained.layer3.22.bn2.bias\", \"pretrained.layer3.22.bn2.running_mean\", \"pretrained.layer3.22.bn2.running_var\", \"pretrained.layer3.22.bn2.num_batches_tracked\", \"pretrained.layer3.22.conv3.weight\", \"pretrained.layer3.22.bn3.weight\", \"pretrained.layer3.22.bn3.bias\", \"pretrained.layer3.22.bn3.running_mean\", \"pretrained.layer3.22.bn3.running_var\", \"pretrained.layer3.22.bn3.num_batches_tracked\", \"pretrained.layer4.0.conv1.weight\", \"pretrained.layer4.0.bn1.weight\", \"pretrained.layer4.0.bn1.bias\", \"pretrained.layer4.0.bn1.running_mean\", \"pretrained.layer4.0.bn1.running_var\", \"pretrained.layer4.0.bn1.num_batches_tracked\", \"pretrained.layer4.0.conv2.weight\", \"pretrained.layer4.0.bn2.weight\", \"pretrained.layer4.0.bn2.bias\", \"pretrained.layer4.0.bn2.running_mean\", \"pretrained.layer4.0.bn2.running_var\", \"pretrained.layer4.0.bn2.num_batches_tracked\", \"pretrained.layer4.0.conv3.weight\", \"pretrained.layer4.0.bn3.weight\", \"pretrained.layer4.0.bn3.bias\", \"pretrained.layer4.0.bn3.running_mean\", \"pretrained.layer4.0.bn3.running_var\", \"pretrained.layer4.0.bn3.num_batches_tracked\", \"pretrained.layer4.0.downsample.0.weight\", \"pretrained.layer4.0.downsample.1.weight\", \"pretrained.layer4.0.downsample.1.bias\", \"pretrained.layer4.0.downsample.1.running_mean\", \"pretrained.layer4.0.downsample.1.running_var\", \"pretrained.layer4.0.downsample.1.num_batches_tracked\", \"pretrained.layer4.1.conv1.weight\", \"pretrained.layer4.1.bn1.weight\", \"pretrained.layer4.1.bn1.bias\", \"pretrained.layer4.1.bn1.running_mean\", \"pretrained.layer4.1.bn1.running_var\", \"pretrained.layer4.1.bn1.num_batches_tracked\", \"pretrained.layer4.1.conv2.weight\", \"pretrained.layer4.1.bn2.weight\", \"pretrained.layer4.1.bn2.bias\", \"pretrained.layer4.1.bn2.running_mean\", \"pretrained.layer4.1.bn2.running_var\", \"pretrained.layer4.1.bn2.num_batches_tracked\", \"pretrained.layer4.1.conv3.weight\", \"pretrained.layer4.1.bn3.weight\", \"pretrained.layer4.1.bn3.bias\", \"pretrained.layer4.1.bn3.running_mean\", \"pretrained.layer4.1.bn3.running_var\", \"pretrained.layer4.1.bn3.num_batches_tracked\", \"pretrained.layer4.2.conv1.weight\", \"pretrained.layer4.2.bn1.weight\", \"pretrained.layer4.2.bn1.bias\", \"pretrained.layer4.2.bn1.running_mean\", \"pretrained.layer4.2.bn1.running_var\", \"pretrained.layer4.2.bn1.num_batches_tracked\", \"pretrained.layer4.2.conv2.weight\", \"pretrained.layer4.2.bn2.weight\", \"pretrained.layer4.2.bn2.bias\", \"pretrained.layer4.2.bn2.running_mean\", \"pretrained.layer4.2.bn2.running_var\", \"pretrained.layer4.2.bn2.num_batches_tracked\", \"pretrained.layer4.2.conv3.weight\", \"pretrained.layer4.2.bn3.weight\", \"pretrained.layer4.2.bn3.bias\", \"pretrained.layer4.2.bn3.running_mean\", \"pretrained.layer4.2.bn3.running_var\", \"pretrained.layer4.2.bn3.num_batches_tracked\"]\n",
    "            for x in dl_list: \n",
    "                del checkpoint[x]\n",
    "            self.decoder.load_state_dict(checkpoint)\n",
    "            print('depth_decoder loaded from',depth_preload_pth)\n",
    "        \n",
    "        if yolo_preload_pth != '':\n",
    "            self.yolo_decoder = yolo_decoder(pre_load = True, pre_load_pth = yolo_preload_pth)\n",
    "            print('yolo_decoder loaded from',yolo_preload_pth)\n",
    "        else: \n",
    "            self.yolo_decoder = yolo_decoder(pre_load = False, pre_load_pth = '')\n",
    "        if yolo_freeze:\n",
    "            child_counter = 0\n",
    "            for child in self.yolo_decoder.children():\n",
    "                print(\"yolo_layer\",child_counter,\"was frozen\")\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "                child_counter += 1 \n",
    "                \n",
    "    \n",
    "    def forward(self,x): \n",
    "        EC1, EC2, EC3, out = self.encoder(x)\n",
    "        depth_out = self.decoder(EC1,EC2,EC3,out)\n",
    "        out_13_yolo, out_26_yolo, out_52_yolo = self.yolo_decoder(EC2,EC3,out)\n",
    "        return depth_out, out_13_yolo, out_26_yolo, out_52_yolo\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\realp/.cache\\torch\\hub\\facebookresearch_WSL-Images_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder loaded weights from D:/ML/EVA/JEDi/Midas/model-f46da743.pt\n",
      "resnet_layer 0 was frozen\n",
      "resnet_layer 1 was frozen\n",
      "resnet_layer 2 was frozen\n",
      "resnet_layer 3 was frozen\n",
      "depth_decoder loaded from D:/ML/EVA/JEDi/Midas/model-f46da743.pt\n",
      "loaded weight from D:/ML/EVA/JEDI/YoloV3master/last_ppe.pt\n",
      "yolo_decoder loaded from D:/ML/EVA/JEDI/YoloV3master/last_ppe.pt\n",
      "yolo_layer 0 was frozen\n",
      "yolo_layer 1 was frozen\n",
      "yolo_layer 2 was frozen\n",
      "yolo_layer 3 was frozen\n",
      "yolo_layer 4 was frozen\n",
      "yolo_layer 5 was frozen\n",
      "yolo_layer 6 was frozen\n",
      "yolo_layer 7 was frozen\n",
      "yolo_layer 8 was frozen\n",
      "yolo_layer 9 was frozen\n",
      "yolo_layer 10 was frozen\n",
      "yolo_layer 11 was frozen\n",
      "yolo_layer 12 was frozen\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 208, 208]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 208, 208]             128\n",
      "              ReLU-3         [-1, 64, 208, 208]               0\n",
      "         MaxPool2d-4         [-1, 64, 104, 104]               0\n",
      "            Conv2d-5        [-1, 256, 104, 104]          16,384\n",
      "       BatchNorm2d-6        [-1, 256, 104, 104]             512\n",
      "              ReLU-7        [-1, 256, 104, 104]               0\n",
      "            Conv2d-8        [-1, 256, 104, 104]          18,432\n",
      "       BatchNorm2d-9        [-1, 256, 104, 104]             512\n",
      "             ReLU-10        [-1, 256, 104, 104]               0\n",
      "           Conv2d-11        [-1, 256, 104, 104]          65,536\n",
      "      BatchNorm2d-12        [-1, 256, 104, 104]             512\n",
      "           Conv2d-13        [-1, 256, 104, 104]          16,384\n",
      "      BatchNorm2d-14        [-1, 256, 104, 104]             512\n",
      "             ReLU-15        [-1, 256, 104, 104]               0\n",
      "       Bottleneck-16        [-1, 256, 104, 104]               0\n",
      "           Conv2d-17        [-1, 256, 104, 104]          65,536\n",
      "      BatchNorm2d-18        [-1, 256, 104, 104]             512\n",
      "             ReLU-19        [-1, 256, 104, 104]               0\n",
      "           Conv2d-20        [-1, 256, 104, 104]          18,432\n",
      "      BatchNorm2d-21        [-1, 256, 104, 104]             512\n",
      "             ReLU-22        [-1, 256, 104, 104]               0\n",
      "           Conv2d-23        [-1, 256, 104, 104]          65,536\n",
      "      BatchNorm2d-24        [-1, 256, 104, 104]             512\n",
      "             ReLU-25        [-1, 256, 104, 104]               0\n",
      "       Bottleneck-26        [-1, 256, 104, 104]               0\n",
      "           Conv2d-27        [-1, 256, 104, 104]          65,536\n",
      "      BatchNorm2d-28        [-1, 256, 104, 104]             512\n",
      "             ReLU-29        [-1, 256, 104, 104]               0\n",
      "           Conv2d-30        [-1, 256, 104, 104]          18,432\n",
      "      BatchNorm2d-31        [-1, 256, 104, 104]             512\n",
      "             ReLU-32        [-1, 256, 104, 104]               0\n",
      "           Conv2d-33        [-1, 256, 104, 104]          65,536\n",
      "      BatchNorm2d-34        [-1, 256, 104, 104]             512\n",
      "             ReLU-35        [-1, 256, 104, 104]               0\n",
      "       Bottleneck-36        [-1, 256, 104, 104]               0\n",
      "           Conv2d-37        [-1, 512, 104, 104]         131,072\n",
      "      BatchNorm2d-38        [-1, 512, 104, 104]           1,024\n",
      "             ReLU-39        [-1, 512, 104, 104]               0\n",
      "           Conv2d-40          [-1, 512, 52, 52]          73,728\n",
      "      BatchNorm2d-41          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-42          [-1, 512, 52, 52]               0\n",
      "           Conv2d-43          [-1, 512, 52, 52]         262,144\n",
      "      BatchNorm2d-44          [-1, 512, 52, 52]           1,024\n",
      "           Conv2d-45          [-1, 512, 52, 52]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-47          [-1, 512, 52, 52]               0\n",
      "       Bottleneck-48          [-1, 512, 52, 52]               0\n",
      "           Conv2d-49          [-1, 512, 52, 52]         262,144\n",
      "      BatchNorm2d-50          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-51          [-1, 512, 52, 52]               0\n",
      "           Conv2d-52          [-1, 512, 52, 52]          73,728\n",
      "      BatchNorm2d-53          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-54          [-1, 512, 52, 52]               0\n",
      "           Conv2d-55          [-1, 512, 52, 52]         262,144\n",
      "      BatchNorm2d-56          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-57          [-1, 512, 52, 52]               0\n",
      "       Bottleneck-58          [-1, 512, 52, 52]               0\n",
      "           Conv2d-59          [-1, 512, 52, 52]         262,144\n",
      "      BatchNorm2d-60          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-61          [-1, 512, 52, 52]               0\n",
      "           Conv2d-62          [-1, 512, 52, 52]          73,728\n",
      "      BatchNorm2d-63          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-64          [-1, 512, 52, 52]               0\n",
      "           Conv2d-65          [-1, 512, 52, 52]         262,144\n",
      "      BatchNorm2d-66          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-67          [-1, 512, 52, 52]               0\n",
      "       Bottleneck-68          [-1, 512, 52, 52]               0\n",
      "           Conv2d-69          [-1, 512, 52, 52]         262,144\n",
      "      BatchNorm2d-70          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-71          [-1, 512, 52, 52]               0\n",
      "           Conv2d-72          [-1, 512, 52, 52]          73,728\n",
      "      BatchNorm2d-73          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-74          [-1, 512, 52, 52]               0\n",
      "           Conv2d-75          [-1, 512, 52, 52]         262,144\n",
      "      BatchNorm2d-76          [-1, 512, 52, 52]           1,024\n",
      "             ReLU-77          [-1, 512, 52, 52]               0\n",
      "       Bottleneck-78          [-1, 512, 52, 52]               0\n",
      "           Conv2d-79         [-1, 1024, 52, 52]         524,288\n",
      "      BatchNorm2d-80         [-1, 1024, 52, 52]           2,048\n",
      "             ReLU-81         [-1, 1024, 52, 52]               0\n",
      "           Conv2d-82         [-1, 1024, 26, 26]         294,912\n",
      "      BatchNorm2d-83         [-1, 1024, 26, 26]           2,048\n",
      "             ReLU-84         [-1, 1024, 26, 26]               0\n",
      "           Conv2d-85         [-1, 1024, 26, 26]       1,048,576\n",
      "      BatchNorm2d-86         [-1, 1024, 26, 26]           2,048\n",
      "           Conv2d-87         [-1, 1024, 26, 26]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 26, 26]           2,048\n",
      "             ReLU-89         [-1, 1024, 26, 26]               0\n",
      "       Bottleneck-90         [-1, 1024, 26, 26]               0\n",
      "           Conv2d-91         [-1, 1024, 26, 26]       1,048,576\n",
      "      BatchNorm2d-92         [-1, 1024, 26, 26]           2,048\n",
      "             ReLU-93         [-1, 1024, 26, 26]               0\n",
      "           Conv2d-94         [-1, 1024, 26, 26]         294,912\n",
      "      BatchNorm2d-95         [-1, 1024, 26, 26]           2,048\n",
      "             ReLU-96         [-1, 1024, 26, 26]               0\n",
      "           Conv2d-97         [-1, 1024, 26, 26]       1,048,576\n",
      "      BatchNorm2d-98         [-1, 1024, 26, 26]           2,048\n",
      "             ReLU-99         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-100         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-101         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-102         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-103         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-104         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-105         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-106         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-107         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-108         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-109         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-110         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-111         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-112         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-113         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-114         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-115         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-116         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-117         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-118         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-119         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-120         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-121         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-122         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-123         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-124         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-125         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-126         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-127         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-128         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-129         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-130         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-131         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-132         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-133         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-134         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-135         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-136         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-137         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-138         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-139         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-140         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-141         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-142         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-143         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-144         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-145         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-146         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-147         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-149         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-150         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-151         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-152         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-153         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-154         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-155         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-156         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-157         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-158         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-159         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-160         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-161         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-162         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-163         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-164         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-165         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-166         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-167         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-168         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-169         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-170         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-171         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-172         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-173         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-174         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-175         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-176         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-177         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-178         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-179         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-180         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-181         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-182         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-183         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-184         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-185         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-186         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-187         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-188         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-189         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-190         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-191         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-192         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-193         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-194         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-195         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-196         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-197         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-198         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-199         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-200         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-201         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-202         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-203         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-204         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-205         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-206         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-207         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-208         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-209         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-210         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-211         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-212         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-213         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-214         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-215         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-216         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-217         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-218         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-219         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-220         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-221         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-222         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-223         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-224         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-225         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-226         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-227         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-228         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-229         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-230         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-231         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-232         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-233         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-234         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-235         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-236         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-237         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-238         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-239         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-240         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-241         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-242         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-243         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-244         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-245         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-246         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-247         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-248         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-249         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-250         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-251         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-252         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-253         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-254         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-255         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-256         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-257         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-258         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-259         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-260         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-261         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-262         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-263         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-264         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-265         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-266         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-267         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-268         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-269         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-270         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-271         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-272         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-273         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-274         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-275         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-276         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-277         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-278         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-279         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-280         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-281         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-282         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-283         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-284         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-285         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-286         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-287         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-288         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-289         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-290         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-291         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-292         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-293         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-294         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-295         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-296         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-297         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-298         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-299         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-300         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-301         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-302         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-303         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-304         [-1, 1024, 26, 26]         294,912\n",
      "     BatchNorm2d-305         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-306         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-307         [-1, 1024, 26, 26]       1,048,576\n",
      "     BatchNorm2d-308         [-1, 1024, 26, 26]           2,048\n",
      "            ReLU-309         [-1, 1024, 26, 26]               0\n",
      "      Bottleneck-310         [-1, 1024, 26, 26]               0\n",
      "          Conv2d-311         [-1, 2048, 26, 26]       2,097,152\n",
      "     BatchNorm2d-312         [-1, 2048, 26, 26]           4,096\n",
      "            ReLU-313         [-1, 2048, 26, 26]               0\n",
      "          Conv2d-314         [-1, 2048, 13, 13]       1,179,648\n",
      "     BatchNorm2d-315         [-1, 2048, 13, 13]           4,096\n",
      "            ReLU-316         [-1, 2048, 13, 13]               0\n",
      "          Conv2d-317         [-1, 2048, 13, 13]       4,194,304\n",
      "     BatchNorm2d-318         [-1, 2048, 13, 13]           4,096\n",
      "          Conv2d-319         [-1, 2048, 13, 13]       2,097,152\n",
      "     BatchNorm2d-320         [-1, 2048, 13, 13]           4,096\n",
      "            ReLU-321         [-1, 2048, 13, 13]               0\n",
      "      Bottleneck-322         [-1, 2048, 13, 13]               0\n",
      "          Conv2d-323         [-1, 2048, 13, 13]       4,194,304\n",
      "     BatchNorm2d-324         [-1, 2048, 13, 13]           4,096\n",
      "            ReLU-325         [-1, 2048, 13, 13]               0\n",
      "          Conv2d-326         [-1, 2048, 13, 13]       1,179,648\n",
      "     BatchNorm2d-327         [-1, 2048, 13, 13]           4,096\n",
      "            ReLU-328         [-1, 2048, 13, 13]               0\n",
      "          Conv2d-329         [-1, 2048, 13, 13]       4,194,304\n",
      "     BatchNorm2d-330         [-1, 2048, 13, 13]           4,096\n",
      "            ReLU-331         [-1, 2048, 13, 13]               0\n",
      "      Bottleneck-332         [-1, 2048, 13, 13]               0\n",
      "          Conv2d-333         [-1, 2048, 13, 13]       4,194,304\n",
      "     BatchNorm2d-334         [-1, 2048, 13, 13]           4,096\n",
      "            ReLU-335         [-1, 2048, 13, 13]               0\n",
      "          Conv2d-336         [-1, 2048, 13, 13]       1,179,648\n",
      "     BatchNorm2d-337         [-1, 2048, 13, 13]           4,096\n",
      "            ReLU-338         [-1, 2048, 13, 13]               0\n",
      "          Conv2d-339         [-1, 2048, 13, 13]       4,194,304\n",
      "     BatchNorm2d-340         [-1, 2048, 13, 13]           4,096\n",
      "            ReLU-341         [-1, 2048, 13, 13]               0\n",
      "      Bottleneck-342         [-1, 2048, 13, 13]               0\n",
      "             enc-343  [[-1, 256, 104, 104], [-1, 512, 52, 52], [-1, 1024, 26, 26], [-1, 2048, 13, 13]]               0\n",
      "          Conv2d-344        [-1, 256, 104, 104]         589,824\n",
      "          Conv2d-345          [-1, 256, 52, 52]       1,179,648\n",
      "          Conv2d-346          [-1, 256, 26, 26]       2,359,296\n",
      "          Conv2d-347          [-1, 256, 13, 13]       4,718,592\n",
      "            ReLU-348          [-1, 256, 13, 13]               0\n",
      "          Conv2d-349          [-1, 256, 13, 13]         590,080\n",
      "            ReLU-350          [-1, 256, 13, 13]               0\n",
      "          Conv2d-351          [-1, 256, 13, 13]         590,080\n",
      "ResidualConvUnit-352          [-1, 256, 13, 13]               0\n",
      "FeatureFusionBlock-353          [-1, 256, 26, 26]               0\n",
      "            ReLU-354          [-1, 256, 26, 26]               0\n",
      "          Conv2d-355          [-1, 256, 26, 26]         590,080\n",
      "            ReLU-356          [-1, 256, 26, 26]               0\n",
      "          Conv2d-357          [-1, 256, 26, 26]         590,080\n",
      "ResidualConvUnit-358          [-1, 256, 26, 26]               0\n",
      "            ReLU-359          [-1, 256, 26, 26]               0\n",
      "          Conv2d-360          [-1, 256, 26, 26]         590,080\n",
      "            ReLU-361          [-1, 256, 26, 26]               0\n",
      "          Conv2d-362          [-1, 256, 26, 26]         590,080\n",
      "ResidualConvUnit-363          [-1, 256, 26, 26]               0\n",
      "FeatureFusionBlock-364          [-1, 256, 52, 52]               0\n",
      "            ReLU-365          [-1, 256, 52, 52]               0\n",
      "          Conv2d-366          [-1, 256, 52, 52]         590,080\n",
      "            ReLU-367          [-1, 256, 52, 52]               0\n",
      "          Conv2d-368          [-1, 256, 52, 52]         590,080\n",
      "ResidualConvUnit-369          [-1, 256, 52, 52]               0\n",
      "            ReLU-370          [-1, 256, 52, 52]               0\n",
      "          Conv2d-371          [-1, 256, 52, 52]         590,080\n",
      "            ReLU-372          [-1, 256, 52, 52]               0\n",
      "          Conv2d-373          [-1, 256, 52, 52]         590,080\n",
      "ResidualConvUnit-374          [-1, 256, 52, 52]               0\n",
      "FeatureFusionBlock-375        [-1, 256, 104, 104]               0\n",
      "            ReLU-376        [-1, 256, 104, 104]               0\n",
      "          Conv2d-377        [-1, 256, 104, 104]         590,080\n",
      "            ReLU-378        [-1, 256, 104, 104]               0\n",
      "          Conv2d-379        [-1, 256, 104, 104]         590,080\n",
      "ResidualConvUnit-380        [-1, 256, 104, 104]               0\n",
      "            ReLU-381        [-1, 256, 104, 104]               0\n",
      "          Conv2d-382        [-1, 256, 104, 104]         590,080\n",
      "            ReLU-383        [-1, 256, 104, 104]               0\n",
      "          Conv2d-384        [-1, 256, 104, 104]         590,080\n",
      "ResidualConvUnit-385        [-1, 256, 104, 104]               0\n",
      "FeatureFusionBlock-386        [-1, 256, 208, 208]               0\n",
      "          Conv2d-387        [-1, 128, 208, 208]         295,040\n",
      "     Interpolate-388        [-1, 128, 416, 416]               0\n",
      "          Conv2d-389         [-1, 32, 416, 416]          36,896\n",
      "            ReLU-390         [-1, 32, 416, 416]               0\n",
      "          Conv2d-391          [-1, 1, 416, 416]              33\n",
      "            ReLU-392          [-1, 1, 416, 416]               0\n",
      "   depth_decoder-393             [-1, 416, 416]               0\n",
      "          Conv2d-394         [-1, 2048, 13, 13]       4,194,304\n",
      "          Conv2d-395          [-1, 512, 13, 13]       1,048,576\n",
      "     BatchNorm2d-396          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-397          [-1, 512, 13, 13]               0\n",
      "          Conv2d-398         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-399         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-400         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-401          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-402          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-403          [-1, 512, 13, 13]               0\n",
      "          Conv2d-404         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-405         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-406         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-407           [-1, 27, 13, 13]          27,675\n",
      "       YOLOLayer-408         [-1, 3, 13, 13, 9]               0\n",
      "          Conv2d-409          [-1, 256, 13, 13]         131,072\n",
      "     BatchNorm2d-410          [-1, 256, 13, 13]             512\n",
      "       LeakyReLU-411          [-1, 256, 13, 13]               0\n",
      "        Upsample-412          [-1, 256, 26, 26]               0\n",
      "          Conv2d-413          [-1, 512, 26, 26]         524,288\n",
      "          Conv2d-414          [-1, 256, 26, 26]         196,608\n",
      "     BatchNorm2d-415          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-416          [-1, 256, 26, 26]               0\n",
      "          Conv2d-417          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-418          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-419          [-1, 512, 26, 26]               0\n",
      "          Conv2d-420          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-421          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-422          [-1, 256, 26, 26]               0\n",
      "          Conv2d-423          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-424          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-425          [-1, 512, 26, 26]               0\n",
      "          Conv2d-426          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-427          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-428          [-1, 256, 26, 26]               0\n",
      "          Conv2d-429          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-430          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-431          [-1, 512, 26, 26]               0\n",
      "          Conv2d-432           [-1, 27, 26, 26]          13,851\n",
      "       YOLOLayer-433         [-1, 3, 26, 26, 9]               0\n",
      "          Conv2d-434          [-1, 128, 26, 26]          32,768\n",
      "     BatchNorm2d-435          [-1, 128, 26, 26]             256\n",
      "       LeakyReLU-436          [-1, 128, 26, 26]               0\n",
      "        Upsample-437          [-1, 128, 52, 52]               0\n",
      "          Conv2d-438          [-1, 256, 52, 52]         131,072\n",
      "          Conv2d-439          [-1, 128, 52, 52]          49,152\n",
      "     BatchNorm2d-440          [-1, 128, 52, 52]             256\n",
      "       LeakyReLU-441          [-1, 128, 52, 52]               0\n",
      "          Conv2d-442          [-1, 256, 52, 52]         294,912\n",
      "     BatchNorm2d-443          [-1, 256, 52, 52]             512\n",
      "       LeakyReLU-444          [-1, 256, 52, 52]               0\n",
      "          Conv2d-445          [-1, 128, 52, 52]          32,768\n",
      "     BatchNorm2d-446          [-1, 128, 52, 52]             256\n",
      "       LeakyReLU-447          [-1, 128, 52, 52]               0\n",
      "          Conv2d-448          [-1, 256, 52, 52]         294,912\n",
      "     BatchNorm2d-449          [-1, 256, 52, 52]             512\n",
      "       LeakyReLU-450          [-1, 256, 52, 52]               0\n",
      "          Conv2d-451          [-1, 128, 52, 52]          32,768\n",
      "     BatchNorm2d-452          [-1, 128, 52, 52]             256\n",
      "       LeakyReLU-453          [-1, 128, 52, 52]               0\n",
      "          Conv2d-454          [-1, 256, 52, 52]         294,912\n",
      "     BatchNorm2d-455          [-1, 256, 52, 52]             512\n",
      "       LeakyReLU-456          [-1, 256, 52, 52]               0\n",
      "          Conv2d-457           [-1, 27, 52, 52]           6,939\n",
      "       YOLOLayer-458         [-1, 3, 52, 52, 9]               0\n",
      "    yolo_decoder-459  [[-1, 3, 13, 13, 9], [-1, 3, 26, 26, 9], [-1, 3, 52, 52, 9]]               0\n",
      "================================================================\n",
      "Total params: 125,265,746\n",
      "Trainable params: 17,440,449\n",
      "Non-trainable params: 107,825,297\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.98\n",
      "Forward/backward pass size (MB): 6278.66\n",
      "Params size (MB): 477.85\n",
      "Estimated Total Size (MB): 6758.49\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = fork(depth_freeze = False, yolo_freeze = True,depth_preload_pth = 'D:/ML/EVA/JEDi/Midas/model-f46da743.pt', yolo_preload_pth = 'D:/ML/EVA/JEDI/YoloV3master/last_ppe.pt').to(device)\n",
    "from torchsummary import summary\n",
    "print(summary(model, (3,416,416)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child 0 was frozen\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "child 1 was frozen\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "child 2 was frozen\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "child_counter = 0\n",
    "for child in model.children():\n",
    "    print(\"child\",child_counter,\"was frozen\")\n",
    "    for param in child.parameters():\n",
    "        print(param.requires_grad)\n",
    "    child_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\EVA\\JEDI\\MiDas\n"
     ]
    }
   ],
   "source": [
    "cd D:\\ML\\EVA\\JEDI\\MiDas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "image = torch.load('D:/ML/EVA/JEDI/test_image_tensor.pt')\n",
    "image_cuda = image.to(device)\n",
    "model = fork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model output\n",
    "EC1, EC2, EC3, out = model.forward(image_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64, 104, 104]),\n",
       " torch.Size([1, 128, 52, 52]),\n",
       " torch.Size([1, 256, 26, 26]),\n",
       " torch.Size([1, 512, 13, 13]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EC1.shape, EC2.shape, EC3.shape, out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP/Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\EVA\\JEDi\\Midas\n"
     ]
    }
   ],
   "source": [
    "cd D:/ML/EVA/JEDi/Midas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((549, 976, 3), torch.Size([1, 3, 416, 416]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import utils\n",
    "import cv2\n",
    "\n",
    "from torchvision.transforms import Compose\n",
    "from midas.midas_net import MidasNet\n",
    "from midas.transforms import Resize, NormalizeImage, PrepareForNet\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Resize(\n",
    "            416,\n",
    "            416,\n",
    "            resize_target=None,\n",
    "            keep_aspect_ratio=False,\n",
    "            ensure_multiple_of=32,\n",
    "            resize_method=\"upper_bound\",\n",
    "            image_interpolation_method=cv2.INTER_CUBIC,\n",
    "        ),\n",
    "        NormalizeImage(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        PrepareForNet(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "input_path = 'D:\\ML\\EVA\\JEDI\\MiDaS\\input'\n",
    "img_names = glob.glob(os.path.join(input_path, \"*\"))\n",
    "num_images = len(img_names)\n",
    "\n",
    "img = cv2.imread(img_names[7])\n",
    "img_input = transform({\"image\": img})[\"image\"]\n",
    "image = torch.from_numpy(img_input).unsqueeze(0)\n",
    "img.shape, image.shape\n",
    "#image_cuda = image.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(image, 'D:/ML/EVA/JEDI/test_image_tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(Darknet.modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Sequential(\n",
       "    (Conv2d): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (Conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (Conv2d): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (Conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (4): WeightedFeatureFusion()\n",
       "  (5): Sequential(\n",
       "    (Conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (Conv2d): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (Conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (8): WeightedFeatureFusion()\n",
       "  (9): Sequential(\n",
       "    (Conv2d): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (10): Sequential(\n",
       "    (Conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (11): WeightedFeatureFusion()\n",
       "  (12): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (13): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (14): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (15): WeightedFeatureFusion()\n",
       "  (16): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (17): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (18): WeightedFeatureFusion()\n",
       "  (19): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (20): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (21): WeightedFeatureFusion()\n",
       "  (22): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (23): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (24): WeightedFeatureFusion()\n",
       "  (25): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (26): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (27): WeightedFeatureFusion()\n",
       "  (28): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (29): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (30): WeightedFeatureFusion()\n",
       "  (31): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (32): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (33): WeightedFeatureFusion()\n",
       "  (34): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (35): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (36): WeightedFeatureFusion()\n",
       "  (37): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (38): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (39): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (40): WeightedFeatureFusion()\n",
       "  (41): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (42): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (43): WeightedFeatureFusion()\n",
       "  (44): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (45): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (46): WeightedFeatureFusion()\n",
       "  (47): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (48): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (49): WeightedFeatureFusion()\n",
       "  (50): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (51): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (52): WeightedFeatureFusion()\n",
       "  (53): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (54): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (55): WeightedFeatureFusion()\n",
       "  (56): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (57): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (58): WeightedFeatureFusion()\n",
       "  (59): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (60): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (61): WeightedFeatureFusion()\n",
       "  (62): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (63): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (64): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (65): WeightedFeatureFusion()\n",
       "  (66): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (67): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (68): WeightedFeatureFusion()\n",
       "  (69): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (70): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (71): WeightedFeatureFusion()\n",
       "  (72): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (73): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (74): WeightedFeatureFusion()\n",
       "  (75): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (76): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (77): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (78): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "  (79): FeatureConcat()\n",
       "  (80): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "  (81): FeatureConcat()\n",
       "  (82): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "  (83): FeatureConcat()\n",
       "  (84): Sequential(\n",
       "    (Conv2d): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (85): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (86): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (87): Sequential(\n",
       "    (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (88): Sequential(\n",
       "    (Conv2d): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (89): YOLOLayer()\n",
       "  (90): FeatureConcat()\n",
       "  (91): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (92): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (93): FeatureConcat()\n",
       "  (94): Sequential(\n",
       "    (Conv2d): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (95): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (96): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (97): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (98): Sequential(\n",
       "    (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (99): Sequential(\n",
       "    (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (100): Sequential(\n",
       "    (Conv2d): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (101): YOLOLayer()\n",
       "  (102): FeatureConcat()\n",
       "  (103): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (104): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (105): FeatureConcat()\n",
       "  (106): Sequential(\n",
       "    (Conv2d): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (107): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (108): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (109): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (110): Sequential(\n",
       "    (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (111): Sequential(\n",
       "    (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (112): Sequential(\n",
       "    (Conv2d): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (113): YOLOLayer()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0].module_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\EVA\\JEDI\\YoloV3master\n"
     ]
    }
   ],
   "source": [
    "cd D:/ML/EVA/JEDI/YoloV3master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = 'D:/ML/EVA/JEDI/YoloV3master/cfg/yolov3-custom.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 225 layers, 6.25895e+07 parameters, 6.25895e+07 gradients\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "from utils_yolo.utils import *\n",
    "Darknet = Darknet(cfg)\n",
    "#Darknet = Darknet(cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.ModuleList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 416, 416]             864\n",
      "       BatchNorm2d-2         [-1, 32, 416, 416]              64\n",
      "         LeakyReLU-3         [-1, 32, 416, 416]               0\n",
      "            Conv2d-4         [-1, 64, 208, 208]          18,432\n",
      "       BatchNorm2d-5         [-1, 64, 208, 208]             128\n",
      "         LeakyReLU-6         [-1, 64, 208, 208]               0\n",
      "            Conv2d-7         [-1, 32, 208, 208]           2,048\n",
      "       BatchNorm2d-8         [-1, 32, 208, 208]              64\n",
      "         LeakyReLU-9         [-1, 32, 208, 208]               0\n",
      "           Conv2d-10         [-1, 64, 208, 208]          18,432\n",
      "      BatchNorm2d-11         [-1, 64, 208, 208]             128\n",
      "        LeakyReLU-12         [-1, 64, 208, 208]               0\n",
      "WeightedFeatureFusion-13         [-1, 64, 208, 208]               0\n",
      "           Conv2d-14        [-1, 128, 104, 104]          73,728\n",
      "      BatchNorm2d-15        [-1, 128, 104, 104]             256\n",
      "        LeakyReLU-16        [-1, 128, 104, 104]               0\n",
      "           Conv2d-17         [-1, 64, 104, 104]           8,192\n",
      "      BatchNorm2d-18         [-1, 64, 104, 104]             128\n",
      "        LeakyReLU-19         [-1, 64, 104, 104]               0\n",
      "           Conv2d-20        [-1, 128, 104, 104]          73,728\n",
      "      BatchNorm2d-21        [-1, 128, 104, 104]             256\n",
      "        LeakyReLU-22        [-1, 128, 104, 104]               0\n",
      "WeightedFeatureFusion-23        [-1, 128, 104, 104]               0\n",
      "           Conv2d-24         [-1, 64, 104, 104]           8,192\n",
      "      BatchNorm2d-25         [-1, 64, 104, 104]             128\n",
      "        LeakyReLU-26         [-1, 64, 104, 104]               0\n",
      "           Conv2d-27        [-1, 128, 104, 104]          73,728\n",
      "      BatchNorm2d-28        [-1, 128, 104, 104]             256\n",
      "        LeakyReLU-29        [-1, 128, 104, 104]               0\n",
      "WeightedFeatureFusion-30        [-1, 128, 104, 104]               0\n",
      "           Conv2d-31          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-32          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-33          [-1, 256, 52, 52]               0\n",
      "           Conv2d-34          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-35          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-36          [-1, 128, 52, 52]               0\n",
      "           Conv2d-37          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-38          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-39          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-40          [-1, 256, 52, 52]               0\n",
      "           Conv2d-41          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-42          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-43          [-1, 128, 52, 52]               0\n",
      "           Conv2d-44          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-45          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-46          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-47          [-1, 256, 52, 52]               0\n",
      "           Conv2d-48          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-49          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-50          [-1, 128, 52, 52]               0\n",
      "           Conv2d-51          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-52          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-53          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-54          [-1, 256, 52, 52]               0\n",
      "           Conv2d-55          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-56          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-57          [-1, 128, 52, 52]               0\n",
      "           Conv2d-58          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-59          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-60          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-61          [-1, 256, 52, 52]               0\n",
      "           Conv2d-62          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-63          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-64          [-1, 128, 52, 52]               0\n",
      "           Conv2d-65          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-66          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-67          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-68          [-1, 256, 52, 52]               0\n",
      "           Conv2d-69          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-70          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-71          [-1, 128, 52, 52]               0\n",
      "           Conv2d-72          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-73          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-74          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-75          [-1, 256, 52, 52]               0\n",
      "           Conv2d-76          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-77          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-78          [-1, 128, 52, 52]               0\n",
      "           Conv2d-79          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-80          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-81          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-82          [-1, 256, 52, 52]               0\n",
      "           Conv2d-83          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-84          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-85          [-1, 128, 52, 52]               0\n",
      "           Conv2d-86          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-87          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-88          [-1, 256, 52, 52]               0\n",
      "WeightedFeatureFusion-89          [-1, 256, 52, 52]               0\n",
      "           Conv2d-90          [-1, 512, 26, 26]       1,179,648\n",
      "      BatchNorm2d-91          [-1, 512, 26, 26]           1,024\n",
      "        LeakyReLU-92          [-1, 512, 26, 26]               0\n",
      "           Conv2d-93          [-1, 256, 26, 26]         131,072\n",
      "      BatchNorm2d-94          [-1, 256, 26, 26]             512\n",
      "        LeakyReLU-95          [-1, 256, 26, 26]               0\n",
      "           Conv2d-96          [-1, 512, 26, 26]       1,179,648\n",
      "      BatchNorm2d-97          [-1, 512, 26, 26]           1,024\n",
      "        LeakyReLU-98          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-99          [-1, 512, 26, 26]               0\n",
      "          Conv2d-100          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-101          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-102          [-1, 256, 26, 26]               0\n",
      "          Conv2d-103          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-104          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-105          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-106          [-1, 512, 26, 26]               0\n",
      "          Conv2d-107          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-108          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-109          [-1, 256, 26, 26]               0\n",
      "          Conv2d-110          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-111          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-112          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-113          [-1, 512, 26, 26]               0\n",
      "          Conv2d-114          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-115          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-116          [-1, 256, 26, 26]               0\n",
      "          Conv2d-117          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-118          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-119          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-120          [-1, 512, 26, 26]               0\n",
      "          Conv2d-121          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-122          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-123          [-1, 256, 26, 26]               0\n",
      "          Conv2d-124          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-125          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-126          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-127          [-1, 512, 26, 26]               0\n",
      "          Conv2d-128          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-129          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-130          [-1, 256, 26, 26]               0\n",
      "          Conv2d-131          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-132          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-133          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-134          [-1, 512, 26, 26]               0\n",
      "          Conv2d-135          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-136          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-137          [-1, 256, 26, 26]               0\n",
      "          Conv2d-138          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-139          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-140          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-141          [-1, 512, 26, 26]               0\n",
      "          Conv2d-142          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-143          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-144          [-1, 256, 26, 26]               0\n",
      "          Conv2d-145          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-146          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-147          [-1, 512, 26, 26]               0\n",
      "WeightedFeatureFusion-148          [-1, 512, 26, 26]               0\n",
      "          Conv2d-149         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-150         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-151         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-152          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-153          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-154          [-1, 512, 13, 13]               0\n",
      "          Conv2d-155         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-156         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-157         [-1, 1024, 13, 13]               0\n",
      "WeightedFeatureFusion-158         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-159          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-160          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-161          [-1, 512, 13, 13]               0\n",
      "          Conv2d-162         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-163         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-164         [-1, 1024, 13, 13]               0\n",
      "WeightedFeatureFusion-165         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-166          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-167          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-168          [-1, 512, 13, 13]               0\n",
      "          Conv2d-169         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-170         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-171         [-1, 1024, 13, 13]               0\n",
      "WeightedFeatureFusion-172         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-173          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-174          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-175          [-1, 512, 13, 13]               0\n",
      "          Conv2d-176         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-177         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-178         [-1, 1024, 13, 13]               0\n",
      "WeightedFeatureFusion-179         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-180          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-181          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-182          [-1, 512, 13, 13]               0\n",
      "          Conv2d-183         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-184         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-185         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-186          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-187          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-188          [-1, 512, 13, 13]               0\n",
      "       MaxPool2d-189          [-1, 512, 13, 13]               0\n",
      "   FeatureConcat-190          [-1, 512, 13, 13]               0\n",
      "       MaxPool2d-191          [-1, 512, 13, 13]               0\n",
      "   FeatureConcat-192          [-1, 512, 13, 13]               0\n",
      "       MaxPool2d-193          [-1, 512, 13, 13]               0\n",
      "   FeatureConcat-194         [-1, 2048, 13, 13]               0\n",
      "          Conv2d-195          [-1, 512, 13, 13]       1,048,576\n",
      "     BatchNorm2d-196          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-197          [-1, 512, 13, 13]               0\n",
      "          Conv2d-198         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-199         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-200         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-201          [-1, 512, 13, 13]         524,288\n",
      "     BatchNorm2d-202          [-1, 512, 13, 13]           1,024\n",
      "       LeakyReLU-203          [-1, 512, 13, 13]               0\n",
      "          Conv2d-204         [-1, 1024, 13, 13]       4,718,592\n",
      "     BatchNorm2d-205         [-1, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-206         [-1, 1024, 13, 13]               0\n",
      "          Conv2d-207          [-1, 255, 13, 13]         261,375\n",
      "       YOLOLayer-208        [-1, 3, 13, 13, 85]               0\n",
      "   FeatureConcat-209          [-1, 512, 13, 13]               0\n",
      "          Conv2d-210          [-1, 256, 13, 13]         131,072\n",
      "     BatchNorm2d-211          [-1, 256, 13, 13]             512\n",
      "       LeakyReLU-212          [-1, 256, 13, 13]               0\n",
      "        Upsample-213          [-1, 256, 26, 26]               0\n",
      "   FeatureConcat-214          [-1, 768, 26, 26]               0\n",
      "          Conv2d-215          [-1, 256, 26, 26]         196,608\n",
      "     BatchNorm2d-216          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-217          [-1, 256, 26, 26]               0\n",
      "          Conv2d-218          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-219          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-220          [-1, 512, 26, 26]               0\n",
      "          Conv2d-221          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-222          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-223          [-1, 256, 26, 26]               0\n",
      "          Conv2d-224          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-225          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-226          [-1, 512, 26, 26]               0\n",
      "          Conv2d-227          [-1, 256, 26, 26]         131,072\n",
      "     BatchNorm2d-228          [-1, 256, 26, 26]             512\n",
      "       LeakyReLU-229          [-1, 256, 26, 26]               0\n",
      "          Conv2d-230          [-1, 512, 26, 26]       1,179,648\n",
      "     BatchNorm2d-231          [-1, 512, 26, 26]           1,024\n",
      "       LeakyReLU-232          [-1, 512, 26, 26]               0\n",
      "          Conv2d-233          [-1, 255, 26, 26]         130,815\n",
      "       YOLOLayer-234        [-1, 3, 26, 26, 85]               0\n",
      "   FeatureConcat-235          [-1, 256, 26, 26]               0\n",
      "          Conv2d-236          [-1, 128, 26, 26]          32,768\n",
      "     BatchNorm2d-237          [-1, 128, 26, 26]             256\n",
      "       LeakyReLU-238          [-1, 128, 26, 26]               0\n",
      "        Upsample-239          [-1, 128, 52, 52]               0\n",
      "   FeatureConcat-240          [-1, 384, 52, 52]               0\n",
      "          Conv2d-241          [-1, 128, 52, 52]          49,152\n",
      "     BatchNorm2d-242          [-1, 128, 52, 52]             256\n",
      "       LeakyReLU-243          [-1, 128, 52, 52]               0\n",
      "          Conv2d-244          [-1, 256, 52, 52]         294,912\n",
      "     BatchNorm2d-245          [-1, 256, 52, 52]             512\n",
      "       LeakyReLU-246          [-1, 256, 52, 52]               0\n",
      "          Conv2d-247          [-1, 128, 52, 52]          32,768\n",
      "     BatchNorm2d-248          [-1, 128, 52, 52]             256\n",
      "       LeakyReLU-249          [-1, 128, 52, 52]               0\n",
      "          Conv2d-250          [-1, 256, 52, 52]         294,912\n",
      "     BatchNorm2d-251          [-1, 256, 52, 52]             512\n",
      "       LeakyReLU-252          [-1, 256, 52, 52]               0\n",
      "          Conv2d-253          [-1, 128, 52, 52]          32,768\n",
      "     BatchNorm2d-254          [-1, 128, 52, 52]             256\n",
      "       LeakyReLU-255          [-1, 128, 52, 52]               0\n",
      "          Conv2d-256          [-1, 256, 52, 52]         294,912\n",
      "     BatchNorm2d-257          [-1, 256, 52, 52]             512\n",
      "       LeakyReLU-258          [-1, 256, 52, 52]               0\n",
      "          Conv2d-259          [-1, 255, 52, 52]          65,535\n",
      "       YOLOLayer-260        [-1, 3, 52, 52, 85]               0\n",
      "================================================================\n",
      "Total params: 62,998,749\n",
      "Trainable params: 62,998,749\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.98\n",
      "Forward/backward pass size (MB): 1026.82\n",
      "Params size (MB): 240.32\n",
      "Estimated Total Size (MB): 1269.12\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "print(summary(model, (3,416,416)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True),\n",
       " LeakyReLU(negative_slope=0.1, inplace=True)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(list(vgg_model.children())), len(list(Darknet.children()))\n",
    "#list(list(Darknet.children())[0][0].children())\n",
    "#list(Darknet.children())[0][1]\n",
    "def _gt_darknet_child(x):\n",
    "    if isinstance(list(Darknet.children())[0][x], nn.Sequential):\n",
    "        return list(list(Darknet.children())[0][x].children())\n",
    "    else: \n",
    "        temp = []\n",
    "        temp.append(list(Darknet.children())[0][x])\n",
    "        return temp\n",
    "    \n",
    "def _gt_darknet_children(l):\n",
    "    layer_list = []\n",
    "    for x in l: \n",
    "        layer_list.extend(_gt_darknet_child(x))\n",
    "    return layer_list\n",
    "    \n",
    "        \n",
    "_gt_darknet_child(99)\n",
    "#_gt_darknet_children(list(range(84,89)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = \"10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\"\n",
    "k = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[6,7,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class yolo_decoder(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(yolo_decoder, self).__init__()\n",
    "        #anchors for 13x13, 26X26, 52X52\n",
    "        val = \"10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\"\n",
    "        anc_13 = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[6,7,8]]\n",
    "        anc_26 = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[3,4,5]]\n",
    "        anc_52 = np.array([float(x) for x in val.split(',')]).reshape((-1, 2))[[0,1,2]]\n",
    "        #13x13 yolo layer\n",
    "        self.yolo_13_bottle_neck = nn.Conv2d(2048, 2048, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.yolo_13_path = nn.Sequential(*_gt_darknet_children(list(range(84,87))))\n",
    "        self.yolo_13_tail = nn.Sequential(*_gt_darknet_children(list(range(87,89))))\n",
    "        self.yolo_13 = YOLOLayer(anchors=anc_13,  # anchor list\n",
    "                                nc=4,  # number of classes\n",
    "                                img_size= (416, 416),  # (416, 416)\n",
    "                                yolo_index=0,  # 0, 1, 2...\n",
    "                                layers=[],  # output layers\n",
    "                                stride=32)\n",
    "        #26x26 yolo layer\n",
    "        self.yolo_26_upsample = nn.Sequential(*_gt_darknet_children(list(range(91,93))))\n",
    "        self.yolo_26_bottle_neck = nn.Conv2d(1024, 512, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.yolo_26_path =  nn.Sequential(*_gt_darknet_children(list(range(94,99))))\n",
    "        self.yolo_26_tail = nn.Sequential(*_gt_darknet_children(list(range(99,101))))\n",
    "        self.yolo_26 = YOLOLayer(anchors=anc_26,  # anchor list\n",
    "                                nc=4,  # number of classes\n",
    "                                img_size= (416, 416),  # (416, 416)\n",
    "                                yolo_index=0,  # 0, 1, 2...\n",
    "                                layers=[],  # output layers\n",
    "                                stride=16)\n",
    "        \n",
    "      #52X52 yolo layer \n",
    "        self.yolo_52_upsample = nn.Sequential(*_gt_darknet_children(list(range(103,105))))\n",
    "        self.yolo_52_bottle_neck = nn.Conv2d(512, 256, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.yolo_52_path_tail = nn.Sequential(*_gt_darknet_children(list(range(106,113))))\n",
    "        self.yolo_52 = YOLOLayer(anchors=anc_52,  # anchor list\n",
    "                                nc=4,  # number of classes\n",
    "                                img_size= (416, 416),  # (416, 416)\n",
    "                                yolo_index=0,  # 0, 1, 2...\n",
    "                                layers=[],  # output layers\n",
    "                                stride=8)\n",
    "    \n",
    "    def forward(self, out, EC3, EC2):\n",
    "        #yolo 13\n",
    "        out_bn = self.yolo_13_bottle_neck(out)\n",
    "        out_13_path = self.yolo_13_path(out_bn)\n",
    "        out_13_tail = self.yolo_13_tail(out_13_path)\n",
    "        out_13_yolo = self.yolo_13(out_13_tail,[])\n",
    "        #yolo 26\n",
    "        out_26_upsample = self.yolo_26_upsample(out_13_path)\n",
    "        out_EC3_bn = self.yolo_26_bottle_neck(EC3)\n",
    "        out_26_FC = _FeatureConcat([out_26_upsample,out_EC3_bn])\n",
    "        out_26_path = self.yolo_26_path(out_26_FC)\n",
    "        out_26_tail = self.yolo_26_tail(out_26_path)\n",
    "        out_26_yolo = self.yolo_26(out_26_tail,[])\n",
    "        #yolo 52\n",
    "        out_52_upsample = self.yolo_52_upsample(out_26_path)\n",
    "        out_EC2_bn = self.yolo_52_bottle_neck(EC2)\n",
    "        out_52_FC = _FeatureConcat([out_52_upsample,out_EC2_bn])\n",
    "        out_52_tail = self.yolo_52_path_tail(out_52_FC)\n",
    "        out_52_yolo = self.yolo_52(out_52_tail,[])\n",
    "        return out_13_yolo,out_26_yolo,out_52_yolo\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 52, 52, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo_test = yolo_decoder().to(device)\n",
    "yolo_test.forward(out,EC3, EC2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 13, 13])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.modules at 0x0000026BB9D3E0C8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model = torchvision.models.vgg16(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (Conv2d): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "  (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Darknet.children())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#freezing layers\n",
    "def _gt_child(model, x):\n",
    "    if isinstance(list(model.children())[0][x], nn.Sequential):\n",
    "        return list(list(model.children())[0][x].children())\n",
    "\n",
    "def _gt_children(model,l = ):\n",
    "    layer_list = []\n",
    "    for x in l: \n",
    "        layer_list.extend(_gt_darknet_child(model,x))\n",
    "    return layer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enc(\n",
       "  (res1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (res2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (res3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (res4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.children())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "child_counter = 0\n",
    "for child in model.children():\n",
    "    #if print(child)\n",
    "    for superchild in child.children():\n",
    "            print(superchild)\n",
    "            #print()\n",
    "            #break\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
